# ä¸Šå¸‚å…¬å¸æ–°é—»æ–‡æœ¬åˆ†æä¸åˆ†ç±»é¢„æµ‹

 ![image](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/assets/images/FINNEWS-HUNTER.jpg)

[![Star History Chart](https://api.star-history.com/svg?repos=DemonDamon/Listed-company-news-crawl-and-text-analysis&type=Date)]([https://star-history.com/#linhandev/dataset&Date](https://star-history.com/#DemonDamon/Listed-company-news-crawl-and-text-analysis&Date))

-------------------------------

## ç®€ä»‹

ä¸Šå¸‚å…¬å¸æ–°é—»æ–‡æœ¬åˆ†æä¸åˆ†ç±»é¢„æµ‹çš„åŸºæœ¬æ­¥éª¤å¦‚ä¸‹ï¼š

 - ä»æ–°æµªè´¢ç»ã€æ¯ç»ç½‘ã€é‡‘èç•Œã€ä¸­å›½è¯åˆ¸ç½‘ã€è¯åˆ¸æ—¶æŠ¥ç½‘ä¸Šï¼Œçˆ¬å–ä¸Šå¸‚å…¬å¸ï¼ˆä¸ªè‚¡ï¼‰çš„å†å²æ–°é—»æ–‡æœ¬æ•°æ®ï¼ˆåŒ…æ‹¬æ—¶é—´ã€ç½‘å€ã€æ ‡é¢˜ã€æ­£æ–‡ï¼‰
 - ä»Tushareä¸Šè·å–æ²ªæ·±è‚¡ç¥¨æ—¥çº¿æ•°æ®ï¼ˆå¼€ã€é«˜ã€ä½ã€æ”¶ã€æˆäº¤é‡å’ŒæŒä»“é‡ï¼‰å’ŒåŸºæœ¬ä¿¡æ¯ï¼ˆåŒ…æ‹¬è‚¡ç¥¨ä»£ç ã€è‚¡ç¥¨åç§°ã€æ‰€å±è¡Œä¸šã€æ‰€å±åœ°åŒºã€PEå€¼ã€æ€»èµ„äº§ã€æµåŠ¨èµ„äº§ã€å›ºå®šèµ„äº§ã€ç•™å­˜èµ„äº§ç­‰ï¼‰
 - å¯¹æŠ“å–çš„æ–°é—»æ–‡æœ¬æŒ‰ç…§ï¼Œå»åœç”¨è¯ã€åŠ è½½æ–°è¯ã€åˆ†è¯çš„é¡ºåºè¿›è¡Œå¤„ç†
 - åˆ©ç”¨å‰ä¸¤æ­¥ä¸­æ‰€è·å–çš„è‚¡ç¥¨åç§°å’Œåˆ†è¯åçš„ç»“æœï¼ŒæŠ½å–å‡ºæ¯æ¡æ–°é—»é‡Œæ‰€åŒ…å«çš„ï¼ˆ0æ”¯ã€1æ”¯æˆ–å¤šæ”¯ï¼‰è‚¡ç¥¨åç§°ï¼Œå¹¶å°†æ‰€å¯¹åº”çš„æ‰€æœ‰è‚¡ç¥¨ä»£ç ï¼Œç»„åˆæˆä¸è¯¥æ¡æ–°é—»ç›¸å…³çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¹¶åœ¨å†å²æ•°æ®è¡¨ä¸­å¢åŠ ä¸€åˆ—ç›¸å…³è‚¡ç¥¨ä»£ç æ•°æ®
 - ä»å†å²æ–°é—»æ•°æ®åº“ä¸­æŠ½å–ä¸æŸæ”¯è‚¡ç¥¨ç›¸å…³çš„æ‰€æœ‰æ–°é—»æ–‡æœ¬ï¼Œåˆ©ç”¨è¯¥æ”¯è‚¡ç¥¨çš„æ—¥çº¿æ•°æ®ï¼ˆæ¯”å¦‚æŸä¸€å¤©å‘å¸ƒçš„æ¶ˆæ¯ï¼Œåœ¨è®¾å®šNå¤©åå¦‚æœä»·æ ¼ä¸Šæ¶¨åˆ™è®¤ä¸ºæ˜¯åˆ©å¥½æ¶ˆæ¯ï¼Œåä¹‹åˆ™æ˜¯åˆ©ç©ºæ¶ˆæ¯ï¼‰ç»™æ¯æ¡æ–°é—»è´´ä¸Šâ€œåˆ©å¥½â€å’Œâ€œåˆ©ç©ºâ€çš„æ ‡ç­¾ï¼Œå¹¶å­˜å‚¨åˆ°æ–°çš„æ•°æ®åº“ä¸­ï¼ˆæˆ–å¯¼å‡ºåˆ°CSVæ–‡ä»¶ï¼‰
 - å®æ—¶æŠ“å–æ–°é—»æ•°æ®ï¼Œåˆ¤æ–­ä¸è¯¥æ–°é—»ç›¸å…³çš„è‚¡ç¥¨æœ‰å“ªäº›ï¼Œåˆ©ç”¨ä¸Šä¸€æ­¥çš„ç»“æœï¼Œå¯¹ä¸æŸæ”¯è‚¡ç¥¨ç›¸å…³çš„æ‰€æœ‰å†å²æ–°é—»æ–‡æœ¬ï¼ˆå·²è´´æ ‡ç­¾ï¼‰è¿›è¡Œæ–‡æœ¬åˆ†æï¼ˆæ„å»ºæ–°çš„ç‰¹å¾é›†ï¼‰ï¼Œç„¶ååˆ©ç”¨SVMï¼ˆæˆ–éšæœºæ£®æ—ï¼‰åˆ†ç±»å™¨å¯¹æ–‡æœ¬åˆ†æç»“æœè¿›è¡Œè®­ç»ƒï¼ˆå¦‚æœå·²ä¿å­˜è®­ç»ƒæ¨¡å‹ï¼Œå¯é€‰æ‹©é‡æ–°è®­ç»ƒæˆ–ç›´æ¥åŠ è½½æ¨¡å‹ï¼‰ï¼Œæœ€ååˆ©ç”¨è®­ç»ƒæ¨¡å‹å¯¹å®æ—¶æŠ“å–çš„æ–°é—»æ•°æ®è¿›è¡Œåˆ†ç±»é¢„æµ‹

å¼€å‘ç¯å¢ƒ`Python-v3(3.6)`ï¼š

 - gensim==3.2.0
 - jieba==0.39
 - scikit-learn==0.19.1
 - pandas==0.20.0
 - numpy==1.13.3+mkl
 - scipy==0.19.0
 - pymongo==3.6.0
 - beautifulsoup4==4.6.0
 - tushare==1.1.1
 - requests==2.18.4
 - gevent==1.2.1

## æ–‡æœ¬å¤„ç† -> [text_processing.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/Text_Analysis/text_processing.py)

 - æ–‡æœ¬å¤„ç†åŒ…æ‹¬å»åœç”¨è¯å¤„ç†ã€åŠ è½½æ–°è¯ã€ä¸­æ–‡åˆ†è¯ã€å»æ‰å‡ºç°æ¬¡æ•°å°‘çš„åˆ†è¯
 - ç”Ÿæˆå­—å…¸å’ŒBowå‘é‡ï¼Œå¹¶åŸºäºGensimè½¬åŒ–æ¨¡å‹ï¼ˆLSIã€LDAã€TF-IDFï¼‰è½¬åŒ–Bowå‘é‡
 - è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦
 - æ‰“å°è¯äº‘

## æ–‡æœ¬æŒ–æ˜ -> [text_mining.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/Text_Analysis/text_mining.py)

 - ä»æ–°é—»æ–‡æœ¬ä¸­æŠ½å–ç‰¹å®šä¿¡æ¯ï¼Œå¹¶è´´ä¸Šæ–°çš„æ–‡æœ¬æ ‡ç­¾æ–¹ä¾¿å¾€åè®­ç»ƒæ¨¡å‹
 - ä»æ•°æ®åº“ä¸­æŠ½å–ä¸æŸæ”¯è‚¡ç¥¨ç›¸å…³çš„æ‰€æœ‰æ–°é—»æ–‡æœ¬
 - å°†è´´å¥½æ ‡ç­¾çš„å†å²æ–°é—»è¿›è¡Œåˆ†ç±»è®­ç»ƒï¼Œåˆ©ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹å®æ—¶æŠ“å–çš„æ–°é—»æ–‡æœ¬è¿›è¡Œåˆ†ç±»é¢„æµ‹

## æ–°é—»çˆ¬å– -> [crawler_cnstock.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/Crawler/crawler_cnstock.py), [crawler_jrj.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/Crawler/crawler_jrj.py), [crawler_nbd.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/Crawler/crawler_nbd.py), [crawler_sina.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/Crawler/crawler_sina.py), [crawler_stcn.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/Crawler/crawler_stcn.py)

 - åˆ†æç½‘ç«™ç»“æ„ï¼Œå¤šçº¿ç¨‹ï¼ˆæˆ–åç¨‹ï¼‰çˆ¬å–ä¸Šå¸‚å…¬å¸å†å²æ–°é—»æ•°æ®

## Tushareæ•°æ®æå– -> [crawler_tushare.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/run_crawler_tushare.py)

 - è·å–æ²ªæ·±æ‰€æœ‰è‚¡ç¥¨çš„åŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬è‚¡ç¥¨ä»£ç ã€è‚¡ç¥¨åç§°ã€æ‰€å±è¡Œä¸šã€æ‰€å±åœ°åŒºç­‰

## ç”¨æ³•

 - é…å¥½è¿è¡Œç¯å¢ƒä»¥åŠå®‰è£…MongoDBï¼Œæœ€å¥½å†å®‰è£…ä¸€ä¸ªMongoDBçš„å¯è§†åŒ–ç®¡ç†å·¥å…·Studio 3T
 - å…ˆè¿è¡Œ[crawler_cnstock.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/Crawler/crawler_cnstock.py), [crawler_jrj.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/Crawler/crawler_jrj.py), [crawler_nbd.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/Crawler/crawler_nbd.py), [crawler_sina.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/Crawler/crawler_sina.py), [crawler_stcn.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/Crawler/crawler_stcn.py)è¿™5ä¸ªpyæ–‡ä»¶ï¼Œè€Œä¸”å¯èƒ½å› ä¸ºå¯¹æ–¹æœåŠ¡å™¨æ²¡æœ‰å“åº”è€Œé‡å¤å¤šæ¬¡è¿è¡Œè¿™å‡ ä¸ªæ–‡ä»¶æ‰èƒ½æŠ“å–å¤§é‡çš„å†å²æ•°æ®
 - æ¥ç€è¿è¡Œ[crawler_tushare.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/run_crawler_tushare.py)ä»Tushareè·å–åŸºæœ¬ä¿¡æ¯å’Œè‚¡ç¥¨ä»·æ ¼
 - æœ€åè¿è¡Œ[run_main.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/run_main.py)æ–‡ä»¶ï¼Œå…¶ä¸­æœ‰4ä¸ªæ­¥éª¤ï¼Œé™¤äº†ç¬¬1æ­¥åˆå§‹åŒ–å¤–ï¼Œå…¶ä»–å‡ æ­¥æœ€å¥½å•ç‹¬è¿è¡Œ
 - æ³¨æ„ï¼šæ‰€æœ‰ç¨‹åºéƒ½å¿…é¡»åœ¨æ–‡ä»¶æ‰€åœ¨ç›®å½•ä¸‹è¿è¡Œ

## æ›´æ–°ç›®æ ‡

 ç”±äºä¹‹å‰çš„é¡¹ç›®ä»£ç æ˜¯åœ¨åˆå­¦Pythonçš„æ—¶å€™å†™çš„ï¼Œå¾ˆå¤šå†™æ³•éƒ½æ˜¯å…¥é—¨çº§åˆ«ï¼Œå› æ­¤ä¸ºäº†æé«˜æ•´ä½“é¡¹ç›®çš„è´¨é‡ï¼Œé™¤äº†ä¼˜åŒ–ä»£ç ç»†èŠ‚å’Œå·²æœ‰çš„åŠŸèƒ½æ¨¡å—ä¹‹å¤–ï¼Œè¿˜åŠ å…¥äº†å¤šä¸ªåŠŸèƒ½æ¨¡å—ï¼Œæ¥æ”¯æ’‘æœªæ¥æ›´åŠ æ™ºèƒ½åŒ–å’Œä¸ªæ€§åŒ–çš„é‡‘èåˆ†æä¸äº¤æ˜“ã€‚
 - å®Œæˆåˆæ­¥æ„æƒ³ï¼Œé‡æ„è¯¥é¡¹ç›®ï¼Œå°†é¡¹ç›®åˆ†æˆ8å¤§æ¨¡å—ï¼Œåˆ†åˆ«æ˜¯`æ•°æ®è·å–æ¨¡å—`ï¼Œ`æ•°æ®æ¸…æ´—ä¸é¢„å¤„ç†æ¨¡å—`ï¼Œ`å¤§æ•°æ®å¯è§†åŒ–æ¨¡å—`ï¼Œ`åŸºäºæœºå™¨å­¦ä¹ çš„æ–‡æœ¬æŒ–æ˜æ¨¡å—`ï¼Œ`é‡‘èçŸ¥è¯†å›¾è°±æ„å»ºæ¨¡å—`ï¼Œ`ä»»åŠ¡å¯¼å‘å¤šè½®å¯¹è¯æ¨¡å—`ï¼Œ`é‡‘èäº¤æ˜“æ¨¡å—`ï¼Œ`é€šç”¨æœåŠ¡æ¨¡å—`
 (å¤‡æ³¨ï¼šé¡¹ç›®åœ¨å®Œå–„ä¹‹åä¼šé‡æ–°æ›´åä¸º`Finnews Hunter`ï¼Œå‘½åçš„æ¥æºæ˜¯å‡ºäºå¯¹`ã€Šå…¨èŒçŒäººã€‹`çš„å–œçˆ±ï¼Œä¸é¡¹ç›®æœ¬è´¨çš„ç»“åˆï¼Œå…¶ä¸­`Finnews`æ˜¯`Financial News`çš„ç®€å†™ã€‚ä¸Šé¢æåˆ°çš„8ä¸ªæ¨¡å—ï¼Œåˆ†åˆ«ç”±`ã€Šå…¨èŒçŒäººã€‹`ä¸­çš„æœ¬äººæœ€å–œçˆ±çš„8ä½è§’è‰²å‘½åï¼Œåˆ†åˆ«æ˜¯
 - `æ•°æ®è·å–æ¨¡å—`               -> [Gon](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/tree/main/src/Gon) -> `ç½‘é¡µçˆ¬è™«ã€å„ç§æ•°æ®æºAPIè°ƒç”¨ç­‰`
 - `æ•°æ®æ¸…æ´—ä¸é¢„å¤„ç†æ¨¡å—`       -> [Killua](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/tree/main/src/Killua) -> `æ•°æ®æ¸…æ´—ã€æ•°æ®è½¬æ¢(æ•°æ®é‡‡æ ·ã€ç±»å‹è½¬æ¢ã€å½’ä¸€åŒ–ç­‰)ã€æ•°æ®æè¿°(æ•°æ®å¯è§†åŒ–)ã€ç‰¹å¾é€‰æ‹©ä¸ç»„åˆ(ç†µå¢ç›Šå’Œåˆ†æ”¯å®šç•Œç­‰)ã€ç‰¹å¾æŠ½å–(ä¸»æˆåˆ†åˆ†æã€çº¿æ€§åˆ¤åˆ«åˆ†æç­‰)`
 - `å¤§æ•°æ®å¯è§†åŒ–æ¨¡å—`           -> [Kurapika](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/tree/main/src/Kurapika) -> `åŸºäºå¤šä¸ªå¯è§†åŒ–æ¨¡å—è¿›è¡Œå°è£…ï¼ŒåŒ…æ‹¬æä¾›Webå¯è§†åŒ–ç•Œé¢`
 - `è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡å—`           -> [Leorio](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/tree/main/src/Leorio) -> `ä¸­æ–‡åˆ†è¯ã€è¯æ€§æ ‡æ³¨ã€å®ä½“è¯†åˆ«`
 - `åŸºäºæœºå™¨å­¦ä¹ çš„æ–‡æœ¬æŒ–æ˜æ¨¡å—` -> [Hisoka](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/tree/main/src/Hisoka)  -> ``
 - `é‡‘èçŸ¥è¯†å›¾è°±æ„å»ºæ¨¡å—`       -> [Chrollo](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/tree/main/src/Chrollo) -> ``
 - `ä»»åŠ¡å¯¼å‘å¤šè½®å¯¹è¯æ¨¡å—`       -> [Illumi](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/tree/main/src/Illumi) -> ``
 - `é‡‘èäº¤æ˜“æ¨¡å—`               -> [Feitan](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/tree/main/src/Feitan) -> ``
 - `åŸºç¡€ä¸WebæœåŠ¡æ¨¡å—`          -> [Kite](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/tree/main/src/Kite) -> `åŸºç¡€æœåŠ¡é›†ï¼ŒåŒ…æ‹¬åŸºæœ¬å‚æ•°é…ç½®æ–‡ä»¶(.py)ã€æ•°æ®åº“çš„æ„å»ºä¸è¿æ¥ã€æ—¥å¿—æ‰“å°ä¸æ”¶é›†ã€å¤šçº¿ç¨‹æœåŠ¡ã€WebæœåŠ¡æ¡†æ¶æ­å»ºä»¥åŠå…¶ä»–å‡½æ•°`)
 
 ## æ›´æ–°æ—¥å¿—
 - æ³¨æ„ï¼š  
   - ä»¥ä¸‹ä¾‹å­å‡éœ€åœ¨ä»£ç æ ¹ç›®å½•[src](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/tree/main/src)ä¸‹æ‰§è¡Œ  
   - å…ˆå®‰è£…å¥½MongoDBç”¨ä½œå­˜å‚¨æ•°æ®åº“ï¼Œä»¥åŠRedisç”¨åšç®€å•çš„æ¶ˆæ¯é˜Ÿåˆ—
   - è¿è¡Œä¸‹é¢demoæ—¶ï¼Œå…ˆè¦è®¾ç½®[config.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/src/Kite/config.py)é‡Œé¢çš„å‚æ•°
   
 - æ›´æ–°[crawler_tushare.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/Crawler/crawler_tushare.py)ä»£ç ä¸º[stockinfospyder.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/src/Gon/stockinfospyder.py)ï¼Œç›´æ¥è¿è¡Œå³å¯è·å–è‚¡ç¥¨å†å²ä»·æ ¼æ•°æ®ï¼Œå¹¶åœ¨æ¯å¤©15:30åˆ†åæ›´æ–°æ•°æ®(ç›®å‰åªé‡‡é›†å¤©æ•°æ®)
    - example-1 è°ƒç”¨[AkShare](https://www.akshare.xyz/zh_CN/latest/)æ¥å£è·å–è‚¡ç¥¨å†å²ä»·æ ¼æ•°æ®ï¼Œå¹¶å¼€å¯å®æ—¶æ›´æ–°
    ```
    from Kite import config
    from Gon.stockinfospyder import StockInfoSpyder

    stock_info_spyder = StockInfoSpyder(config.STOCK_DATABASE_NAME, config.COLLECTION_NAME_STOCK_BASIC_INFO)
    # æŒ‡å®šæ—¶é—´æ®µï¼Œè·å–å†å²æ•°æ®ï¼Œå¦‚ï¼šstock_info_spyder.get_historical_news(start_date="20150101", end_date="20201204")
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¶é—´æ®µï¼Œä¸”æ•°æ®åº“å·²å­˜åœ¨éƒ¨åˆ†æ•°æ®ï¼Œåˆ™ä»æœ€æ–°çš„æ•°æ®æ—¶é—´å¼€å§‹è·å–ç›´åˆ°ç°åœ¨ï¼Œæ¯”å¦‚æ•°æ®åº“é‡Œå·²æœ‰sh600000ä»·æ ¼æ•°æ®åˆ°
    # 2020-12-03å·ï¼Œå¦‚ä¸è®¾å®šå…·ä½“æ—¶é—´ï¼Œåˆ™ä»è‡ªåŠ¨è·å–sh600000è‡ª2020-12-04è‡³å½“å‰çš„ä»·æ ¼æ•°æ®
    stock_info_spyder.get_historical_news()
    ```
    - example-2 å¼€å¯è‡ªåŠ¨åŒ–æ›´æ–°æ‰€æœ‰è‚¡ç¥¨ä»·æ ¼æ•°æ®(ç›®å‰åªæ”¯æŒåœ¨15:30åˆ†åæ›´æ–°æ—¥æ•°æ®)
    ```
    from Kite import config
    from Gon.stockinfospyder import StockInfoSpyder

    stock_info_spyder = StockInfoSpyder(config.STOCK_DATABASE_NAME, config.COLLECTION_NAME_STOCK_BASIC_INFO)
    stock_info_spyder.get_realtime_news()
    ```
 - æ›´æ–°[crawler_cnstock.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/Crawler/crawler_cnstock.py)ä»£ç ä¸º[cnstockspyder.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/src/Gon/cnstockspyder.py)ï¼Œç›´æ¥è¿è¡Œå³å¯è·å–ä¸­å›½è¯åˆ¸ç½‘å†å²æ–°é—»æ•°æ®ï¼Œå¹¶å¯ä»¥å®æ—¶æ›´æ–°é‡‡é›†
    - example-1 çˆ¬å–å†å²æ–°é—»æ•°æ®ï¼Œç„¶åå»é‡ä»¥åŠå»NULL
    ```
    import time
    import logging
    from Kite import config
    from Killua.denull import DeNull
    from Killua.deduplication import Deduplication 
    from Gon.cnstockspyder import CnStockSpyder

    cnstock_spyder = CnStockSpyder(config.DATABASE_NAME, config.COLLECTION_NAME_CNSTOCK)
    for url_to_be_crawled, type_chn in config.WEBSITES_LIST_TO_BE_CRAWLED_CNSTOCK.items():
        logging.info("start crawling {} ...".format(url_to_be_crawled))
        cnstock_spyder.get_historical_news(url_to_be_crawled, category_chn=type_chn)
        logging.info("finished ...")
        time.sleep(30)

    Deduplication(config.DATABASE_NAME, config.COLLECTION_NAME_CNSTOCK).run()
    DeNull(config.DATABASE_NAME, config.COLLECTION_NAME_CNSTOCK).run()
    ```
    - example-2 å®æ—¶æ›´æ–°æ–°é—»æ•°æ®åº“ï¼Œå¹¶ä¸”å°†æ–°æ•°æ®æ¨è¿›redisæ¶ˆæ¯é˜Ÿåˆ—ç­‰å¾…å¤„ç†
    ```
    import time, logging, threading
    from Kite import config
    from Kite.database import Database
    from Killua.denull import DeNull
    from Killua.deduplication import Deduplication 
    from Gon.cnstockspyder import CnStockSpyder

    obj = Database()
    df = obj.get_data(config.DATABASE_NAME, config.COLLECTION_NAME_CNSTOCK, keys=["Date", "Category"])

    cnstock_spyder = CnStockSpyder(config.DATABASE_NAME, config.COLLECTION_NAME_CNSTOCK)
    # å…ˆè¡¥å……å†å²æ•°æ®ï¼Œæ¯”å¦‚å·²çˆ¬å–æ•°æ®åˆ°2020-12-01ï¼Œä½†æ˜¯å¯åŠ¨å®æ—¶çˆ¬å–ç¨‹åºåœ¨2020-12-23ï¼Œåˆ™å…ˆ
    # è‡ªåŠ¨è¡¥å……çˆ¬å–2020-12-02è‡³2020-12-23çš„æ–°é—»æ•°æ®
    for url_to_be_crawled, type_chn in config.WEBSITES_LIST_TO_BE_CRAWLED_CNSTOCK.items():
        # æŸ¥è¯¢type_chnçš„æœ€è¿‘ä¸€æ¡æ•°æ®çš„æ—¶é—´
        latets_date_in_db = max(df[df.Category == type_chn]["Date"].to_list())
        cnstock_spyder.get_historical_news(url_to_be_crawled, category_chn=type_chn, start_date=latets_date_in_db)

    Deduplication(config.DATABASE_NAME, config.COLLECTION_NAME_CNSTOCK).run()
    DeNull(config.DATABASE_NAME, config.COLLECTION_NAME_CNSTOCK).run()

    # å¼€å¯å¤šçº¿ç¨‹å¹¶è¡Œå®æ—¶çˆ¬å–
    thread_list = []
    for url, type_chn in config.WEBSITES_LIST_TO_BE_CRAWLED_CNSTOCK.items():
        thread = threading.Thread(target=cnstock_spyder.get_realtime_news, args=(url, type_chn, 60))
        thread_list.append(thread)
    for thread in thread_list:
        thread.start()
    for thread in thread_list:
        thread.join()
    ```
 - æ›´æ–°[crawler_jrj.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/Crawler/crawler_jrj.py)ä»£ç ä¸º[jrjspyder.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/src/Gon/jrjspyder.py)ï¼Œç›´æ¥è¿è¡Œå³å¯è·å–é‡‘èç•Œå†å²æ–°é—»æ•°æ®ï¼Œå¹¶å¯ä»¥å®æ—¶æ›´æ–°é‡‡é›†
    - example-1 çˆ¬å–å†å²æ–°é—»æ•°æ®ï¼Œç„¶åå»é‡ä»¥åŠå»NULL
    ```
    from Kite import config
    from Killua.denull import DeNull
    from Killua.deduplication import Deduplication 
    from Gon.jrjspyder import JrjSpyder

    jrj_spyder = JrjSpyder(config.DATABASE_NAME, config.COLLECTION_NAME_JRJ)
    jrj_spyder.get_historical_news(config.WEBSITES_LIST_TO_BE_CRAWLED_JRJ, start_date="2015-01-01")

    Deduplication(config.DATABASE_NAME, config.COLLECTION_NAME_JRJ).run()
    DeNull(config.DATABASE_NAME, config.COLLECTION_NAME_JRJ).run()
    ```
    - example-2 å·²çˆ¬å–ä¸€å®šé‡çš„å†å²æ•°æ®ä¸‹ï¼Œå¼€å¯å®æ—¶æ›´æ–°æ–°é—»æ•°æ®åº“ï¼Œå¹¶ä¸”å°†æ–°æ•°æ®æ¨è¿›redisæ¶ˆæ¯é˜Ÿåˆ—ç­‰å¾…å¤„ç†
    ```
    from Kite import config
    from Gon.jrjspyder import JrjSpyder

    jrj_spyder = JrjSpyder(config.DATABASE_NAME, config.COLLECTION_NAME_JRJ)
    jrj_spyder.get_historical_news(config.WEBSITES_LIST_TO_BE_CRAWLED_JRJ)  # è¡¥å……çˆ¬è™«æ•°æ®åˆ°æœ€æ–°æ—¥æœŸ
    jrj_spyder.get_realtime_news()
    ```
 - æ›´æ–°[crawler_nbd.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/Crawler/crawler_nbd.py)ä»£ç ä¸º[nbdspyder.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/src/Gon/nbdspyder.py)ï¼Œç›´æ¥è¿è¡Œå³å¯è·å–æ¯ç»ç½‘å†å²æ–°é—»æ•°æ®ï¼Œå¹¶å¯ä»¥å®æ—¶æ›´æ–°é‡‡é›†
    - example-1 çˆ¬å–å†å²æ–°é—»æ•°æ®ï¼Œç„¶åå»é‡ä»¥åŠå»NULL
    ```
    from Kite import config
    from Killua.denull import DeNull
    from Killua.deduplication import Deduplication 
    from Gon.nbdspyder import NbdSpyder

    nbd_spyder = NbdSpyder(config.DATABASE_NAME, config.COLLECTION_NAME_NBD)
    nbd_spyder.get_historical_news(start_page=684)

    Deduplication(config.DATABASE_NAME, config.COLLECTION_NAME_NBD).run()
    DeNull(config.DATABASE_NAME, config.COLLECTION_NAME_NBD).run()
    ```
    - example-2 å·²çˆ¬å–ä¸€å®šé‡çš„å†å²æ•°æ®ä¸‹ï¼Œå¼€å¯å®æ—¶æ›´æ–°æ–°é—»æ•°æ®åº“ï¼Œå¹¶ä¸”å°†æ–°æ•°æ®æ¨è¿›redisæ¶ˆæ¯é˜Ÿåˆ—ç­‰å¾…å¤„ç†
    ```
    from Kite import config
    from Killua.denull import DeNull
    from Killua.deduplication import Deduplication 
    from Gon.nbdspyder import NbdSpyder

    # å¦‚æœæ²¡æœ‰å†å²æ•°æ®ä»å¤´çˆ¬å–ï¼Œå¦‚æœå·²çˆ¬å–å†å²æ•°æ®ï¼Œåˆ™ä»æœ€æ–°çš„æ—¶é—´å¼€å§‹çˆ¬å–
    # å¦‚å†å²æ•°æ®ä¸­æœ€è¿‘çš„æ–°é—»æ—¶é—´æ˜¯"2020-12-09 20:37:10"ï¼Œåˆ™ä»è¯¥æ—¶é—´å¼€å§‹çˆ¬å–
    nbd_spyder = NbdSpyder(config.DATABASE_NAME, config.COLLECTION_NAME_NBD)
    nbd_spyder.get_historical_news()

    Deduplication(config.DATABASE_NAME, config.COLLECTION_NAME_NBD).run()
    DeNull(config.DATABASE_NAME, config.COLLECTION_NAME_NBD).run()

    nbd_spyder.get_realtime_news()
    ```
 - æ›´æ–°[crawler_sina.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/Crawler/crawler_sina.py)ä»£ç ä¸º[sinaspyder.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/src/Gon/sinaspyder.py)ï¼Œç›´æ¥è¿è¡Œå³å¯è·å–æ–°æµªè´¢ç»å†å²æ–°é—»æ•°æ®(æœªæ›´æ–°)
 - åœæ­¢`è¯åˆ¸æ—¶æŠ¥ç½‘`çˆ¬è™«ä»£ç çš„æ›´æ–°(æ—§ä»£ç å·²ä¸å¯ç”¨)ï¼Œæ–°å¢`ç½‘æ˜“è´¢ç»`å’Œ`å‡¤å‡°è´¢ç»`çš„çˆ¬è™«ä»£ç (æœªæ›´æ–°)
 - æ–°å¢[buildstocknewsdb.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/src/Killua/buildstocknewsdb.py)å¦‚æœå·²ç»åœ¨æ¯ç»ç½‘ã€ä¸­å›½è¯åˆ¸ç½‘å’Œé‡‘èç•Œçˆ¬å–äº†ä¸€å®šé‡æ–°é—»æ–‡æœ¬ï¼Œæ¥ä¸‹æ¥å°±æ˜¯é’ˆå¯¹æ¯æ”¯è‚¡ç¥¨æ„å»ºå¯¹åº”çš„æ–°é—»æ•°æ®åº“ï¼Œå¹¶æ ¹æ®è‚¡ä»·è´´ä¸Š3/5/10/15/30/60å¤©æ ‡ç­¾ï¼Œå…·ä½“åˆ¤æ–­æ¡ä»¶æŸ¥çœ‹[buildstocknewsdb.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/src/Killua/buildstocknewsdb.py)ç¬¬111-116è¡Œæ³¨é‡Š
    - example-1 ä»å†å²æ–°é—»æ•°æ®åº“ä¸­æŠ½å–ã€æ„å»ºæ¯æ”¯è‚¡ç¥¨çš„æ–°é—»æ•°æ®åº“ï¼Œå¹¶è´´ä¸Šæ ‡ç­¾
    ```
    from Kite import config
    from Killua.buildstocknewsdb import GenStockNewsDB

    gen_stock_news_db = GenStockNewsDB()
    gen_stock_news_db.get_all_news_about_specific_stock(config.DATABASE_NAME, config.COLLECTION_NAME_CNSTOCK)
    gen_stock_news_db.get_all_news_about_specific_stock(config.DATABASE_NAME, config.COLLECTION_NAME_NBD)
    gen_stock_news_db.get_all_news_about_specific_stock(config.DATABASE_NAME, config.COLLECTION_NAME_JRJ)
    ```
    - example-2 ç›‘å¬redisæ¶ˆæ¯é˜Ÿåˆ—ï¼Œå°†æ–°çš„æ•°æ®åˆ†åˆ«å­˜å…¥ä¸è¯¥æ–°é—»ç›¸å…³çš„æ‰€æœ‰è‚¡ç¥¨æ–°é—»æ•°æ®åº“ä¸­
    ```
    from Kite import config
    from Killua.buildstocknewsdb import GenStockNewsDB

    gen_stock_news_db = GenStockNewsDB()
    gen_stock_news_db.listen_redis_queue()
    ```
 - æ–°å¢[realtime_spyder_startup.bat](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/src/realtime_spyder_startup.bat)åŒæ—¶ä»¥ä¸‹ç¨‹åº
    - å¼€å¯å¤šä¸ªçˆ¬è™«å®ä¾‹ï¼ŒåŒ…æ‹¬[realtime_starter_cnstock.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/src/Gon/realtime_starter_cnstock.py)ã€[realtime_starter_jrj.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/src/Gon/realtime_starter_jrj.py)ã€[realtime_starter_nbd.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/src/Gon/realtime_starter_nbd.py)ç­‰
    - å…¨è‚¡ç¥¨æ•°æ®æ›´æ–°ä»£ç [realtime_starter_stock_price.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/src/Gon/realtime_starter_stock_price.py)
    - ç›‘å¬redisæ¶ˆæ¯é˜Ÿåˆ—[realtime_starter_redis_queue.py](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/src/Gon/realtime_starter_redis_queue.py)
  - æ–°å¢[realtime_spyder_stopall.bat](https://github.com/DemonDamon/Listed-company-news-crawl-and-text-analysis/blob/main/src/realtime_spyder_stopall.bat)æ‰¹é‡ç»ˆæ­¢çˆ¬è™«ç¨‹åº
 - æ›´æ–°å‰ä½¿ç”¨jiebaåˆ†è¯ç³»ç»Ÿï¼Œåœ¨å®ä½“è¯†åˆ«ä¸Šéœ€è¦ä¸æ–­ç»´æŠ¤æ–°è¯è¡¨æ¥æé«˜è¯†åˆ«ç²¾åº¦ï¼›æ›´æ–°åï¼Œä½¿ç”¨åŸºäºBERTé¢„è®­ç»ƒçš„FinBERTå¯¹é‡‘èé¢†åŸŸå®ä½“è¿›è¡Œè¯†åˆ«

# FinnewsHunter (Reborn)

åŸºäº AgenticX æ¡†æ¶æ„å»ºçš„ä¼ä¸šçº§å¤šæ™ºèƒ½ä½“é‡‘èå†³ç­–å¹³å°ã€‚

## é¡¹ç›®çŠ¶æ€

ğŸš§ **é‡æ„è¿›è¡Œä¸­** ğŸš§

æœ¬é¡¹ç›®æ­£åœ¨ç»å†é‡å¤§é‡æ„ï¼Œä»å•ä¸€è„šæœ¬é›†åˆå‡çº§ä¸ºç°ä»£åŒ–çš„å¾®æœåŠ¡æ¶æ„ã€‚

- **æ—§ç‰ˆä»£ç **ï¼šå·²å½’æ¡£è‡³ `legacy_v1/` ç›®å½•ã€‚
- **é‡æ„è§„åˆ’**ï¼šè¯¦è§ [planning.md](../../planning.md)ã€‚

## æŠ€æœ¯æ¶æ„

- **åç«¯**: Python, FastAPI, AgenticX (Orchestrator, Debate, Tools)
- **å‰ç«¯**: TypeScript, React
- **ç®—æ³•**: sklearn, PyTorch, vllm

## å¿«é€Ÿå¼€å§‹

### åç«¯å¼€å‘

1. è¿›å…¥åç«¯ç›®å½•ï¼š
   ```bash
   cd backend
   ```
2. å®‰è£…ä¾èµ–ï¼š
   ```bash
   pip install -r requirements.txt
   ```
3. å¯åŠ¨æœåŠ¡ï¼š
   ```bash
   uvicorn app.main:app --reload
   ```

## ç›®å½•ç»“æ„

```
FinnewsHunter/
â”œâ”€â”€ backend/            # FastAPI åç«¯æœåŠ¡
â”‚   â”œâ”€â”€ app/            # åº”ç”¨ä»£ç 
â”‚   â””â”€â”€ tests/          # æµ‹è¯•ç”¨ä¾‹
â”œâ”€â”€ frontend/           # React å‰ç«¯åº”ç”¨ (å¾…åˆå§‹åŒ–)
â”œâ”€â”€ legacy_v1/          # æ—§ç‰ˆä»£ç å½’æ¡£
â”œâ”€â”€ docs/               # é¡¹ç›®æ–‡æ¡£
â””â”€â”€ README.md           # é¡¹ç›®è¯´æ˜
```

### å¿«é€Ÿå¼€å§‹

1. è¿›å…¥åç«¯ç›®å½•ï¼š
   ```bash
   cd backend
   ```
2. å®‰è£…ä¾èµ–ï¼š
   ```bash
   pip install -r requirements.txt
   ```
3. å¯åŠ¨æœåŠ¡ï¼š
   ```bash
   uvicorn app.main:app --reload
   ```

## ç›®å½•ç»“æ„

```
FinnewsHunter/
â”œâ”€â”€ backend/            # FastAPI åç«¯æœåŠ¡
â”‚   â”œâ”€â”€ app/            # åº”ç”¨ä»£ç 
â”‚   â””â”€â”€ tests/          # æµ‹è¯•ç”¨ä¾‹
â”œâ”€â”€ frontend/           # React å‰ç«¯åº”ç”¨ (å¾…åˆå§‹åŒ–)
â”œâ”€â”€ legacy_v1/          # æ—§ç‰ˆä»£ç å½’æ¡£
â”œâ”€â”€ docs/               # é¡¹ç›®æ–‡æ¡£
â””â”€â”€ README.md           # é¡¹ç›®è¯´æ˜
```