# FinnewsHunterï¼šé‡‘èæ–°é—»é©±åŠ¨çš„å¤šæ™ºèƒ½ä½“æŠ•èµ„å†³ç­–å¹³å°

![FinnewsHunter Logo](assets/images/FINNEWS_HUNTER.png)

åŸºäº [AgenticX](https://github.com/DemonDamon/AgenticX) æ¡†æ¶æ„å»ºçš„ä¼ä¸šçº§é‡‘èæ–°é—»åˆ†æç³»ç»Ÿï¼Œèåˆå®æ—¶æ–°é—»æµã€æ·±åº¦é‡åŒ–åˆ†æå’Œå¤šæ™ºèƒ½ä½“è¾©è®ºæœºåˆ¶ã€‚

---

## ğŸ¯ é¡¹ç›®ç‰¹è‰²

- âœ… **AgenticX åŸç”Ÿ**: æ·±åº¦é›†æˆ AgenticX æ¡†æ¶ï¼Œä½¿ç”¨ Agentã€Toolã€Workflow ç­‰æ ¸å¿ƒæŠ½è±¡
- âœ… **æ™ºèƒ½ä½“é©±åŠ¨**: NewsAnalyst æ™ºèƒ½ä½“è‡ªåŠ¨åˆ†ææ–°é—»æƒ…æ„Ÿå’Œå¸‚åœºå½±å“
- âœ… **å®Œæ•´æŠ€æœ¯æ ˆ**: FastAPI + PostgreSQL + Milvus + Redis + React
- âœ… **ç”Ÿäº§å°±ç»ª**: Docker Compose ä¸€é”®éƒ¨ç½²ï¼Œæ—¥å¿—ã€ç›‘æ§å®Œå¤‡

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

![FinnewsHunter Architecture](assets/images/arch-20251201.png)

ç³»ç»Ÿé‡‡ç”¨åˆ†å±‚æ¶æ„è®¾è®¡ï¼š
- **M6 å‰ç«¯äº¤äº’å±‚**: React + TypeScript + Shadcn UI
- **M1 å¹³å°æœåŠ¡å±‚**: FastAPI Gateway + Task Manager
- **M4/M5 æ™ºèƒ½ä½“ååŒå±‚**: AgenticX Agent + Debate Workflow
- **M2/M3 åŸºç¡€è®¾æ–½å±‚**: Crawler Service + LLM Service + Embedding
- **M7-M11 å­˜å‚¨ä¸å­¦ä¹ å±‚**: PostgreSQL + Milvus + Redis + ACE Framework

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ç½®æ¡ä»¶

- Python 3.11+
- Docker & Docker Compose
- (å¯é€‰) OpenAI API Key æˆ–æœ¬åœ° LLM

### 1. å®‰è£… AgenticX

```bash
cd /Users/damon/myWork/AgenticX
pip install -e .
```

### 2. å®‰è£…ä¾èµ–

```bash
cd examples/agenticx-for-finance/FinnewsHunter/backend
pip install -r requirements.txt
```

### 3. é…ç½®ç¯å¢ƒå˜é‡

```bash
cp env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œå¡«å…¥ OPENAI_API_KEY ç­‰é…ç½®
```

### 4. å¯åŠ¨æœåŠ¡

```bash
# æ–¹å¼ 1: ä½¿ç”¨å¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰
chmod +x start.sh
./start.sh

# æ–¹å¼ 2: æ‰‹åŠ¨å¯åŠ¨
cd ../deploy
docker-compose -f docker-compose.dev.yml up -d
cd ../backend
python -m app.core.database  # åˆå§‹åŒ–æ•°æ®åº“
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 5. è®¿é—®åº”ç”¨

- **åç«¯ API**: http://localhost:8000
- **API æ–‡æ¡£**: http://localhost:8000/docs
- **å‰ç«¯ç•Œé¢**: ç›´æ¥æ‰“å¼€ `frontend/index.html`

---

## ğŸ“š ä½¿ç”¨æŒ‡å—

### æ­¥éª¤ 1: çˆ¬å–æ–°é—»

**æ–¹å¼ 1: é€šè¿‡å‰ç«¯**
1. æ‰“å¼€ `frontend/index.html`
2. è¾“å…¥é¡µç èŒƒå›´ï¼ˆå¦‚ 1-3ï¼‰
3. ç‚¹å‡»"ğŸ“° çˆ¬å–æ–°é—»"

**æ–¹å¼ 2: é€šè¿‡ API**
```bash
curl -X POST http://localhost:8000/api/v1/news/crawl \
  -H "Content-Type: application/json" \
  -d '{
    "source": "sina",
    "start_page": 1,
    "end_page": 2
  }'
```

### æ­¥éª¤ 2: æŸ¥çœ‹æ–°é—»åˆ—è¡¨

```bash
curl http://localhost:8000/api/v1/news/?limit=10
```

### æ­¥éª¤ 3: åˆ†ææ–°é—»

**æ–¹å¼ 1: é€šè¿‡å‰ç«¯**
- åœ¨æ–°é—»å¡ç‰‡ä¸Šç‚¹å‡»"ğŸ“Š åˆ†æ"æŒ‰é’®

**æ–¹å¼ 2: é€šè¿‡ API**
```bash
curl -X POST http://localhost:8000/api/v1/analysis/news/1
```

### æ­¥éª¤ 4: æŸ¥çœ‹åˆ†æç»“æœ

```bash
curl http://localhost:8000/api/v1/analysis/1
```

---

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
FinnewsHunter/
â”œâ”€â”€ backend/                    # åç«¯æœåŠ¡
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ agents/            # æ™ºèƒ½ä½“å®šä¹‰ï¼ˆNewsAnalystï¼‰
â”‚   â”‚   â”œâ”€â”€ api/               # FastAPI è·¯ç”±
â”‚   â”‚   â”œâ”€â”€ core/              # æ ¸å¿ƒé…ç½®ï¼ˆconfig, databaseï¼‰
â”‚   â”‚   â”œâ”€â”€ models/            # SQLAlchemy æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ services/          # ä¸šåŠ¡æœåŠ¡ï¼ˆLLM, Embedding, Analysisï¼‰
â”‚   â”‚   â”œâ”€â”€ storage/           # å­˜å‚¨å°è£…ï¼ˆMilvusï¼‰
â”‚   â”‚   â””â”€â”€ tools/             # AgenticX å·¥å…·ï¼ˆCrawler, Cleanerï¼‰
â”‚   â”œâ”€â”€ requirements.txt       # Python ä¾èµ–
â”‚   â””â”€â”€ start.sh              # å¯åŠ¨è„šæœ¬
â”œâ”€â”€ deploy/                    # éƒ¨ç½²é…ç½®
â”‚   â””â”€â”€ docker-compose.dev.yml # Docker Compose é…ç½®
â”œâ”€â”€ frontend/                  # å‰ç«¯ç•Œé¢ï¼ˆMVPï¼‰
â”‚   â””â”€â”€ index.html            # ç®€åŒ–ç‰ˆå‰ç«¯
â””â”€â”€ legacy_v1/                # åŸå§‹ä»£ç ï¼ˆå·²è¿ç§»ï¼‰
```

---

## ğŸ§ª æµ‹è¯•ä¸éªŒæ”¶

### MVP éªŒæ”¶æ ‡å‡†

- [x] æ–°é—»çˆ¬å–æˆåŠŸå¹¶å­˜å…¥ PostgreSQL
- [ ] NewsAnalyst è°ƒç”¨ LLM å®Œæˆåˆ†æ
- [ ] åˆ†æç»“æœåŒ…å«æƒ…æ„Ÿè¯„åˆ†
- [ ] å‰ç«¯èƒ½å¤Ÿå±•ç¤ºæ–°é—»å’Œåˆ†æç»“æœ

### æµ‹è¯•æµç¨‹

1. **å¯åŠ¨æ‰€æœ‰æœåŠ¡**
   ```bash
   ./start.sh
   ```

2. **æ£€æŸ¥ Docker å®¹å™¨çŠ¶æ€**
   ```bash
   docker ps
   # åº”çœ‹åˆ°: postgres, redis, milvus-standalone, milvus-etcd, milvus-minio
   ```

3. **æµ‹è¯•æ–°é—»çˆ¬å–**
   ```bash
   curl -X POST http://localhost:8000/api/v1/news/crawl \
     -H "Content-Type: application/json" \
     -d '{"source": "sina", "start_page": 1, "end_page": 1}'
   
   # ç­‰å¾… 5-10 ç§’åæŸ¥çœ‹ç»“æœ
   curl http://localhost:8000/api/v1/news/?limit=5
   ```

4. **æµ‹è¯•æ™ºèƒ½ä½“åˆ†æ**
   ```bash
   # è·å–ç¬¬ä¸€æ¡æ–°é—»çš„ID
   NEWS_ID=$(curl -s http://localhost:8000/api/v1/news/?limit=1 | jq '.[0].id')
   
   # è§¦å‘åˆ†æ
   curl -X POST http://localhost:8000/api/v1/analysis/news/$NEWS_ID
   
   # æŸ¥çœ‹åˆ†æç»“æœ
   curl http://localhost:8000/api/v1/analysis/1
   ```

5. **æµ‹è¯•å‰ç«¯ç•Œé¢**
   - æ‰“å¼€ `frontend/index.html`
   - ç‚¹å‡»"çˆ¬å–æ–°é—»"å¹¶ç­‰å¾…å®Œæˆ
   - é€‰æ‹©ä¸€æ¡æ–°é—»ç‚¹å‡»"åˆ†æ"
   - æŸ¥çœ‹æƒ…æ„Ÿè¯„åˆ†æ˜¯å¦æ˜¾ç¤º

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: æ•°æ®åº“è¿æ¥å¤±è´¥

```bash
# æ£€æŸ¥ PostgreSQL æ˜¯å¦å¯åŠ¨
docker ps | grep postgres

# æŸ¥çœ‹æ—¥å¿—
docker logs finnews_postgres

# é‡å¯å®¹å™¨
docker-compose -f deploy/docker-compose.dev.yml restart postgres
```

### é—®é¢˜ 2: LLM è°ƒç”¨å¤±è´¥

æ£€æŸ¥ `.env` æ–‡ä»¶ä¸­çš„ API Key é…ç½®ï¼š
```bash
# ç¡®ä¿è®¾ç½®äº† OPENAI_API_KEY
grep OPENAI_API_KEY backend/.env
```

### é—®é¢˜ 3: Milvus è¿æ¥å¤±è´¥

```bash
# Milvus éœ€è¦è¾ƒé•¿å¯åŠ¨æ—¶é—´ï¼ˆçº¦ 60 ç§’ï¼‰
docker logs finnews_milvus

# ç­‰å¾…å¥åº·æ£€æŸ¥é€šè¿‡
docker inspect finnews_milvus | grep Health
```

### é—®é¢˜ 4: å‰ç«¯ CORS é”™è¯¯

ç¡®ä¿åç«¯ `core/config.py` ä¸­çš„ CORS é…ç½®åŒ…å«å‰ç«¯åœ°å€ï¼š
```python
BACKEND_CORS_ORIGINS = ["http://localhost:3000", "http://localhost:8000"]
```

---

## ğŸ“Š æ•°æ®åº“ç»“æ„

### Newsï¼ˆæ–°é—»è¡¨ï¼‰
- id, title, content, url, source
- publish_time, stock_codes
- sentiment_score, is_embedded

### Analysisï¼ˆåˆ†æè¡¨ï¼‰
- id, news_id, agent_name
- sentiment, sentiment_score, confidence
- analysis_result, structured_data

### Stockï¼ˆè‚¡ç¥¨è¡¨ï¼‰
- id, code, name, industry, market

---

## ğŸ› ï¸ å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„çˆ¬è™«

1. ç»§æ‰¿ `BaseCrawler` ç±»
2. å®ç° `crawl()` æ–¹æ³•
3. æ³¨å†Œåˆ° `tools/__init__.py`

ç¤ºä¾‹ï¼š
```python
# backend/app/tools/custom_crawler.py
from .crawler_base import BaseCrawler

class CustomCrawlerTool(BaseCrawler):
    name = "custom_crawler"
    
    def crawl(self, start_page, end_page):
        # å®ç°çˆ¬å–é€»è¾‘
        pass
```

### æ·»åŠ æ–°çš„æ™ºèƒ½ä½“

1. ç»§æ‰¿ `Agent` ç±»
2. å®šä¹‰ roleã€goalã€backstory
3. å®ç°ä¸šåŠ¡æ–¹æ³•

ç¤ºä¾‹ï¼š
```python
# backend/app/agents/risk_analyst.py
from agenticx import Agent

class RiskAnalystAgent(Agent):
    def __init__(self, llm_provider):
        super().__init__(
            name="RiskAnalyst",
            role="é£é™©åˆ†æå¸ˆ",
            goal="è¯„ä¼°æŠ•èµ„é£é™©",
            llm_provider=llm_provider
        )
```

---

## ğŸ“ˆ è·¯çº¿å›¾

### Phase 1: MVPï¼ˆå·²å®Œæˆï¼‰ âœ…
- [x] é¡¹ç›®åŸºç¡€è®¾æ–½
- [x] æ•°æ®åº“æ¨¡å‹
- [x] çˆ¬è™«å·¥å…·é‡æ„
- [x] LLM æœåŠ¡é›†æˆ
- [x] NewsAnalyst æ™ºèƒ½ä½“
- [x] FastAPI è·¯ç”±
- [x] ç®€åŒ–ç‰ˆå‰ç«¯

### Phase 2: å¤šæ™ºèƒ½ä½“åä½œï¼ˆè®¡åˆ’ä¸­ï¼‰
- [ ] BullResearcher & BearResearcher æ™ºèƒ½ä½“
- [ ] åŸºäº `agenticx.collaboration.Debate` çš„è¾©è®ºå·¥ä½œæµ
- [ ] å®æ—¶ WebSocket æ¨é€
- [ ] æ™ºèƒ½ä½“æ‰§è¡Œè½¨è¿¹å¯è§†åŒ–

### Phase 3: çŸ¥è¯†å¢å¼ºï¼ˆè®¡åˆ’ä¸­ï¼‰
- [ ] é‡‘èçŸ¥è¯†å›¾è°±ï¼ˆNeo4jï¼‰
- [ ] æ™ºèƒ½ä½“è®°å¿†ç³»ç»Ÿ
- [ ] GraphRetriever å›¾æ£€ç´¢

### Phase 4: è‡ªæˆ‘è¿›åŒ–ï¼ˆè®¡åˆ’ä¸­ï¼‰
- [ ] ACE æ¡†æ¶é›†æˆ
- [ ] æŠ•èµ„ç­–ç•¥ Playbook
- [ ] å†³ç­–æ•ˆæœè¯„ä¼°ä¸å­¦ä¹ 

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ª AgenticX çš„è®¸å¯è¯ã€‚

---

## ğŸ™ è‡´è°¢

- [AgenticX](https://github.com/yourusername/AgenticX) - å¤šæ™ºèƒ½ä½“æ¡†æ¶
- [FastAPI](https://fastapi.tiangolo.com/) - Web æ¡†æ¶
- [Milvus](https://milvus.io/) - å‘é‡æ•°æ®åº“
- [é˜¿é‡Œäº‘ç™¾ç‚¼](https://dashscope.console.aliyun.com/) - LLM æœåŠ¡
- [Shadcn UI](https://ui.shadcn.com/) - å‰ç«¯ç»„ä»¶åº“

---

## â­ Star History

å¦‚æœä½ è§‰å¾—è¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œæ¬¢è¿ç»™ä¸ª Star â­ï¸ï¼

[![Star History Chart](https://api.star-history.com/svg?repos=DemonDamon/Listed-company-news-crawl-and-text-analysis&type=Date)](https://star-history.com/#DemonDamon/Listed-company-news-crawl-and-text-analysis&Date)

---

**Built with â¤ï¸ using AgenticX**

