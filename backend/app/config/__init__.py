"""
é…ç½®æ¨¡å—
"""
import os
from pathlib import Path
from typing import Dict, Any, Optional, List
import yaml
from pydantic import BaseModel, Field


# é…ç½®ç›®å½•
CONFIG_DIR = Path(__file__).parent


class AgentConfig(BaseModel):
    """æ™ºèƒ½ä½“é…ç½®"""
    name: str
    role: str
    description: str


class FlowStep(BaseModel):
    """æµç¨‹æ­¥éª¤é…ç½®"""
    name: str
    description: str
    parallel: bool = False
    agents: List[str] = Field(default_factory=list)
    type: Optional[str] = None
    max_rounds: Optional[int] = None


class FlowConfig(BaseModel):
    """æµç¨‹é…ç½®"""
    type: str
    steps: List[FlowStep]


class ModeRules(BaseModel):
    """æ¨¡å¼è§„åˆ™é…ç½®"""
    max_time: int = 300
    max_rounds: Optional[int] = None
    round_time_limit: Optional[int] = None
    manager_can_interrupt: bool = False
    require_news: bool = True
    require_financial: bool = True
    require_data_collection: bool = False
    early_decision: bool = False
    min_news_count: int = 0


class DebateRules(BaseModel):
    """è¾©è®ºè§„åˆ™é…ç½®"""
    opening_statement: bool = True
    rebuttal_required: bool = True
    evidence_required: bool = True
    interrupt_cooldown: int = 30


class DebateModeConfig(BaseModel):
    """è¾©è®ºæ¨¡å¼é…ç½®"""
    name: str
    description: str
    icon: str = "ğŸ“Š"
    agents: List[AgentConfig]
    flow: FlowConfig
    rules: ModeRules
    debate_rules: Optional[DebateRules] = None


class LLMConfig(BaseModel):
    """LLMé…ç½®"""
    default_provider: str = "bailian"
    default_model: str = "qwen-plus"
    temperature: float = 0.7
    max_tokens: int = 4096


class DataSourceConfig(BaseModel):
    """æ•°æ®æºé…ç½®"""
    type: str
    priority: int = 1


class DataSourcesConfig(BaseModel):
    """æ•°æ®æºé›†åˆé…ç½®"""
    news: List[DataSourceConfig] = Field(default_factory=list)
    financial: List[DataSourceConfig] = Field(default_factory=list)


class OutputConfig(BaseModel):
    """è¾“å‡ºé…ç½®"""
    format: str = "markdown"
    include_trajectory: bool = True
    include_timestamps: bool = True


class GlobalConfig(BaseModel):
    """å…¨å±€é…ç½®"""
    llm: LLMConfig = Field(default_factory=LLMConfig)
    data_sources: DataSourcesConfig = Field(default_factory=DataSourcesConfig)
    output: OutputConfig = Field(default_factory=OutputConfig)


class DebateModesConfig(BaseModel):
    """è¾©è®ºæ¨¡å¼æ€»é…ç½®"""
    default_mode: str = "parallel"
    modes: Dict[str, DebateModeConfig]
    global_config: GlobalConfig = Field(default_factory=GlobalConfig, alias="global")
    
    class Config:
        populate_by_name = True


def load_debate_modes_config() -> DebateModesConfig:
    """åŠ è½½è¾©è®ºæ¨¡å¼é…ç½®"""
    config_file = CONFIG_DIR / "debate_modes.yaml"
    
    if not config_file.exists():
        raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
    
    with open(config_file, "r", encoding="utf-8") as f:
        raw_config = yaml.safe_load(f)
    
    # å¤„ç† global å…³é”®å­—å†²çª
    if "global" in raw_config:
        raw_config["global_config"] = raw_config.pop("global")
    
    return DebateModesConfig(**raw_config)


def get_mode_config(mode_name: str) -> Optional[DebateModeConfig]:
    """è·å–æŒ‡å®šæ¨¡å¼çš„é…ç½®"""
    config = load_debate_modes_config()
    return config.modes.get(mode_name)


def get_available_modes() -> List[Dict[str, Any]]:
    """è·å–æ‰€æœ‰å¯ç”¨çš„æ¨¡å¼åˆ—è¡¨"""
    config = load_debate_modes_config()
    modes = []
    for mode_id, mode_config in config.modes.items():
        modes.append({
            "id": mode_id,
            "name": mode_config.name,
            "description": mode_config.description,
            "icon": mode_config.icon,
            "is_default": mode_id == config.default_mode
        })
    return modes


def get_default_mode() -> str:
    """è·å–é»˜è®¤æ¨¡å¼"""
    config = load_debate_modes_config()
    return config.default_mode


# å•ä¾‹ç¼“å­˜
_cached_config: Optional[DebateModesConfig] = None


def get_cached_config() -> DebateModesConfig:
    """è·å–ç¼“å­˜çš„é…ç½®ï¼ˆé¿å…é‡å¤è¯»å–æ–‡ä»¶ï¼‰"""
    global _cached_config
    if _cached_config is None:
        _cached_config = load_debate_modes_config()
    return _cached_config


def reload_config() -> DebateModesConfig:
    """é‡æ–°åŠ è½½é…ç½®"""
    global _cached_config
    _cached_config = load_debate_modes_config()
    return _cached_config

