"""
æ™ºèƒ½ä½“ API è·¯ç”± - Phase 2
æä¾›è¾©è®ºåŠŸèƒ½ã€æ‰§è¡Œæ—¥å¿—ã€æ€§èƒ½ç›‘æ§ç­‰æ¥å£
"""
import logging
import json
import asyncio
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any, AsyncGenerator
from fastapi import APIRouter, Depends, HTTPException, Query, Body
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, desc, or_

from ...core.database import get_db
from ...models.news import News
from ...models.analysis import Analysis
from ...agents.debate_agents import create_debate_workflow
from ...agents.orchestrator import create_orchestrator
from ...services.llm_service import get_llm_provider
from ...services.stock_data_service import stock_data_service

logger = logging.getLogger(__name__)

router = APIRouter()


# ============ æ¨¡æ‹Ÿæ•°æ®å­˜å‚¨ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ•°æ®åº“ï¼‰ ============

# å­˜å‚¨æ‰§è¡Œæ—¥å¿—
execution_logs: List[Dict[str, Any]] = []

# å­˜å‚¨è¾©è®ºç»“æœ
debate_results: Dict[str, Dict[str, Any]] = {}


# ============ Pydantic æ¨¡å‹ ============

class DebateRequest(BaseModel):
    """è¾©è®ºè¯·æ±‚"""
    stock_code: str = Field(..., description="è‚¡ç¥¨ä»£ç ")
    stock_name: Optional[str] = Field(None, description="è‚¡ç¥¨åç§°")
    context: Optional[str] = Field(None, description="é¢å¤–èƒŒæ™¯ä¿¡æ¯")
    provider: Optional[str] = Field(None, description="LLMæä¾›å•†")
    model: Optional[str] = Field(None, description="æ¨¡å‹åç§°")
    mode: Optional[str] = Field("parallel", description="è¾©è®ºæ¨¡å¼: parallel, realtime_debate, quick_analysis")


class DebateResponse(BaseModel):
    """è¾©è®ºå“åº”"""
    success: bool
    debate_id: Optional[str] = None
    stock_code: str
    stock_name: Optional[str] = None
    mode: Optional[str] = None  # è¾©è®ºæ¨¡å¼
    bull_analysis: Optional[Dict[str, Any]] = None
    bear_analysis: Optional[Dict[str, Any]] = None
    final_decision: Optional[Dict[str, Any]] = None
    quick_analysis: Optional[Dict[str, Any]] = None  # å¿«é€Ÿåˆ†æç»“æœ
    debate_history: Optional[List[Dict[str, Any]]] = None  # å®æ—¶è¾©è®ºå†å²
    trajectory: Optional[List[Dict[str, Any]]] = None
    execution_time: Optional[float] = None
    error: Optional[str] = None


class AgentLogEntry(BaseModel):
    """æ™ºèƒ½ä½“æ—¥å¿—æ¡ç›®"""
    id: str
    timestamp: str
    agent_name: str
    agent_role: Optional[str] = None
    action: str
    status: str  # "started", "completed", "failed"
    details: Optional[Dict[str, Any]] = None
    execution_time: Optional[float] = None


class AgentMetrics(BaseModel):
    """æ™ºèƒ½ä½“æ€§èƒ½æŒ‡æ ‡"""
    total_executions: int
    successful_executions: int
    failed_executions: int
    avg_execution_time: float
    agent_stats: Dict[str, Dict[str, Any]]
    recent_activity: List[Dict[str, Any]]


class TrajectoryStep(BaseModel):
    """æ‰§è¡Œè½¨è¿¹æ­¥éª¤"""
    step_id: str
    step_name: str
    timestamp: str
    agent_name: Optional[str] = None
    input_data: Optional[Dict[str, Any]] = None
    output_data: Optional[Dict[str, Any]] = None
    duration: Optional[float] = None
    status: str


# ============ API ç«¯ç‚¹ ============

@router.post("/debate", response_model=DebateResponse)
async def run_stock_debate(
    request: DebateRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    è§¦å‘è‚¡ç¥¨è¾©è®ºåˆ†æï¼ˆBull vs Bearï¼‰
    
    - **stock_code**: è‚¡ç¥¨ä»£ç 
    - **stock_name**: è‚¡ç¥¨åç§°ï¼ˆå¯é€‰ï¼‰
    - **context**: é¢å¤–èƒŒæ™¯ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
    - **provider**: LLMæä¾›å•†ï¼ˆå¯é€‰ï¼‰
    - **model**: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
    """
    logger.info(f"ğŸ¯ æ”¶åˆ°è¾©è®ºè¯·æ±‚: stock_code={request.stock_code}, stock_name={request.stock_name}")
    
    start_time = datetime.utcnow()
    debate_id = f"debate_{start_time.strftime('%Y%m%d%H%M%S')}_{request.stock_code}"
    
    try:
        # è®°å½•å¼€å§‹
        log_entry = {
            "id": debate_id,
            "timestamp": start_time.isoformat(),
            "agent_name": "DebateWorkflow",
            "action": "debate_start",
            "status": "started",
            "details": {
                "stock_code": request.stock_code,
                "stock_name": request.stock_name
            }
        }
        execution_logs.append(log_entry)
        
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        code = request.stock_code.upper()
        if code.startswith("SH") or code.startswith("SZ"):
            short_code = code[2:]
        else:
            short_code = code
            code = f"SH{code}" if code.startswith("6") else f"SZ{code}"
        
        logger.info(f"ğŸ” æŸ¥è¯¢è‚¡ç¥¨ {code} çš„å…³è”æ–°é—»...")
        
        # è·å–å…³è”æ–°é—» - ä½¿ç”¨ PostgreSQL åŸç”Ÿ ARRAY æŸ¥è¯¢è¯­æ³•
        from sqlalchemy import text
        stock_codes_filter = text(
            "stock_codes @> ARRAY[:code1]::varchar[] OR stock_codes @> ARRAY[:code2]::varchar[]"
        ).bindparams(code1=short_code, code2=code)
        
        news_query = select(News).where(stock_codes_filter).order_by(desc(News.publish_time)).limit(10)
        
        result = await db.execute(news_query)
        news_list = result.scalars().all()
        
        logger.info(f"ğŸ“° æ‰¾åˆ° {len(news_list)} æ¡å…³è”æ–°é—»")
        
        news_data = [
            {
                "id": n.id,
                "title": n.title,
                "content": n.content[:500],
                "sentiment_score": n.sentiment_score,
                "publish_time": n.publish_time.isoformat() if n.publish_time else None
            }
            for n in news_list
        ]
        
        # å¦‚æœæ²¡æœ‰å…³è”æ–°é—»ï¼Œç»™å‡ºè­¦å‘Š
        if not news_data:
            logger.warning(f"âš ï¸ è‚¡ç¥¨ {code} æ²¡æœ‰å…³è”æ–°é—»ï¼Œè¾©è®ºå°†åŸºäºç©ºæ•°æ®è¿›è¡Œ")
        
        # è·å–è´¢åŠ¡æ•°æ®å’Œèµ„é‡‘æµå‘ï¼ˆç”¨äºå¢å¼ºè¾©è®ºä¸Šä¸‹æ–‡ï¼‰
        logger.info(f"ğŸ“Š è·å– {code} çš„è´¢åŠ¡æ•°æ®å’Œèµ„é‡‘æµå‘...")
        try:
            debate_context = await stock_data_service.get_debate_context(code)
            akshare_context = debate_context.get("summary", "")
            logger.info(f"ğŸ“Š è·å–åˆ°é¢å¤–æ•°æ®: {akshare_context[:100]}...")
        except Exception as e:
            logger.warning(f"âš ï¸ è·å–è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
            akshare_context = ""
        
        # åˆå¹¶ç”¨æˆ·æä¾›çš„ä¸Šä¸‹æ–‡å’Œ akshare æ•°æ®
        full_context = ""
        if request.context:
            full_context += f"ã€ç”¨æˆ·è¡¥å……ä¿¡æ¯ã€‘\n{request.context}\n\n"
        if akshare_context:
            full_context += f"ã€å®æ—¶æ•°æ®ã€‘\n{akshare_context}"
        
        # åˆ›å»º LLM providerï¼ˆå¦‚æœæŒ‡å®šäº†è‡ªå®šä¹‰é…ç½®ï¼‰
        llm_provider = None
        if request.provider or request.model:
            logger.info(f"ğŸ¤– ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹: provider={request.provider}, model={request.model}")
            llm_provider = get_llm_provider(
                provider=request.provider,
                model=request.model
            )
        else:
            logger.info("ğŸ¤– ä½¿ç”¨é»˜è®¤ LLM é…ç½®")
        
        # é€‰æ‹©è¾©è®ºæ¨¡å¼
        mode = request.mode or "parallel"
        logger.info(f"âš”ï¸ å¼€å§‹è¾©è®ºå·¥ä½œæµï¼Œæ¨¡å¼: {mode}")
        
        if mode == "parallel":
            # ä½¿ç”¨åŸæœ‰çš„å¹¶è¡Œå·¥ä½œæµ
            workflow = create_debate_workflow(llm_provider)
            debate_result = await workflow.run_debate(
                stock_code=code,
                stock_name=request.stock_name or code,
                news_list=news_data,
                context=full_context
            )
        else:
            # ä½¿ç”¨æ–°çš„ç¼–æ’å™¨ï¼ˆæ”¯æŒ realtime_debate å’Œ quick_analysisï¼‰
            orchestrator = create_orchestrator(mode=mode, llm_provider=llm_provider)
            debate_result = await orchestrator.run(
                stock_code=code,
                stock_name=request.stock_name or code,
                context=full_context,
                news_list=news_data
            )
        
        end_time = datetime.utcnow()
        execution_time = (end_time - start_time).total_seconds()
        
        # å­˜å‚¨ç»“æœ
        debate_results[debate_id] = debate_result
        
        # è®°å½•å®Œæˆ
        log_entry = {
            "id": f"{debate_id}_complete",
            "timestamp": end_time.isoformat(),
            "agent_name": "DebateWorkflow",
            "action": "debate_complete",
            "status": "completed" if debate_result.get("success") else "failed",
            "details": {
                "stock_code": request.stock_code,
                "rating": debate_result.get("final_decision", {}).get("rating", "unknown")
            },
            "execution_time": execution_time
        }
        execution_logs.append(log_entry)
        
        if debate_result.get("success"):
            return DebateResponse(
                success=True,
                debate_id=debate_id,
                stock_code=code,
                stock_name=request.stock_name,
                mode=mode,
                bull_analysis=debate_result.get("bull_analysis"),
                bear_analysis=debate_result.get("bear_analysis"),
                final_decision=debate_result.get("final_decision"),
                quick_analysis=debate_result.get("quick_analysis"),
                debate_history=debate_result.get("debate_history"),
                trajectory=debate_result.get("trajectory"),
                execution_time=execution_time
            )
        else:
            return DebateResponse(
                success=False,
                debate_id=debate_id,
                stock_code=code,
                mode=mode,
                error=debate_result.get("error", "Unknown error")
            )
    
    except Exception as e:
        logger.error(f"Debate failed: {e}", exc_info=True)
        
        # è®°å½•å¤±è´¥
        log_entry = {
            "id": f"{debate_id}_error",
            "timestamp": datetime.utcnow().isoformat(),
            "agent_name": "DebateWorkflow",
            "action": "debate_error",
            "status": "failed",
            "details": {"error": str(e)}
        }
        execution_logs.append(log_entry)
        
        return DebateResponse(
            success=False,
            debate_id=debate_id,
            stock_code=request.stock_code,
            error=str(e)
        )


# ============ SSE æµå¼è¾©è®º ============

async def generate_debate_stream(
    stock_code: str,
    stock_name: str,
    mode: str,
    context: str,
    news_data: List[Dict],
    llm_provider
) -> AsyncGenerator[str, None]:
    """
    ç”Ÿæˆè¾©è®ºçš„ SSE æµ
    
    äº‹ä»¶ç±»å‹:
    - phase: é˜¶æ®µå˜åŒ–
    - agent: æ™ºèƒ½ä½“å‘è¨€
    - progress: è¿›åº¦æ›´æ–°
    - result: æœ€ç»ˆç»“æœ
    - error: é”™è¯¯ä¿¡æ¯
    """
    debate_id = f"debate_{datetime.utcnow().strftime('%Y%m%d%H%M%S')}"
    
    def sse_event(event_type: str, data: Dict) -> str:
        """æ ¼å¼åŒ– SSE äº‹ä»¶"""
        return f"event: {event_type}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"
    
    try:
        # å‘é€å¼€å§‹äº‹ä»¶
        yield sse_event("phase", {
            "phase": "start",
            "message": f"å¼€å§‹{mode}æ¨¡å¼åˆ†æ",
            "debate_id": debate_id
        })
        
        if mode == "quick_analysis":
            # å¿«é€Ÿåˆ†ææ¨¡å¼ - ä½¿ç”¨æµå¼è¾“å‡º
            yield sse_event("phase", {"phase": "analyzing", "message": "å¿«é€Ÿåˆ†æå¸ˆæ­£åœ¨åˆ†æ..."})
            
            prompt = f"""è¯·å¯¹ {stock_name}({stock_code}) è¿›è¡Œå¿«é€ŸæŠ•èµ„åˆ†æã€‚

èƒŒæ™¯èµ„æ–™:
{context[:2000]}

ç›¸å…³æ–°é—»:
{json.dumps([n.get('title', '') for n in news_data[:5]], ensure_ascii=False)}

è¯·å¿«é€Ÿç»™å‡ºï¼š
1. æ ¸å¿ƒè§‚ç‚¹ï¼ˆä¸€å¥è¯ï¼‰
2. çœ‹å¤šå› ç´ ï¼ˆ3ç‚¹ï¼‰
3. çœ‹ç©ºå› ç´ ï¼ˆ3ç‚¹ï¼‰
4. æŠ•èµ„å»ºè®®ï¼ˆä¹°å…¥/æŒæœ‰/å–å‡ºï¼‰
5. é£é™©æç¤º"""
            
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‚¡ç¥¨åˆ†æå¸ˆï¼Œæ“…é•¿å¿«é€Ÿåˆ†æå’Œå†³ç­–ã€‚"},
                {"role": "user", "content": prompt}
            ]
            
            full_response = ""
            for chunk in llm_provider.stream(messages):
                full_response += chunk
                yield sse_event("agent", {
                    "agent": "QuickAnalyst",
                    "role": "å¿«é€Ÿåˆ†æå¸ˆ",
                    "content": chunk,
                    "is_chunk": True
                })
                await asyncio.sleep(0)  # è®©å‡ºæ§åˆ¶æƒ
            
            # å‘é€å®Œæˆäº‹ä»¶
            yield sse_event("result", {
                "success": True,
                "mode": mode,
                "quick_analysis": {
                    "analysis": full_response,
                    "success": True
                },
                "execution_time": 0
            })
            
        elif mode == "realtime_debate":
            # å®æ—¶è¾©è®ºæ¨¡å¼ - å¤šè½®äº¤é”‹
            max_rounds = 3  # æœ€å¤§è¾©è®ºè½®æ•°
            
            yield sse_event("phase", {"phase": "data_collection", "message": "æ•°æ®ä¸“å‘˜æ­£åœ¨æœé›†èµ„æ–™..."})
            await asyncio.sleep(0.3)
            
            # æ•°æ®æœé›†
            yield sse_event("agent", {
                "agent": "DataCollector",
                "role": "æ•°æ®ä¸“å‘˜",
                "content": f"ğŸ“Š å·²æœé›† {stock_name} çš„ç›¸å…³æ•°æ®ï¼š{len(news_data)} æ¡æ–°é—»ï¼Œè´¢åŠ¡æ•°æ®å·²å°±ç»ªã€‚\n\nè¾©è®ºå³å°†å¼€å§‹ï¼Œå…± {max_rounds} è½®ã€‚",
                "is_chunk": False
            })
            
            # è¾©è®ºå†å²ï¼ˆç”¨äºä¸Šä¸‹æ–‡ï¼‰
            debate_history = []
            bull_full = ""
            bear_full = ""
            
            # å¤šè½®è¾©è®º
            for round_num in range(1, max_rounds + 1):
                yield sse_event("phase", {
                    "phase": "debate",
                    "message": f"ç¬¬ {round_num}/{max_rounds} è½®è¾©è®º",
                    "round": round_num,
                    "max_rounds": max_rounds
                })
                
                # === Bull å‘è¨€ ===
                yield sse_event("agent", {
                    "agent": "BullResearcher",
                    "role": "çœ‹å¤šç ”ç©¶å‘˜",
                    "content": "",
                    "is_start": True,
                    "round": round_num
                })
                
                if round_num == 1:
                    # ç¬¬ä¸€è½®ï¼šå¼€åœºé™ˆè¿°
                    bull_prompt = f"""ä½ æ˜¯çœ‹å¤šç ”ç©¶å‘˜ï¼Œæ­£åœ¨å‚ä¸å…³äº {stock_name}({stock_code}) çš„å¤šç©ºè¾©è®ºã€‚

èƒŒæ™¯èµ„æ–™: {context[:800]}
æ–°é—»: {json.dumps([n.get('title', '') for n in news_data[:3]], ensure_ascii=False)}

è¿™æ˜¯ç¬¬1è½®è¾©è®ºï¼Œè¯·åšå¼€åœºé™ˆè¿°ï¼ˆçº¦150å­—ï¼‰ï¼š
1. è¡¨æ˜ä½ çš„æ ¸å¿ƒçœ‹å¤šè§‚ç‚¹
2. ç»™å‡º2-3ä¸ªå…³é”®è®ºæ®"""
                else:
                    # åç»­è½®æ¬¡ï¼šåé©³å¯¹æ–¹
                    last_bear = debate_history[-1]["content"] if debate_history else ""
                    bull_prompt = f"""ä½ æ˜¯çœ‹å¤šç ”ç©¶å‘˜ï¼Œæ­£åœ¨ä¸çœ‹ç©ºç ”ç©¶å‘˜è¾©è®º {stock_name}ã€‚

è¿™æ˜¯ç¬¬{round_num}è½®è¾©è®ºã€‚

å¯¹æ–¹ï¼ˆçœ‹ç©ºç ”ç©¶å‘˜ï¼‰åˆšæ‰è¯´ï¼š
"{last_bear[:300]}"

è¯·åé©³å¯¹æ–¹è§‚ç‚¹å¹¶è¡¥å……æ–°è®ºæ®ï¼ˆçº¦120å­—ï¼‰ï¼š
1. æŒ‡å‡ºå¯¹æ–¹è®ºæ®çš„æ¼æ´
2. è¡¥å……æ–°çš„çœ‹å¤šç†ç”±"""
                
                bull_messages = [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½è¾©è®ºä¸­çš„çœ‹å¤šç ”ç©¶å‘˜ã€‚è¨€ç®€æ„èµ…ï¼Œæœ‰ç†æœ‰æ®ï¼Œè¯­æ°”è‡ªä¿¡ä½†ä¸å‚²æ…¢ã€‚"},
                    {"role": "user", "content": bull_prompt}
                ]
                
                bull_response = ""
                for chunk in llm_provider.stream(bull_messages):
                    bull_response += chunk
                    yield sse_event("agent", {
                        "agent": "BullResearcher",
                        "role": "çœ‹å¤šç ”ç©¶å‘˜",
                        "content": chunk,
                        "is_chunk": True,
                        "round": round_num
                    })
                    await asyncio.sleep(0)
                
                bull_full += f"\n\n**ã€ç¬¬{round_num}è½®ã€‘**\n{bull_response}"
                debate_history.append({"agent": "Bull", "round": round_num, "content": bull_response})
                
                yield sse_event("agent", {
                    "agent": "BullResearcher",
                    "role": "çœ‹å¤šç ”ç©¶å‘˜",
                    "content": "",
                    "is_end": True,
                    "round": round_num
                })
                
                # === Bear å‘è¨€ï¼ˆåé©³ï¼‰ ===
                yield sse_event("agent", {
                    "agent": "BearResearcher",
                    "role": "çœ‹ç©ºç ”ç©¶å‘˜",
                    "content": "",
                    "is_start": True,
                    "round": round_num
                })
                
                if round_num == 1:
                    bear_prompt = f"""ä½ æ˜¯çœ‹ç©ºç ”ç©¶å‘˜ï¼Œæ­£åœ¨ä¸çœ‹å¤šç ”ç©¶å‘˜è¾©è®º {stock_name}({stock_code})ã€‚

èƒŒæ™¯èµ„æ–™: {context[:800]}

å¯¹æ–¹ï¼ˆçœ‹å¤šç ”ç©¶å‘˜ï¼‰åˆšæ‰è¯´ï¼š
"{bull_response[:300]}"

è¿™æ˜¯ç¬¬1è½®è¾©è®ºï¼Œè¯·åé©³å¯¹æ–¹å¹¶é™ˆè¿°ä½ çš„çœ‹ç©ºè§‚ç‚¹ï¼ˆçº¦150å­—ï¼‰ï¼š
1. æŒ‡å‡ºå¯¹æ–¹è®ºæ®çš„é—®é¢˜
2. ç»™å‡º2-3ä¸ªé£é™©å› ç´ """
                else:
                    bear_prompt = f"""ä½ æ˜¯çœ‹ç©ºç ”ç©¶å‘˜ï¼Œæ­£åœ¨ä¸çœ‹å¤šç ”ç©¶å‘˜è¾©è®º {stock_name}ã€‚

è¿™æ˜¯ç¬¬{round_num}è½®è¾©è®ºã€‚

å¯¹æ–¹ï¼ˆçœ‹å¤šç ”ç©¶å‘˜ï¼‰åˆšæ‰è¯´ï¼š
"{bull_response[:300]}"

è¯·åé©³å¯¹æ–¹è§‚ç‚¹å¹¶è¡¥å……æ–°è®ºæ®ï¼ˆçº¦120å­—ï¼‰ï¼š
1. é©³æ–¥å¯¹æ–¹çš„æ–°è®ºæ®
2. å¼ºåŒ–ä½ çš„é£é™©è­¦ç¤º"""
                
                bear_messages = [
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½è¾©è®ºä¸­çš„çœ‹ç©ºç ”ç©¶å‘˜ã€‚è¨€ç®€æ„èµ…ï¼Œå–„äºå‘ç°é£é™©ï¼Œè¯­æ°”è°¨æ…ä½†æœ‰è¯´æœåŠ›ã€‚"},
                    {"role": "user", "content": bear_prompt}
                ]
                
                bear_response = ""
                for chunk in llm_provider.stream(bear_messages):
                    bear_response += chunk
                    yield sse_event("agent", {
                        "agent": "BearResearcher",
                        "role": "çœ‹ç©ºç ”ç©¶å‘˜",
                        "content": chunk,
                        "is_chunk": True,
                        "round": round_num
                    })
                    await asyncio.sleep(0)
                
                bear_full += f"\n\n**ã€ç¬¬{round_num}è½®ã€‘**\n{bear_response}"
                debate_history.append({"agent": "Bear", "round": round_num, "content": bear_response})
                
                yield sse_event("agent", {
                    "agent": "BearResearcher",
                    "role": "çœ‹ç©ºç ”ç©¶å‘˜",
                    "content": "",
                    "is_end": True,
                    "round": round_num
                })
            
            # === æŠ•èµ„ç»ç†æ€»ç»“å†³ç­– ===
            yield sse_event("phase", {"phase": "decision", "message": "è¾©è®ºç»“æŸï¼ŒæŠ•èµ„ç»ç†æ­£åœ¨åšæœ€ç»ˆå†³ç­–..."})
            
            yield sse_event("agent", {
                "agent": "InvestmentManager",
                "role": "æŠ•èµ„ç»ç†",
                "content": "",
                "is_start": True
            })
            
            # æ•´ç†è¾©è®ºå†å²
            debate_summary = "\n".join([
                f"ã€ç¬¬{h['round']}è½®-{'çœ‹å¤š' if h['agent']=='Bull' else 'çœ‹ç©º'}ã€‘{h['content'][:150]}..."
                for h in debate_history
            ])
            
            decision_prompt = f"""ä½ æ˜¯æŠ•èµ„ç»ç†ï¼Œåˆšåˆšä¸»æŒäº†ä¸€åœºå…³äº {stock_name}({stock_code}) çš„å¤šç©ºè¾©è®ºã€‚

è¾©è®ºå›é¡¾ï¼š
{debate_summary}

è¯·åšå‡ºæœ€ç»ˆæŠ•èµ„å†³ç­–ï¼ˆçº¦200å­—ï¼‰ï¼š
1. è¯„ä»·åŒæ–¹è¾©è®ºè¡¨ç°
2. æŒ‡å‡ºæœ€æœ‰è¯´æœåŠ›çš„è®ºç‚¹
3. **æœ€ç»ˆè¯„çº§**ï¼š[å¼ºçƒˆæ¨è/æ¨è/ä¸­æ€§/è°¨æ…/å›é¿]
4. ç»™å‡ºæ“ä½œå»ºè®®"""
            
            decision_messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æŠ•èµ„ç»ç†ï¼Œå–„äºåœ¨å¤šç©ºè§‚ç‚¹ä¸­åšå‡ºç†æ€§å†³ç­–ã€‚"},
                {"role": "user", "content": decision_prompt}
            ]
            
            decision = ""
            for chunk in llm_provider.stream(decision_messages):
                decision += chunk
                yield sse_event("agent", {
                    "agent": "InvestmentManager",
                    "role": "æŠ•èµ„ç»ç†",
                    "content": chunk,
                    "is_chunk": True
                })
                await asyncio.sleep(0)
            
            yield sse_event("agent", {
                "agent": "InvestmentManager",
                "role": "æŠ•èµ„ç»ç†",
                "content": "",
                "is_end": True
            })
            
            # æå–è¯„çº§
            rating = "ä¸­æ€§"
            for r in ["å¼ºçƒˆæ¨è", "æ¨è", "ä¸­æ€§", "è°¨æ…", "å›é¿"]:
                if r in decision:
                    rating = r
                    break
            
            # å‘é€å®Œæˆäº‹ä»¶
            yield sse_event("result", {
                "success": True,
                "mode": mode,
                "debate_id": debate_id,
                "total_rounds": max_rounds,
                "bull_analysis": {"analysis": bull_full.strip(), "success": True, "agent_name": "BullResearcher", "agent_role": "çœ‹å¤šç ”ç©¶å‘˜"},
                "bear_analysis": {"analysis": bear_full.strip(), "success": True, "agent_name": "BearResearcher", "agent_role": "çœ‹ç©ºç ”ç©¶å‘˜"},
                "final_decision": {"decision": decision, "rating": rating, "success": True, "agent_name": "InvestmentManager", "agent_role": "æŠ•èµ„ç»ç†"},
                "debate_history": debate_history
            })
            
        else:
            # parallel æ¨¡å¼ - ä¹Ÿä½¿ç”¨æµå¼ï¼Œä½†å¹¶è¡Œå±•ç¤º
            yield sse_event("phase", {"phase": "parallel_analysis", "message": "Bull/Bear å¹¶è¡Œåˆ†æä¸­..."})
            
            # ç”±äºæ˜¯å¹¶è¡Œï¼Œæˆ‘ä»¬äº¤æ›¿è¾“å‡º
            bull_prompt = f"""ä½ æ˜¯çœ‹å¤šç ”ç©¶å‘˜ï¼Œè¯·ä»ç§¯æè§’åº¦åˆ†æ {stock_name}({stock_code})ï¼š
èƒŒæ™¯èµ„æ–™: {context[:1500]}
æ–°é—»: {json.dumps([n.get('title', '') for n in news_data[:5]], ensure_ascii=False)}
è¯·ç»™å‡ºå®Œæ•´çš„çœ‹å¤šåˆ†ææŠ¥å‘Šã€‚"""

            bear_prompt = f"""ä½ æ˜¯çœ‹ç©ºç ”ç©¶å‘˜ï¼Œè¯·ä»é£é™©è§’åº¦åˆ†æ {stock_name}({stock_code})ï¼š
èƒŒæ™¯èµ„æ–™: {context[:1500]}
æ–°é—»: {json.dumps([n.get('title', '') for n in news_data[:5]], ensure_ascii=False)}
è¯·ç»™å‡ºå®Œæ•´çš„çœ‹ç©ºåˆ†ææŠ¥å‘Šã€‚"""

            # Bull æµå¼è¾“å‡º
            yield sse_event("agent", {"agent": "BullResearcher", "role": "çœ‹å¤šç ”ç©¶å‘˜", "content": "", "is_start": True})
            bull_analysis = ""
            for chunk in llm_provider.stream([
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¹è§‚ä½†ç†æ€§çš„è‚¡ç¥¨ç ”ç©¶å‘˜ã€‚"},
                {"role": "user", "content": bull_prompt}
            ]):
                bull_analysis += chunk
                yield sse_event("agent", {"agent": "BullResearcher", "role": "çœ‹å¤šç ”ç©¶å‘˜", "content": chunk, "is_chunk": True})
                await asyncio.sleep(0)
            yield sse_event("agent", {"agent": "BullResearcher", "role": "çœ‹å¤šç ”ç©¶å‘˜", "content": "", "is_end": True})
            
            # Bear æµå¼è¾“å‡º
            yield sse_event("agent", {"agent": "BearResearcher", "role": "çœ‹ç©ºç ”ç©¶å‘˜", "content": "", "is_start": True})
            bear_analysis = ""
            for chunk in llm_provider.stream([
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½è°¨æ…çš„è‚¡ç¥¨ç ”ç©¶å‘˜ã€‚"},
                {"role": "user", "content": bear_prompt}
            ]):
                bear_analysis += chunk
                yield sse_event("agent", {"agent": "BearResearcher", "role": "çœ‹ç©ºç ”ç©¶å‘˜", "content": chunk, "is_chunk": True})
                await asyncio.sleep(0)
            yield sse_event("agent", {"agent": "BearResearcher", "role": "çœ‹ç©ºç ”ç©¶å‘˜", "content": "", "is_end": True})
            
            # æŠ•èµ„ç»ç†å†³ç­–
            yield sse_event("phase", {"phase": "decision", "message": "æŠ•èµ„ç»ç†å†³ç­–ä¸­..."})
            yield sse_event("agent", {"agent": "InvestmentManager", "role": "æŠ•èµ„ç»ç†", "content": "", "is_start": True})
            
            decision_prompt = f"""ç»¼åˆä»¥ä¸‹å¤šç©ºè§‚ç‚¹ï¼Œå¯¹ {stock_name} åšå‡ºæŠ•èµ„å†³ç­–ï¼š
ã€çœ‹å¤šã€‘{bull_analysis[:800]}
ã€çœ‹ç©ºã€‘{bear_analysis[:800]}
è¯·ç»™å‡ºè¯„çº§[å¼ºçƒˆæ¨è/æ¨è/ä¸­æ€§/è°¨æ…/å›é¿]å’Œå†³ç­–ç†ç”±ã€‚"""
            
            decision = ""
            for chunk in llm_provider.stream([
                {"role": "system", "content": "ä½ æ˜¯æŠ•èµ„ç»ç†ã€‚"},
                {"role": "user", "content": decision_prompt}
            ]):
                decision += chunk
                yield sse_event("agent", {"agent": "InvestmentManager", "role": "æŠ•èµ„ç»ç†", "content": chunk, "is_chunk": True})
                await asyncio.sleep(0)
            yield sse_event("agent", {"agent": "InvestmentManager", "role": "æŠ•èµ„ç»ç†", "content": "", "is_end": True})
            
            rating = "ä¸­æ€§"
            for r in ["å¼ºçƒˆæ¨è", "æ¨è", "ä¸­æ€§", "è°¨æ…", "å›é¿"]:
                if r in decision:
                    rating = r
                    break
            
            yield sse_event("result", {
                "success": True,
                "mode": mode,
                "bull_analysis": {"analysis": bull_analysis, "success": True, "agent_name": "BullResearcher", "agent_role": "çœ‹å¤šç ”ç©¶å‘˜"},
                "bear_analysis": {"analysis": bear_analysis, "success": True, "agent_name": "BearResearcher", "agent_role": "çœ‹ç©ºç ”ç©¶å‘˜"},
                "final_decision": {"decision": decision, "rating": rating, "success": True, "agent_name": "InvestmentManager", "agent_role": "æŠ•èµ„ç»ç†"}
            })
        
        yield sse_event("phase", {"phase": "complete", "message": "åˆ†æå®Œæˆ"})
        
    except Exception as e:
        logger.error(f"SSE Debate error: {e}", exc_info=True)
        yield sse_event("error", {"message": str(e)})


@router.post("/debate/stream")
async def run_stock_debate_stream(
    request: DebateRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    æµå¼è¾©è®ºåˆ†æï¼ˆSSEï¼‰
    
    ä½¿ç”¨ Server-Sent Events å®æ—¶æ¨é€è¾©è®ºè¿‡ç¨‹
    """
    logger.info(f"ğŸ¯ æ”¶åˆ°æµå¼è¾©è®ºè¯·æ±‚: stock_code={request.stock_code}, mode={request.mode}")
    
    # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
    code = request.stock_code.upper()
    if code.startswith("SH") or code.startswith("SZ"):
        short_code = code[2:]
    else:
        short_code = code
        code = f"SH{code}" if code.startswith("6") else f"SZ{code}"
    
    # è·å–å…³è”æ–°é—»
    from sqlalchemy import text
    stock_codes_filter = text(
        "stock_codes @> ARRAY[:code1]::varchar[] OR stock_codes @> ARRAY[:code2]::varchar[]"
    ).bindparams(code1=short_code, code2=code)
    
    news_query = select(News).where(stock_codes_filter).order_by(desc(News.publish_time)).limit(10)
    result = await db.execute(news_query)
    news_list = result.scalars().all()
    
    news_data = [
        {
            "id": n.id,
            "title": n.title,
            "content": n.content[:500] if n.content else "",
            "sentiment_score": n.sentiment_score,
            "publish_time": n.publish_time.isoformat() if n.publish_time else None
        }
        for n in news_list
    ]
    
    # è·å–é¢å¤–ä¸Šä¸‹æ–‡
    try:
        debate_context = await stock_data_service.get_debate_context(code)
        akshare_context = debate_context.get("summary", "")
    except Exception as e:
        logger.warning(f"è·å–è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
        akshare_context = ""
    
    full_context = ""
    if request.context:
        full_context += f"ã€ç”¨æˆ·è¡¥å……ã€‘{request.context}\n\n"
    if akshare_context:
        full_context += f"ã€å®æ—¶æ•°æ®ã€‘{akshare_context}"
    
    # åˆ›å»º LLM provider
    llm_provider = get_llm_provider(
        provider=request.provider,
        model=request.model
    ) if request.provider or request.model else get_llm_provider()
    
    mode = request.mode or "parallel"
    stock_name = request.stock_name or code
    
    return StreamingResponse(
        generate_debate_stream(code, stock_name, mode, full_context, news_data, llm_provider),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # ç¦ç”¨ nginx ç¼“å†²
        }
    )


@router.get("/debate/{debate_id}", response_model=DebateResponse)
async def get_debate_result(debate_id: str):
    """
    è·å–è¾©è®ºç»“æœ
    
    - **debate_id**: è¾©è®ºID
    """
    if debate_id not in debate_results:
        raise HTTPException(status_code=404, detail="Debate not found")
    
    result = debate_results[debate_id]
    
    return DebateResponse(
        success=result.get("success", False),
        debate_id=debate_id,
        stock_code=result.get("stock_code", ""),
        stock_name=result.get("stock_name"),
        bull_analysis=result.get("bull_analysis"),
        bear_analysis=result.get("bear_analysis"),
        final_decision=result.get("final_decision"),
        trajectory=result.get("trajectory"),
        execution_time=result.get("execution_time")
    )


@router.get("/logs", response_model=List[AgentLogEntry])
async def get_agent_logs(
    limit: int = Query(50, le=200),
    agent_name: Optional[str] = Query(None, description="æŒ‰æ™ºèƒ½ä½“åç§°ç­›é€‰"),
    status: Optional[str] = Query(None, description="æŒ‰çŠ¶æ€ç­›é€‰: started, completed, failed")
):
    """
    è·å–æ™ºèƒ½ä½“æ‰§è¡Œæ—¥å¿—
    
    - **limit**: è¿”å›æ•°é‡é™åˆ¶
    - **agent_name**: æŒ‰æ™ºèƒ½ä½“åç§°ç­›é€‰
    - **status**: æŒ‰çŠ¶æ€ç­›é€‰
    """
    logs = execution_logs.copy()
    
    # ç­›é€‰
    if agent_name:
        logs = [log for log in logs if log.get("agent_name") == agent_name]
    if status:
        logs = [log for log in logs if log.get("status") == status]
    
    # æŒ‰æ—¶é—´å€’åº
    logs.sort(key=lambda x: x.get("timestamp", ""), reverse=True)
    
    # é™åˆ¶æ•°é‡
    logs = logs[:limit]
    
    return [AgentLogEntry(**log) for log in logs]


@router.get("/metrics", response_model=AgentMetrics)
async def get_agent_metrics():
    """
    è·å–æ™ºèƒ½ä½“æ€§èƒ½æŒ‡æ ‡
    """
    total = len(execution_logs)
    successful = len([log for log in execution_logs if log.get("status") == "completed"])
    failed = len([log for log in execution_logs if log.get("status") == "failed"])
    
    # è®¡ç®—å¹³å‡æ‰§è¡Œæ—¶é—´
    execution_times = [
        log.get("execution_time", 0) 
        for log in execution_logs 
        if log.get("execution_time") is not None
    ]
    avg_time = sum(execution_times) / len(execution_times) if execution_times else 0
    
    # æŒ‰æ™ºèƒ½ä½“ç»Ÿè®¡
    agent_stats = {}
    for log in execution_logs:
        agent_name = log.get("agent_name", "Unknown")
        if agent_name not in agent_stats:
            agent_stats[agent_name] = {
                "total": 0,
                "successful": 0,
                "failed": 0,
                "avg_time": 0,
                "times": []
            }
        agent_stats[agent_name]["total"] += 1
        if log.get("status") == "completed":
            agent_stats[agent_name]["successful"] += 1
        elif log.get("status") == "failed":
            agent_stats[agent_name]["failed"] += 1
        if log.get("execution_time"):
            agent_stats[agent_name]["times"].append(log["execution_time"])
    
    # è®¡ç®—æ¯ä¸ªæ™ºèƒ½ä½“çš„å¹³å‡æ—¶é—´
    for agent_name, stats in agent_stats.items():
        if stats["times"]:
            stats["avg_time"] = sum(stats["times"]) / len(stats["times"])
        del stats["times"]  # ä¸è¿”å›åŸå§‹æ—¶é—´åˆ—è¡¨
    
    # æœ€è¿‘æ´»åŠ¨
    recent_logs = sorted(
        execution_logs, 
        key=lambda x: x.get("timestamp", ""), 
        reverse=True
    )[:10]
    
    recent_activity = [
        {
            "timestamp": log.get("timestamp"),
            "agent_name": log.get("agent_name"),
            "action": log.get("action"),
            "status": log.get("status")
        }
        for log in recent_logs
    ]
    
    return AgentMetrics(
        total_executions=total,
        successful_executions=successful,
        failed_executions=failed,
        avg_execution_time=round(avg_time, 2),
        agent_stats=agent_stats,
        recent_activity=recent_activity
    )


@router.get("/trajectory/{debate_id}", response_model=List[TrajectoryStep])
async def get_debate_trajectory(debate_id: str):
    """
    è·å–è¾©è®ºæ‰§è¡Œè½¨è¿¹
    
    - **debate_id**: è¾©è®ºID
    """
    if debate_id not in debate_results:
        raise HTTPException(status_code=404, detail="Debate not found")
    
    result = debate_results[debate_id]
    trajectory = result.get("trajectory", [])
    
    steps = []
    for i, step in enumerate(trajectory):
        steps.append(TrajectoryStep(
            step_id=f"{debate_id}_step_{i}",
            step_name=step.get("step", "unknown"),
            timestamp=step.get("timestamp", ""),
            agent_name=step.get("data", {}).get("agent"),
            input_data=None,  # å¯ä»¥æ‰©å±•
            output_data=step.get("data"),
            duration=None,
            status="completed"
        ))
    
    return steps


@router.delete("/logs")
async def clear_logs():
    """
    æ¸…ç©ºæ‰§è¡Œæ—¥å¿—ï¼ˆä»…ç”¨äºå¼€å‘æµ‹è¯•ï¼‰
    """
    global execution_logs
    count = len(execution_logs)
    execution_logs = []
    return {"message": f"Cleared {count} logs"}


@router.get("/available")
async def get_available_agents():
    """
    è·å–å¯ç”¨çš„æ™ºèƒ½ä½“åˆ—è¡¨
    """
    return {
        "agents": [
            {
                "name": "NewsAnalyst",
                "role": "é‡‘èæ–°é—»åˆ†æå¸ˆ",
                "description": "åˆ†æé‡‘èæ–°é—»çš„æƒ…æ„Ÿã€å½±å“å’Œå…³é”®ä¿¡æ¯",
                "status": "active"
            },
            {
                "name": "BullResearcher",
                "role": "çœ‹å¤šç ”ç©¶å‘˜",
                "description": "ä»ç§¯æè§’åº¦åˆ†æè‚¡ç¥¨ï¼Œå‘ç°æŠ•èµ„æœºä¼š",
                "status": "active"
            },
            {
                "name": "BearResearcher",
                "role": "çœ‹ç©ºç ”ç©¶å‘˜",
                "description": "ä»é£é™©è§’åº¦åˆ†æè‚¡ç¥¨ï¼Œè¯†åˆ«æ½œåœ¨é—®é¢˜",
                "status": "active"
            },
            {
                "name": "InvestmentManager",
                "role": "æŠ•èµ„ç»ç†",
                "description": "ç»¼åˆå¤šæ–¹è§‚ç‚¹ï¼Œåšå‡ºæŠ•èµ„å†³ç­–",
                "status": "active"
            }
        ],
        "workflows": [
            {
                "name": "NewsAnalysisWorkflow",
                "description": "æ–°é—»åˆ†æå·¥ä½œæµï¼šçˆ¬å– -> æ¸…æ´— -> æƒ…æ„Ÿåˆ†æ",
                "agents": ["NewsAnalyst"],
                "status": "active"
            },
            {
                "name": "InvestmentDebateWorkflow",
                "description": "æŠ•èµ„è¾©è®ºå·¥ä½œæµï¼šBull vs Bear å¤šæ™ºèƒ½ä½“è¾©è®º",
                "agents": ["BullResearcher", "BearResearcher", "InvestmentManager"],
                "status": "active"
            }
        ]
    }

