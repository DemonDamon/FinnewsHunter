"""
æ™ºèƒ½ä½“ API è·¯ç”± - Phase 2
æä¾›è¾©è®ºåŠŸèƒ½ã€æ‰§è¡Œæ—¥å¿—ã€æ€§èƒ½ç›‘æ§ç­‰æ¥å£
"""
import logging
import json
import asyncio
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any, AsyncGenerator
from fastapi import APIRouter, Depends, HTTPException, Query, Body
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, desc, or_

from ...core.database import get_db
from ...models.news import News
from ...models.analysis import Analysis
from ...agents import (
    create_debate_workflow,
    create_orchestrator,
    create_data_collector
)
from ...services.llm_service import get_llm_provider
from ...services.stock_data_service import stock_data_service

logger = logging.getLogger(__name__)

router = APIRouter()


# ============ å¤šè¯­è¨€æç¤ºè¯è¾…åŠ©å‡½æ•° ============

def get_prompts(language: str = "zh") -> Dict[str, str]:
    """è·å–å¤šè¯­è¨€æç¤ºè¯"""
    if language == "en":
        return {
            "quick_analyst_system": "You are a professional stock analyst, skilled in quick analysis and decision-making.",
            "quick_analysis_prompt": """Please provide a quick investment analysis for {stock_name}({stock_code}).

Background:
{context}

Related News:
{news}

Please quickly provide:
1. Core Viewpoint (one sentence)
2. Bullish Factors (3 points)
3. Bearish Factors (3 points)
4. Investment Recommendation (Buy/Hold/Sell)
5. Risk Warning""",
            "data_collector_content": "ğŸ“Š Collected relevant data for {stock_name}: {count} news items, financial data ready.\n\nDebate will begin in {rounds} rounds.",
            "bull_system": "You are a bullish researcher, skilled at analyzing stocks from a positive perspective. When answering user questions, maintain an optimistic but rational attitude.",
            "bear_system": "You are a bearish researcher, skilled at identifying risks. When answering user questions, remain cautious and focus on potential risks.",
            "manager_system": "You are an experienced investment manager, skilled at comprehensive analysis and providing investment advice. Answer user questions objectively and professionally.",
            "phase_start": "Starting {mode} mode analysis",
            "phase_analyzing": "Quick analyst is analyzing...",
            "phase_data_collection": "Data Collector is gathering materials...",
            "role_quick_analyst": "Quick Analyst",
            "role_data_collector": "Data Collector",
            "round_debate": "Round {round}/{max_rounds} debate",
            "role_bull": "Bull Researcher",
            "role_bear": "Bear Researcher",
            "bull_first_round": """You are a bullish researcher participating in a bull vs bear debate about {stock_name}({stock_code}).

Background: {context}
News: {news}

This is Round 1. Please make an opening statement (about 150 words):
1. State your core bullish view
2. Provide 2-3 key arguments""",
            "bull_subsequent_rounds": """You are a bullish researcher debating with a bearish researcher about {stock_name}.

This is Round {round}.

The bearish researcher just said:
"{bear_last_statement}"

Please refute the opponent's arguments and add new points (about 120 words):
1. Point out flaws in the opponent's arguments
2. Add new bullish reasons""",
            "bear_first_round": """You are a bearish researcher participating in a bull vs bear debate about {stock_name}({stock_code}).

Background: {context}
News: {news}

This is Round 1. Please make an opening statement (about 150 words):
1. State your core bearish view
2. Provide 2-3 key risk points""",
            "bear_subsequent_rounds": """You are a bearish researcher debating with a bullish researcher about {stock_name}.

This is Round {round}.

The bullish researcher just said:
"{bull_last_statement}"

Please refute the opponent's arguments and add new points (about 120 words):
1. Point out flaws in the opponent's arguments
2. Add new risk points""",
            "manager_decision": """You are an investment manager synthesizing the debate between bullish and bearish researchers to make a final investment decision.

Stock: {stock_name}({stock_code})

Bullish Researcher's View:
{bull_analysis}

Bearish Researcher's View:
{bear_analysis}

Please provide the final decision (about 200 words):
1. Comprehensive evaluation of both views
2. Investment recommendation (Strongly Recommend/Recommend/Neutral/Avoid/Caution)
3. Reasoning and risk warnings""",
        }
    else:  # zh (default)
        return {
            "quick_analyst_system": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è‚¡ç¥¨åˆ†æå¸ˆï¼Œæ“…é•¿å¿«é€Ÿåˆ†æå’Œå†³ç­–ã€‚",
            "quick_analysis_prompt": """è¯·å¯¹ {stock_name}({stock_code}) è¿›è¡Œå¿«é€ŸæŠ•èµ„åˆ†æã€‚

èƒŒæ™¯èµ„æ–™:
{context}

ç›¸å…³æ–°é—»:
{news}

è¯·å¿«é€Ÿç»™å‡ºï¼š
1. æ ¸å¿ƒè§‚ç‚¹ï¼ˆä¸€å¥è¯ï¼‰
2. çœ‹å¤šå› ç´ ï¼ˆ3ç‚¹ï¼‰
3. çœ‹ç©ºå› ç´ ï¼ˆ3ç‚¹ï¼‰
4. æŠ•èµ„å»ºè®®ï¼ˆä¹°å…¥/æŒæœ‰/å–å‡ºï¼‰
5. é£é™©æç¤º""",
            "data_collector_content": "ğŸ“Š å·²æœé›† {stock_name} çš„ç›¸å…³æ•°æ®ï¼š{count} æ¡æ–°é—»ï¼Œè´¢åŠ¡æ•°æ®å·²å°±ç»ªã€‚\n\nè¾©è®ºå³å°†å¼€å§‹ï¼Œå…± {rounds} è½®ã€‚",
            "bull_system": "ä½ æ˜¯ä¸€ä½çœ‹å¤šç ”ç©¶å‘˜ï¼Œæ“…é•¿ä»ç§¯æè§’åº¦åˆ†æè‚¡ç¥¨ã€‚å›ç­”ç”¨æˆ·é—®é¢˜æ—¶ä¿æŒä¹è§‚ä½†ç†æ€§çš„æ€åº¦ã€‚",
            "bear_system": "ä½ æ˜¯ä¸€ä½çœ‹ç©ºç ”ç©¶å‘˜ï¼Œæ“…é•¿å‘ç°é£é™©ã€‚å›ç­”ç”¨æˆ·é—®é¢˜æ—¶ä¿æŒè°¨æ…ï¼Œé‡ç‚¹æŒ‡å‡ºæ½œåœ¨é£é™©ã€‚",
            "manager_system": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æŠ•èµ„ç»ç†ï¼Œæ“…é•¿ç»¼åˆåˆ†æå’Œç»™å‡ºæŠ•èµ„å»ºè®®ã€‚å›ç­”ç”¨æˆ·é—®é¢˜æ—¶å®¢è§‚ã€ä¸“ä¸šã€‚",
            "phase_start": "å¼€å§‹{mode}æ¨¡å¼åˆ†æ",
            "phase_analyzing": "å¿«é€Ÿåˆ†æå¸ˆæ­£åœ¨åˆ†æ...",
            "phase_data_collection": "æ•°æ®ä¸“å‘˜æ­£åœ¨æœé›†èµ„æ–™...",
            "role_quick_analyst": "å¿«é€Ÿåˆ†æå¸ˆ",
            "role_data_collector": "æ•°æ®ä¸“å‘˜",
            "round_debate": "ç¬¬ {round}/{max_rounds} è½®è¾©è®º",
            "role_bull": "çœ‹å¤šç ”ç©¶å‘˜",
            "role_bear": "çœ‹ç©ºç ”ç©¶å‘˜",
            "bull_first_round": """ä½ æ˜¯çœ‹å¤šç ”ç©¶å‘˜ï¼Œæ­£åœ¨å‚ä¸å…³äº {stock_name}({stock_code}) çš„å¤šç©ºè¾©è®ºã€‚

èƒŒæ™¯èµ„æ–™: {context}
æ–°é—»: {news}

è¿™æ˜¯ç¬¬1è½®è¾©è®ºï¼Œè¯·åšå¼€åœºé™ˆè¿°ï¼ˆçº¦150å­—ï¼‰ï¼š
1. è¡¨æ˜ä½ çš„æ ¸å¿ƒçœ‹å¤šè§‚ç‚¹
2. ç»™å‡º2-3ä¸ªå…³é”®è®ºæ®""",
            "bull_subsequent_rounds": """ä½ æ˜¯çœ‹å¤šç ”ç©¶å‘˜ï¼Œæ­£åœ¨ä¸çœ‹ç©ºç ”ç©¶å‘˜è¾©è®º {stock_name}ã€‚

è¿™æ˜¯ç¬¬{round}è½®è¾©è®ºã€‚

å¯¹æ–¹ï¼ˆçœ‹ç©ºç ”ç©¶å‘˜ï¼‰åˆšæ‰è¯´ï¼š
"{bear_last_statement}"

è¯·åé©³å¯¹æ–¹è§‚ç‚¹å¹¶è¡¥å……æ–°è®ºæ®ï¼ˆçº¦120å­—ï¼‰ï¼š
1. æŒ‡å‡ºå¯¹æ–¹è®ºæ®çš„æ¼æ´
2. è¡¥å……æ–°çš„çœ‹å¤šç†ç”±""",
            "bear_first_round": """ä½ æ˜¯çœ‹ç©ºç ”ç©¶å‘˜ï¼Œæ­£åœ¨å‚ä¸å…³äº {stock_name}({stock_code}) çš„å¤šç©ºè¾©è®ºã€‚

èƒŒæ™¯èµ„æ–™: {context}
æ–°é—»: {news}

è¿™æ˜¯ç¬¬1è½®è¾©è®ºï¼Œè¯·åšå¼€åœºé™ˆè¿°ï¼ˆçº¦150å­—ï¼‰ï¼š
1. è¡¨æ˜ä½ çš„æ ¸å¿ƒçœ‹ç©ºè§‚ç‚¹
2. ç»™å‡º2-3ä¸ªå…³é”®é£é™©ç‚¹""",
            "bear_subsequent_rounds": """ä½ æ˜¯çœ‹ç©ºç ”ç©¶å‘˜ï¼Œæ­£åœ¨ä¸çœ‹å¤šç ”ç©¶å‘˜è¾©è®º {stock_name}ã€‚

è¿™æ˜¯ç¬¬{round}è½®è¾©è®ºã€‚

å¯¹æ–¹ï¼ˆçœ‹å¤šç ”ç©¶å‘˜ï¼‰åˆšæ‰è¯´ï¼š
"{bull_last_statement}"

è¯·åé©³å¯¹æ–¹è§‚ç‚¹å¹¶è¡¥å……æ–°è®ºæ®ï¼ˆçº¦120å­—ï¼‰ï¼š
1. æŒ‡å‡ºå¯¹æ–¹è®ºæ®çš„æ¼æ´
2. è¡¥å……æ–°çš„é£é™©ç‚¹""",
            "manager_decision": """ä½ æ˜¯æŠ•èµ„ç»ç†ï¼Œæ­£åœ¨ç»¼åˆçœ‹å¤šå’Œçœ‹ç©ºç ”ç©¶å‘˜çš„è¾©è®ºï¼Œåšå‡ºæœ€ç»ˆæŠ•èµ„å†³ç­–ã€‚

è‚¡ç¥¨: {stock_name}({stock_code})

çœ‹å¤šç ”ç©¶å‘˜è§‚ç‚¹:
{bull_analysis}

çœ‹ç©ºç ”ç©¶å‘˜è§‚ç‚¹:
{bear_analysis}

è¯·ç»™å‡ºæœ€ç»ˆå†³ç­–ï¼ˆçº¦200å­—ï¼‰ï¼š
1. ç»¼åˆè¯„ä¼°åŒæ–¹è§‚ç‚¹
2. ç»™å‡ºæŠ•èµ„å»ºè®®ï¼ˆå¼ºçƒˆæ¨è/æ¨è/ä¸­æ€§/å›é¿/è°¨æ…ï¼‰
3. è¯´æ˜ç†ç”±å’Œé£é™©æç¤º""",
        }


# ============ æ¨¡æ‹Ÿæ•°æ®å­˜å‚¨ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ•°æ®åº“ï¼‰ ============

# å­˜å‚¨æ‰§è¡Œæ—¥å¿—
execution_logs: List[Dict[str, Any]] = []

# å­˜å‚¨è¾©è®ºç»“æœ
debate_results: Dict[str, Dict[str, Any]] = {}


# ============ Pydantic æ¨¡å‹ ============

class DebateRequest(BaseModel):
    """è¾©è®ºè¯·æ±‚"""
    stock_code: str = Field(..., description="è‚¡ç¥¨ä»£ç ")
    stock_name: Optional[str] = Field(None, description="è‚¡ç¥¨åç§°")
    context: Optional[str] = Field(None, description="é¢å¤–èƒŒæ™¯ä¿¡æ¯")
    provider: Optional[str] = Field(None, description="LLMæä¾›å•†")
    model: Optional[str] = Field(None, description="æ¨¡å‹åç§°")
    mode: Optional[str] = Field("parallel", description="è¾©è®ºæ¨¡å¼: parallel, realtime_debate, quick_analysis")
    language: Optional[str] = Field("zh", description="è¯­è¨€è®¾ç½®: zh=ä¸­æ–‡, en=è‹±æ–‡")


class DebateResponse(BaseModel):
    """è¾©è®ºå“åº”"""
    success: bool
    debate_id: Optional[str] = None
    stock_code: str
    stock_name: Optional[str] = None
    mode: Optional[str] = None  # è¾©è®ºæ¨¡å¼
    bull_analysis: Optional[Dict[str, Any]] = None
    bear_analysis: Optional[Dict[str, Any]] = None
    final_decision: Optional[Dict[str, Any]] = None
    quick_analysis: Optional[Dict[str, Any]] = None  # å¿«é€Ÿåˆ†æç»“æœ
    debate_history: Optional[List[Dict[str, Any]]] = None  # å®æ—¶è¾©è®ºå†å²
    trajectory: Optional[List[Dict[str, Any]]] = None
    execution_time: Optional[float] = None
    error: Optional[str] = None


class AgentLogEntry(BaseModel):
    """æ™ºèƒ½ä½“æ—¥å¿—æ¡ç›®"""
    id: str
    timestamp: str
    agent_name: str
    agent_role: Optional[str] = None
    action: str
    status: str  # "started", "completed", "failed"
    details: Optional[Dict[str, Any]] = None
    execution_time: Optional[float] = None


class AgentMetrics(BaseModel):
    """æ™ºèƒ½ä½“æ€§èƒ½æŒ‡æ ‡"""
    total_executions: int
    successful_executions: int
    failed_executions: int
    avg_execution_time: float
    agent_stats: Dict[str, Dict[str, Any]]
    recent_activity: List[Dict[str, Any]]


class TrajectoryStep(BaseModel):
    """æ‰§è¡Œè½¨è¿¹æ­¥éª¤"""
    step_id: str
    step_name: str
    timestamp: str
    agent_name: Optional[str] = None
    input_data: Optional[Dict[str, Any]] = None
    output_data: Optional[Dict[str, Any]] = None
    duration: Optional[float] = None
    status: str


class SearchPlanRequest(BaseModel):
    """ç”Ÿæˆæœç´¢è®¡åˆ’è¯·æ±‚"""
    query: str
    stock_code: str
    stock_name: Optional[str] = None


class SearchExecuteRequest(BaseModel):
    """æ‰§è¡Œæœç´¢è®¡åˆ’è¯·æ±‚"""
    plan: Dict[str, Any]  # å®Œæ•´çš„ SearchPlan å¯¹è±¡


# ============ API ç«¯ç‚¹ ============

@router.post("/debate", response_model=DebateResponse)
async def run_stock_debate(
    request: DebateRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    è§¦å‘è‚¡ç¥¨è¾©è®ºåˆ†æï¼ˆBull vs Bearï¼‰
    
    - **stock_code**: è‚¡ç¥¨ä»£ç 
    - **stock_name**: è‚¡ç¥¨åç§°ï¼ˆå¯é€‰ï¼‰
    - **context**: é¢å¤–èƒŒæ™¯ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
    - **provider**: LLMæä¾›å•†ï¼ˆå¯é€‰ï¼‰
    - **model**: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼‰
    """
    logger.info(f"ğŸ¯ æ”¶åˆ°è¾©è®ºè¯·æ±‚: stock_code={request.stock_code}, stock_name={request.stock_name}")
    
    start_time = datetime.utcnow()
    debate_id = f"debate_{start_time.strftime('%Y%m%d%H%M%S')}_{request.stock_code}"
    
    try:
        # è®°å½•å¼€å§‹
        log_entry = {
            "id": debate_id,
            "timestamp": start_time.isoformat(),
            "agent_name": "DebateWorkflow",
            "action": "debate_start",
            "status": "started",
            "details": {
                "stock_code": request.stock_code,
                "stock_name": request.stock_name
            }
        }
        execution_logs.append(log_entry)
        
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        code = request.stock_code.upper()
        if code.startswith("SH") or code.startswith("SZ"):
            short_code = code[2:]
        else:
            short_code = code
            code = f"SH{code}" if code.startswith("6") else f"SZ{code}"
        
        logger.info(f"ğŸ” æŸ¥è¯¢è‚¡ç¥¨ {code} çš„å…³è”æ–°é—»...")
        
        # è·å–å…³è”æ–°é—» - ä½¿ç”¨ PostgreSQL åŸç”Ÿ ARRAY æŸ¥è¯¢è¯­æ³•
        from sqlalchemy import text
        stock_codes_filter = text(
            "stock_codes @> ARRAY[:code1]::varchar[] OR stock_codes @> ARRAY[:code2]::varchar[]"
        ).bindparams(code1=short_code, code2=code)
        
        news_query = select(News).where(stock_codes_filter).order_by(desc(News.publish_time)).limit(10)
        
        result = await db.execute(news_query)
        news_list = result.scalars().all()
        
        logger.info(f"ğŸ“° æ‰¾åˆ° {len(news_list)} æ¡å…³è”æ–°é—»")
        
        news_data = [
            {
                "id": n.id,
                "title": n.title,
                "content": n.content[:500],
                "sentiment_score": n.sentiment_score,
                "publish_time": n.publish_time.isoformat() if n.publish_time else None
            }
            for n in news_list
        ]
        
        # å¦‚æœæ²¡æœ‰å…³è”æ–°é—»ï¼Œç»™å‡ºè­¦å‘Š
        if not news_data:
            logger.warning(f"âš ï¸ è‚¡ç¥¨ {code} æ²¡æœ‰å…³è”æ–°é—»ï¼Œè¾©è®ºå°†åŸºäºç©ºæ•°æ®è¿›è¡Œ")
        
        # è·å–è´¢åŠ¡æ•°æ®å’Œèµ„é‡‘æµå‘ï¼ˆç”¨äºå¢å¼ºè¾©è®ºä¸Šä¸‹æ–‡ï¼‰
        logger.info(f"ğŸ“Š è·å– {code} çš„è´¢åŠ¡æ•°æ®å’Œèµ„é‡‘æµå‘...")
        try:
            debate_context = await stock_data_service.get_debate_context(code)
            akshare_context = debate_context.get("summary", "")
            logger.info(f"ğŸ“Š è·å–åˆ°é¢å¤–æ•°æ®: {akshare_context[:100]}...")
        except Exception as e:
            logger.warning(f"âš ï¸ è·å–è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
            akshare_context = ""
        
        # åˆå¹¶ç”¨æˆ·æä¾›çš„ä¸Šä¸‹æ–‡å’Œ akshare æ•°æ®
        full_context = ""
        if request.context:
            full_context += f"ã€ç”¨æˆ·è¡¥å……ä¿¡æ¯ã€‘\n{request.context}\n\n"
        if akshare_context:
            full_context += f"ã€å®æ—¶æ•°æ®ã€‘\n{akshare_context}"
        
        # åˆ›å»º LLM providerï¼ˆå¦‚æœæŒ‡å®šäº†è‡ªå®šä¹‰é…ç½®ï¼‰
        llm_provider = None
        if request.provider or request.model:
            logger.info(f"ğŸ¤– ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹: provider={request.provider}, model={request.model}")
            llm_provider = get_llm_provider(
                provider=request.provider,
                model=request.model
            )
        else:
            logger.info("ğŸ¤– ä½¿ç”¨é»˜è®¤ LLM é…ç½®")
        
        # é€‰æ‹©è¾©è®ºæ¨¡å¼
        mode = request.mode or "parallel"
        logger.info(f"âš”ï¸ å¼€å§‹è¾©è®ºå·¥ä½œæµï¼Œæ¨¡å¼: {mode}")
        
        if mode == "parallel":
            # ä½¿ç”¨åŸæœ‰çš„å¹¶è¡Œå·¥ä½œæµ
            workflow = create_debate_workflow(llm_provider)
            debate_result = await workflow.run_debate(
                stock_code=code,
                stock_name=request.stock_name or code,
                news_list=news_data,
                context=full_context
            )
        else:
            # ä½¿ç”¨æ–°çš„ç¼–æ’å™¨ï¼ˆæ”¯æŒ realtime_debate å’Œ quick_analysisï¼‰
            orchestrator = create_orchestrator(mode=mode, llm_provider=llm_provider)
            debate_result = await orchestrator.run(
                stock_code=code,
                stock_name=request.stock_name or code,
                context=full_context,
                news_list=news_data
            )
        
        end_time = datetime.utcnow()
        execution_time = (end_time - start_time).total_seconds()
        
        # å­˜å‚¨ç»“æœ
        debate_results[debate_id] = debate_result
        
        # è®°å½•å®Œæˆ
        log_entry = {
            "id": f"{debate_id}_complete",
            "timestamp": end_time.isoformat(),
            "agent_name": "DebateWorkflow",
            "action": "debate_complete",
            "status": "completed" if debate_result.get("success") else "failed",
            "details": {
                "stock_code": request.stock_code,
                "rating": debate_result.get("final_decision", {}).get("rating", "unknown")
            },
            "execution_time": execution_time
        }
        execution_logs.append(log_entry)
        
        if debate_result.get("success"):
            return DebateResponse(
                success=True,
                debate_id=debate_id,
                stock_code=code,
                stock_name=request.stock_name,
                mode=mode,
                bull_analysis=debate_result.get("bull_analysis"),
                bear_analysis=debate_result.get("bear_analysis"),
                final_decision=debate_result.get("final_decision"),
                quick_analysis=debate_result.get("quick_analysis"),
                debate_history=debate_result.get("debate_history"),
                trajectory=debate_result.get("trajectory"),
                execution_time=execution_time
            )
        else:
            return DebateResponse(
                success=False,
                debate_id=debate_id,
                stock_code=code,
                mode=mode,
                error=debate_result.get("error", "Unknown error")
            )
    
    except Exception as e:
        logger.error(f"Debate failed: {e}", exc_info=True)
        
        # è®°å½•å¤±è´¥
        log_entry = {
            "id": f"{debate_id}_error",
            "timestamp": datetime.utcnow().isoformat(),
            "agent_name": "DebateWorkflow",
            "action": "debate_error",
            "status": "failed",
            "details": {"error": str(e)}
        }
        execution_logs.append(log_entry)
        
        return DebateResponse(
            success=False,
            debate_id=debate_id,
            stock_code=request.stock_code,
            error=str(e)
        )


# ============ SSE æµå¼è¾©è®º ============

async def generate_debate_stream(
    stock_code: str,
    stock_name: str,
    mode: str,
    context: str,
    news_data: List[Dict],
    llm_provider,
    language: str = "zh"
) -> AsyncGenerator[str, None]:
    """
    ç”Ÿæˆè¾©è®ºçš„ SSE æµ
    
    äº‹ä»¶ç±»å‹:
    - phase: é˜¶æ®µå˜åŒ–
    - agent: æ™ºèƒ½ä½“å‘è¨€
    - progress: è¿›åº¦æ›´æ–°
    - result: æœ€ç»ˆç»“æœ
    - error: é”™è¯¯ä¿¡æ¯
    """
    debate_id = f"debate_{datetime.utcnow().strftime('%Y%m%d%H%M%S')}"
    prompts = get_prompts(language)
    
    def sse_event(event_type: str, data: Dict) -> str:
        """æ ¼å¼åŒ– SSE äº‹ä»¶"""
        return f"event: {event_type}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"
    
    try:
        # å‘é€å¼€å§‹äº‹ä»¶
        yield sse_event("phase", {
            "phase": "start",
            "message": prompts["phase_start"].format(mode=mode),
            "debate_id": debate_id
        })
        
        if mode == "quick_analysis":
            # å¿«é€Ÿåˆ†ææ¨¡å¼ - ä½¿ç”¨æµå¼è¾“å‡º
            yield sse_event("phase", {"phase": "analyzing", "message": prompts["phase_analyzing"]})
            
            news_titles = json.dumps([n.get('title', '') for n in news_data[:5]], ensure_ascii=False)
            prompt = prompts["quick_analysis_prompt"].format(
                stock_name=stock_name,
                stock_code=stock_code,
                context=context[:2000],
                news=news_titles
            )
            
            messages = [
                {"role": "system", "content": prompts["quick_analyst_system"]},
                {"role": "user", "content": prompt}
            ]
            
            full_response = ""
            for chunk in llm_provider.stream(messages):
                full_response += chunk
                yield sse_event("agent", {
                    "agent": "QuickAnalyst",
                    "role": prompts["role_quick_analyst"],
                    "content": chunk,
                    "is_chunk": True
                })
                await asyncio.sleep(0)  # è®©å‡ºæ§åˆ¶æƒ
            
            # å‘é€å®Œæˆäº‹ä»¶
            yield sse_event("result", {
                "success": True,
                "mode": mode,
                "quick_analysis": {
                    "analysis": full_response,
                    "success": True
                },
                "execution_time": 0
            })
            
        elif mode == "realtime_debate":
            # å®æ—¶è¾©è®ºæ¨¡å¼ - å¤šè½®äº¤é”‹
            max_rounds = 3  # æœ€å¤§è¾©è®ºè½®æ•°
            
            yield sse_event("phase", {"phase": "data_collection", "message": prompts["phase_data_collection"]})
            await asyncio.sleep(0.3)
            
            # æ•°æ®æœé›†
            yield sse_event("agent", {
                "agent": "DataCollector",
                "role": prompts["role_data_collector"],
                "content": prompts["data_collector_content"].format(
                    stock_name=stock_name,
                    count=len(news_data),
                    rounds=max_rounds
                ),
                "is_chunk": False
            })
            
            # è¾©è®ºå†å²ï¼ˆç”¨äºä¸Šä¸‹æ–‡ï¼‰
            debate_history = []
            bull_full = ""
            bear_full = ""
            
            # å¤šè½®è¾©è®º
            for round_num in range(1, max_rounds + 1):
                yield sse_event("phase", {
                    "phase": "debate",
                    "message": prompts["round_debate"].format(round=round_num, max_rounds=max_rounds),
                    "round": round_num,
                    "max_rounds": max_rounds
                })
                
                # === Bull å‘è¨€ ===
                yield sse_event("agent", {
                    "agent": "BullResearcher",
                    "role": prompts["role_bull"],
                    "content": "",
                    "is_start": True,
                    "round": round_num
                })
                
                if round_num == 1:
                    # ç¬¬ä¸€è½®ï¼šå¼€åœºé™ˆè¿°
                    news_titles = json.dumps([n.get('title', '') for n in news_data[:3]], ensure_ascii=False)
                    bull_prompt = prompts["bull_first_round"].format(
                        stock_name=stock_name,
                        stock_code=stock_code,
                        context=context[:800],
                        news=news_titles
                    )
                else:
                    # åç»­è½®æ¬¡ï¼šåé©³å¯¹æ–¹
                    last_bear = debate_history[-1]["content"] if debate_history else ""
                    bull_prompt = prompts["bull_subsequent_rounds"].format(
                        stock_name=stock_name,
                        round=round_num,
                        bear_last_statement=last_bear[:300]
                    )
                
                bull_system_msg = prompts["bull_system"] if language == "en" else "ä½ æ˜¯ä¸€ä½è¾©è®ºä¸­çš„çœ‹å¤šç ”ç©¶å‘˜ã€‚è¨€ç®€æ„èµ…ï¼Œæœ‰ç†æœ‰æ®ï¼Œè¯­æ°”è‡ªä¿¡ä½†ä¸å‚²æ…¢ã€‚"
                bull_messages = [
                    {"role": "system", "content": bull_system_msg},
                    {"role": "user", "content": bull_prompt}
                ]
                
                bull_response = ""
                for chunk in llm_provider.stream(bull_messages):
                    bull_response += chunk
                    yield sse_event("agent", {
                        "agent": "BullResearcher",
                        "role": "çœ‹å¤šç ”ç©¶å‘˜",
                        "content": chunk,
                        "is_chunk": True,
                        "round": round_num
                    })
                    await asyncio.sleep(0)
                
                round_marker = f"\n\n**ã€Round {round_num}ã€‘**\n" if language == "en" else f"\n\n**ã€ç¬¬{round_num}è½®ã€‘**\n"
                bull_full += round_marker + bull_response
                debate_history.append({"agent": "Bull", "round": round_num, "content": bull_response})
                
                yield sse_event("agent", {
                    "agent": "BullResearcher",
                    "role": prompts["role_bull"],
                    "content": "",
                    "is_end": True,
                    "round": round_num
                })
                
                # === Bear å‘è¨€ï¼ˆåé©³ï¼‰ ===
                yield sse_event("agent", {
                    "agent": "BearResearcher",
                    "role": prompts["role_bear"],
                    "content": "",
                    "is_start": True,
                    "round": round_num
                })
                
                if round_num == 1:
                    news_titles = json.dumps([n.get('title', '') for n in news_data[:3]], ensure_ascii=False)
                    bear_prompt = prompts["bear_first_round"].format(
                        stock_name=stock_name,
                        stock_code=stock_code,
                        context=context[:800],
                        news=news_titles
                    )
                else:
                    bear_prompt = prompts["bear_subsequent_rounds"].format(
                        stock_name=stock_name,
                        round=round_num,
                        bull_last_statement=bull_response[:300]
                    )
                
                bear_system_msg = prompts["bear_system"] if language == "en" else "ä½ æ˜¯ä¸€ä½è¾©è®ºä¸­çš„çœ‹ç©ºç ”ç©¶å‘˜ã€‚è¨€ç®€æ„èµ…ï¼Œå–„äºå‘ç°é£é™©ï¼Œè¯­æ°”è°¨æ…ä½†æœ‰è¯´æœåŠ›ã€‚"
                bear_messages = [
                    {"role": "system", "content": bear_system_msg},
                    {"role": "user", "content": bear_prompt}
                ]
                
                bear_response = ""
                for chunk in llm_provider.stream(bear_messages):
                    bear_response += chunk
                    yield sse_event("agent", {
                        "agent": "BearResearcher",
                        "role": prompts["role_bear"],
                        "content": chunk,
                        "is_chunk": True,
                        "round": round_num
                    })
                    await asyncio.sleep(0)
                
                bear_full += round_marker + bear_response
                debate_history.append({"agent": "Bear", "round": round_num, "content": bear_response})
                
                yield sse_event("agent", {
                    "agent": "BearResearcher",
                    "role": prompts["role_bear"],
                    "content": "",
                    "is_end": True,
                    "round": round_num
                })
            
            # === æŠ•èµ„ç»ç†æ€»ç»“å†³ç­– ===
            decision_msg = "Debate ended, Investment Manager is making final decision..." if language == "en" else "è¾©è®ºç»“æŸï¼ŒæŠ•èµ„ç»ç†æ­£åœ¨åšæœ€ç»ˆå†³ç­–..."
            yield sse_event("phase", {"phase": "decision", "message": decision_msg})
            
            manager_role = "Investment Manager" if language == "en" else "æŠ•èµ„ç»ç†"
            yield sse_event("agent", {
                "agent": "InvestmentManager",
                "role": manager_role,
                "content": "",
                "is_start": True
            })
            
            # æ•´ç†è¾©è®ºå†å²
            debate_summary = "\n".join([
                f"ã€ç¬¬{h['round']}è½®-{'çœ‹å¤š' if h['agent']=='Bull' else 'çœ‹ç©º'}ã€‘{h['content'][:150]}..."
                for h in debate_history
            ])
            
            decision_prompt = prompts["manager_decision"].format(
                stock_name=stock_name,
                stock_code=stock_code,
                bull_analysis=bull_full[:1000],
                bear_analysis=bear_full[:1000]
            )
            
            manager_system_msg = prompts["manager_system"] if language == "en" else "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æŠ•èµ„ç»ç†ï¼Œå–„äºåœ¨å¤šç©ºè§‚ç‚¹ä¸­åšå‡ºç†æ€§å†³ç­–ã€‚"
            decision_messages = [
                {"role": "system", "content": manager_system_msg},
                {"role": "user", "content": decision_prompt}
            ]
            
            decision = ""
            for chunk in llm_provider.stream(decision_messages):
                decision += chunk
                yield sse_event("agent", {
                    "agent": "InvestmentManager",
                    "role": manager_role,
                    "content": chunk,
                    "is_chunk": True
                })
                await asyncio.sleep(0)
            
            yield sse_event("agent", {
                "agent": "InvestmentManager",
                "role": manager_role,
                "content": "",
                "is_end": True
            })
            
            # æå–è¯„çº§
            if language == "en":
                rating = "Neutral"
                for r in ["Strongly Recommend", "Recommend", "Neutral", "Caution", "Avoid"]:
                    if r in decision:
                        rating = r
                        break
            else:
                rating = "ä¸­æ€§"
                for r in ["å¼ºçƒˆæ¨è", "æ¨è", "ä¸­æ€§", "è°¨æ…", "å›é¿"]:
                    if r in decision:
                        rating = r
                        break
            
            # å‘é€å®Œæˆäº‹ä»¶
            yield sse_event("result", {
                "success": True,
                "mode": mode,
                "debate_id": debate_id,
                "total_rounds": max_rounds,
                "bull_analysis": {"analysis": bull_full.strip(), "success": True, "agent_name": "BullResearcher", "agent_role": prompts["role_bull"]},
                "bear_analysis": {"analysis": bear_full.strip(), "success": True, "agent_name": "BearResearcher", "agent_role": prompts["role_bear"]},
                "final_decision": {"decision": decision, "rating": rating, "success": True, "agent_name": "InvestmentManager", "agent_role": manager_role},
                "debate_history": debate_history
            })
            
        else:
            # parallel æ¨¡å¼ - ä¹Ÿä½¿ç”¨æµå¼ï¼Œä½†å¹¶è¡Œå±•ç¤º
            yield sse_event("phase", {"phase": "parallel_analysis", "message": "Bull/Bear å¹¶è¡Œåˆ†æä¸­..."})
            
            # ç”±äºæ˜¯å¹¶è¡Œï¼Œæˆ‘ä»¬äº¤æ›¿è¾“å‡º
            bull_prompt = f"""ä½ æ˜¯çœ‹å¤šç ”ç©¶å‘˜ï¼Œè¯·ä»ç§¯æè§’åº¦åˆ†æ {stock_name}({stock_code})ï¼š
èƒŒæ™¯èµ„æ–™: {context[:1500]}
æ–°é—»: {json.dumps([n.get('title', '') for n in news_data[:5]], ensure_ascii=False)}
è¯·ç»™å‡ºå®Œæ•´çš„çœ‹å¤šåˆ†ææŠ¥å‘Šã€‚"""

            bear_prompt = f"""ä½ æ˜¯çœ‹ç©ºç ”ç©¶å‘˜ï¼Œè¯·ä»é£é™©è§’åº¦åˆ†æ {stock_name}({stock_code})ï¼š
èƒŒæ™¯èµ„æ–™: {context[:1500]}
æ–°é—»: {json.dumps([n.get('title', '') for n in news_data[:5]], ensure_ascii=False)}
è¯·ç»™å‡ºå®Œæ•´çš„çœ‹ç©ºåˆ†ææŠ¥å‘Šã€‚"""

            # Bull æµå¼è¾“å‡º
            yield sse_event("agent", {"agent": "BullResearcher", "role": "çœ‹å¤šç ”ç©¶å‘˜", "content": "", "is_start": True})
            bull_analysis = ""
            for chunk in llm_provider.stream([
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¹è§‚ä½†ç†æ€§çš„è‚¡ç¥¨ç ”ç©¶å‘˜ã€‚"},
                {"role": "user", "content": bull_prompt}
            ]):
                bull_analysis += chunk
                yield sse_event("agent", {"agent": "BullResearcher", "role": "çœ‹å¤šç ”ç©¶å‘˜", "content": chunk, "is_chunk": True})
                await asyncio.sleep(0)
            yield sse_event("agent", {"agent": "BullResearcher", "role": "çœ‹å¤šç ”ç©¶å‘˜", "content": "", "is_end": True})
            
            # Bear æµå¼è¾“å‡º
            yield sse_event("agent", {"agent": "BearResearcher", "role": "çœ‹ç©ºç ”ç©¶å‘˜", "content": "", "is_start": True})
            bear_analysis = ""
            for chunk in llm_provider.stream([
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½è°¨æ…çš„è‚¡ç¥¨ç ”ç©¶å‘˜ã€‚"},
                {"role": "user", "content": bear_prompt}
            ]):
                bear_analysis += chunk
                yield sse_event("agent", {"agent": "BearResearcher", "role": "çœ‹ç©ºç ”ç©¶å‘˜", "content": chunk, "is_chunk": True})
                await asyncio.sleep(0)
            yield sse_event("agent", {"agent": "BearResearcher", "role": "çœ‹ç©ºç ”ç©¶å‘˜", "content": "", "is_end": True})
            
            # æŠ•èµ„ç»ç†å†³ç­–
            yield sse_event("phase", {"phase": "decision", "message": "æŠ•èµ„ç»ç†å†³ç­–ä¸­..."})
            yield sse_event("agent", {"agent": "InvestmentManager", "role": "æŠ•èµ„ç»ç†", "content": "", "is_start": True})
            
            decision_prompt = f"""ç»¼åˆä»¥ä¸‹å¤šç©ºè§‚ç‚¹ï¼Œå¯¹ {stock_name} åšå‡ºæŠ•èµ„å†³ç­–ï¼š
ã€çœ‹å¤šã€‘{bull_analysis[:800]}
ã€çœ‹ç©ºã€‘{bear_analysis[:800]}
è¯·ç»™å‡ºè¯„çº§[å¼ºçƒˆæ¨è/æ¨è/ä¸­æ€§/è°¨æ…/å›é¿]å’Œå†³ç­–ç†ç”±ã€‚"""
            
            decision = ""
            for chunk in llm_provider.stream([
                {"role": "system", "content": "ä½ æ˜¯æŠ•èµ„ç»ç†ã€‚"},
                {"role": "user", "content": decision_prompt}
            ]):
                decision += chunk
                yield sse_event("agent", {"agent": "InvestmentManager", "role": "æŠ•èµ„ç»ç†", "content": chunk, "is_chunk": True})
                await asyncio.sleep(0)
            yield sse_event("agent", {"agent": "InvestmentManager", "role": "æŠ•èµ„ç»ç†", "content": "", "is_end": True})
            
            rating = "ä¸­æ€§"
            for r in ["å¼ºçƒˆæ¨è", "æ¨è", "ä¸­æ€§", "è°¨æ…", "å›é¿"]:
                if r in decision:
                    rating = r
                    break
            
            yield sse_event("result", {
                "success": True,
                "mode": mode,
                "bull_analysis": {"analysis": bull_analysis, "success": True, "agent_name": "BullResearcher", "agent_role": "çœ‹å¤šç ”ç©¶å‘˜"},
                "bear_analysis": {"analysis": bear_analysis, "success": True, "agent_name": "BearResearcher", "agent_role": "çœ‹ç©ºç ”ç©¶å‘˜"},
                "final_decision": {"decision": decision, "rating": rating, "success": True, "agent_name": "InvestmentManager", "agent_role": "æŠ•èµ„ç»ç†"}
            })
        
        yield sse_event("phase", {"phase": "complete", "message": "åˆ†æå®Œæˆ"})
        
    except Exception as e:
        logger.error(f"SSE Debate error: {e}", exc_info=True)
        yield sse_event("error", {"message": str(e)})


@router.post("/debate/stream")
async def run_stock_debate_stream(
    request: DebateRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    æµå¼è¾©è®ºåˆ†æï¼ˆSSEï¼‰
    
    ä½¿ç”¨ Server-Sent Events å®æ—¶æ¨é€è¾©è®ºè¿‡ç¨‹
    """
    logger.info(f"ğŸ¯ æ”¶åˆ°æµå¼è¾©è®ºè¯·æ±‚: stock_code={request.stock_code}, mode={request.mode}")
    
    # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
    code = request.stock_code.upper()
    if code.startswith("SH") or code.startswith("SZ"):
        short_code = code[2:]
    else:
        short_code = code
        code = f"SH{code}" if code.startswith("6") else f"SZ{code}"
    
    # è·å–å…³è”æ–°é—»
    from sqlalchemy import text
    stock_codes_filter = text(
        "stock_codes @> ARRAY[:code1]::varchar[] OR stock_codes @> ARRAY[:code2]::varchar[]"
    ).bindparams(code1=short_code, code2=code)
    
    news_query = select(News).where(stock_codes_filter).order_by(desc(News.publish_time)).limit(10)
    result = await db.execute(news_query)
    news_list = result.scalars().all()
    
    news_data = [
        {
            "id": n.id,
            "title": n.title,
            "content": n.content[:500] if n.content else "",
            "sentiment_score": n.sentiment_score,
            "publish_time": n.publish_time.isoformat() if n.publish_time else None
        }
        for n in news_list
    ]
    
    # è·å–é¢å¤–ä¸Šä¸‹æ–‡
    try:
        debate_context = await stock_data_service.get_debate_context(code)
        akshare_context = debate_context.get("summary", "")
    except Exception as e:
        logger.warning(f"è·å–è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
        akshare_context = ""
    
    full_context = ""
    if request.context:
        full_context += f"ã€ç”¨æˆ·è¡¥å……ã€‘{request.context}\n\n"
    if akshare_context:
        full_context += f"ã€å®æ—¶æ•°æ®ã€‘{akshare_context}"
    
    # åˆ›å»º LLM provider
    llm_provider = get_llm_provider(
        provider=request.provider,
        model=request.model
    ) if request.provider or request.model else get_llm_provider()
    
    mode = request.mode or "parallel"
    stock_name = request.stock_name or code
    
    language = request.language or "zh"
    
    return StreamingResponse(
        generate_debate_stream(code, stock_name, mode, full_context, news_data, llm_provider, language),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # ç¦ç”¨ nginx ç¼“å†²
        }
    )


# ============ è¿½é—®åŠŸèƒ½ ============

class FollowUpRequest(BaseModel):
    """è¿½é—®è¯·æ±‚"""
    stock_code: str = Field(..., description="è‚¡ç¥¨ä»£ç ")
    stock_name: Optional[str] = Field(None, description="è‚¡ç¥¨åç§°")
    question: str = Field(..., description="ç”¨æˆ·é—®é¢˜")
    target_agent: Optional[str] = Field(None, description="ç›®æ ‡è§’è‰²: bull, bear, manager")
    context: Optional[str] = Field(None, description="ä¹‹å‰çš„è¾©è®ºæ‘˜è¦")


async def generate_followup_stream(
    stock_code: str,
    stock_name: str,
    question: str,
    target_agent: str,
    context: str,
    llm_provider
) -> AsyncGenerator[str, None]:
    """
    ç”Ÿæˆè¿½é—®å›å¤çš„ SSE æµ
    """
    def sse_event(event_type: str, data: Dict) -> str:
        return f"event: {event_type}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"
    
    # ç¡®å®šå›å¤è§’è‰²
    agent_config = {
        'bull': {
            'agent': 'BullResearcher',
            'role': 'å¤šæ–¹è¾©æ‰‹',
            'system': 'ä½ æ˜¯ä¸€ä½çœ‹å¤šç ”ç©¶å‘˜ï¼Œæ“…é•¿ä»ç§¯æè§’åº¦åˆ†æè‚¡ç¥¨ã€‚å›ç­”ç”¨æˆ·é—®é¢˜æ—¶ä¿æŒä¹è§‚ä½†ç†æ€§çš„æ€åº¦ã€‚'
        },
        'bear': {
            'agent': 'BearResearcher', 
            'role': 'ç©ºæ–¹è¾©æ‰‹',
            'system': 'ä½ æ˜¯ä¸€ä½çœ‹ç©ºç ”ç©¶å‘˜ï¼Œæ“…é•¿å‘ç°é£é™©ã€‚å›ç­”ç”¨æˆ·é—®é¢˜æ—¶ä¿æŒè°¨æ…ï¼Œé‡ç‚¹æŒ‡å‡ºæ½œåœ¨é£é™©ã€‚'
        },
        'manager': {
            'agent': 'InvestmentManager',
            'role': 'æŠ•èµ„ç»ç†',
            'system': 'ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æŠ•èµ„ç»ç†ï¼Œæ“…é•¿ç»¼åˆåˆ†æå’Œç»™å‡ºæŠ•èµ„å»ºè®®ã€‚å›ç­”ç”¨æˆ·é—®é¢˜æ—¶å®¢è§‚ã€ä¸“ä¸šã€‚'
        }
    }
    
    config = agent_config.get(target_agent, agent_config['manager'])
    
    try:
        yield sse_event("agent", {
            "agent": config['agent'],
            "role": config['role'],
            "content": "",
            "is_start": True
        })
        
        prompt = f"""ä½ æ­£åœ¨å‚ä¸å…³äº {stock_name}({stock_code}) çš„æŠ•èµ„è®¨è®ºã€‚

ä¹‹å‰çš„è®¨è®ºèƒŒæ™¯ï¼š
{context[:1500] if context else 'æš‚æ— '}

ç”¨æˆ·ç°åœ¨é—®ä½ ï¼š
"{question}"

è¯·ä»¥{config['role']}çš„èº«ä»½å›ç­”ï¼ˆçº¦150-200å­—ï¼‰ï¼š"""

        messages = [
            {"role": "system", "content": config['system']},
            {"role": "user", "content": prompt}
        ]
        
        full_response = ""
        for chunk in llm_provider.stream(messages):
            full_response += chunk
            yield sse_event("agent", {
                "agent": config['agent'],
                "role": config['role'],
                "content": chunk,
                "is_chunk": True
            })
            await asyncio.sleep(0)
        
        yield sse_event("agent", {
            "agent": config['agent'],
            "role": config['role'],
            "content": "",
            "is_end": True
        })
        
        yield sse_event("complete", {"success": True})
        
    except Exception as e:
        logger.error(f"Followup error: {e}", exc_info=True)
        yield sse_event("error", {"message": str(e)})


@router.post("/debate/followup")
async def debate_followup(request: FollowUpRequest):
    """
    è¾©è®ºè¿½é—®ï¼ˆSSEï¼‰
    
    ç”¨æˆ·å¯ä»¥åœ¨è¾©è®ºç»“æŸåç»§ç»­æé—®
    - é»˜è®¤ç”±æŠ•èµ„ç»ç†å›ç­”
    - å¦‚æœé—®é¢˜ä¸­åŒ…å« @å¤šæ–¹ æˆ– @bullï¼Œç”±å¤šæ–¹è¾©æ‰‹å›ç­”
    - å¦‚æœé—®é¢˜ä¸­åŒ…å« @ç©ºæ–¹ æˆ– @bearï¼Œç”±ç©ºæ–¹è¾©æ‰‹å›ç­”
    - å¦‚æœé—®é¢˜ä¸­åŒ…å« @æ•°æ®ä¸“å‘˜ï¼Œåˆ™ç”Ÿæˆæœç´¢è®¡åˆ’ï¼ˆä¸ç›´æ¥å›ç­”ï¼‰
    """
    logger.info(f"ğŸ¯ æ”¶åˆ°è¿½é—®è¯·æ±‚: {request.question[:50]}...")
    
    # è§£æç›®æ ‡è§’è‰²
    question = request.question
    target = request.target_agent or 'manager'
    
    # 1. æ£€æŸ¥æ˜¯å¦æåŠæ•°æ®ä¸“å‘˜ï¼ˆç¡®è®¤ä¼˜å…ˆæ¨¡å¼ï¼‰
    if '@æ•°æ®ä¸“å‘˜' in question or target == 'data_collector':
        logger.info("ğŸ” æ£€æµ‹åˆ°æ•°æ®ä¸“å‘˜æåŠï¼Œç”Ÿæˆæœç´¢è®¡åˆ’...")
        
        # ç§»é™¤æåŠè¯
        clean_question = question.replace('@æ•°æ®ä¸“å‘˜', '').strip()
        
        # åˆ›å»ºæ•°æ®ä¸“å‘˜
        data_collector = create_data_collector()
        
        # ç”Ÿæˆè®¡åˆ’
        plan = await data_collector.generate_search_plan(
            query=clean_question,
            stock_code=request.stock_code,
            stock_name=request.stock_name or request.stock_code
        )
        
        # ä½¿ç”¨ SSE è¿”å›è®¡åˆ’äº‹ä»¶
        async def generate_plan_stream():
            # Pydantic V2: ä½¿ç”¨ model_dump_json() æˆ– json.dumps(model_dump())
            plan_json = json.dumps(plan.model_dump(), ensure_ascii=False)
            yield f"event: task_plan\ndata: {plan_json}\n\n"
            yield "event: complete\ndata: {\"success\": true}\n\n"
            
        return StreamingResponse(
            generate_plan_stream(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )

    # 2. æ™®é€šè¿½é—®é€»è¾‘
    # ä»é—®é¢˜ä¸­è§£æ @ æåŠ
    if '@å¤šæ–¹' in question or '@bull' in question.lower() or '@çœ‹å¤š' in question:
        target = 'bull'
        question = question.replace('@å¤šæ–¹', '').replace('@bull', '').replace('@Bull', '').replace('@çœ‹å¤š', '').strip()
    elif '@ç©ºæ–¹' in question or '@bear' in question.lower() or '@çœ‹ç©º' in question:
        target = 'bear'
        question = question.replace('@ç©ºæ–¹', '').replace('@bear', '').replace('@Bear', '').replace('@çœ‹ç©º', '').strip()
    elif '@ç»ç†' in question or '@manager' in question.lower() or '@æŠ•èµ„ç»ç†' in question:
        target = 'manager'
        question = question.replace('@ç»ç†', '').replace('@manager', '').replace('@Manager', '').replace('@æŠ•èµ„ç»ç†', '').strip()
    
    # åˆ›å»º LLM provider
    llm_provider = get_llm_provider()
    
    stock_name = request.stock_name or request.stock_code
    
    return StreamingResponse(
        generate_followup_stream(
            request.stock_code,
            stock_name,
            question,
            target,
            request.context or "",
            llm_provider
        ),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@router.post("/search/execute")
async def execute_search(request: SearchExecuteRequest):
    """
    æ‰§è¡Œç¡®è®¤åçš„æœç´¢è®¡åˆ’ï¼ˆSSEï¼‰
    """
    from ...agents.data_collector_v2 import SearchPlan
    
    logger.info(f"ğŸš€ æ”¶åˆ°æœç´¢æ‰§è¡Œè¯·æ±‚: {request.plan.get('plan_id')}")
    
    try:
        # ååºåˆ—åŒ–è®¡åˆ’
        plan = SearchPlan(**request.plan)
        
        async def generate_search_results():
            yield f"event: phase\ndata: {json.dumps({'phase': 'executing', 'message': 'æ­£åœ¨æ‰§è¡Œæœç´¢ä»»åŠ¡...'}, ensure_ascii=False)}\n\n"
            
            data_collector = create_data_collector()
            
            # æ‰§è¡Œè®¡åˆ’
            results = await data_collector.execute_search_plan(plan)
            
            # å‘é€ç»“æœäº‹ä»¶
            yield f"event: agent\ndata: {json.dumps({'agent': 'DataCollector', 'role': 'æ•°æ®ä¸“å‘˜', 'content': results.get('summary', ''), 'is_chunk': False}, ensure_ascii=False)}\n\n"
            
            yield f"event: result\ndata: {json.dumps(results, ensure_ascii=False)}\n\n"
            yield "event: complete\ndata: {\"success\": true}\n\n"
            
        return StreamingResponse(
            generate_search_results(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no"
            }
        )
        
    except Exception as e:
        logger.error(f"æ‰§è¡Œæœç´¢è®¡åˆ’å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/debate/{debate_id}", response_model=DebateResponse)
async def get_debate_result(debate_id: str):
    """
    è·å–è¾©è®ºç»“æœ
    
    - **debate_id**: è¾©è®ºID
    """
    if debate_id not in debate_results:
        raise HTTPException(status_code=404, detail="Debate not found")
    
    result = debate_results[debate_id]
    
    return DebateResponse(
        success=result.get("success", False),
        debate_id=debate_id,
        stock_code=result.get("stock_code", ""),
        stock_name=result.get("stock_name"),
        bull_analysis=result.get("bull_analysis"),
        bear_analysis=result.get("bear_analysis"),
        final_decision=result.get("final_decision"),
        trajectory=result.get("trajectory"),
        execution_time=result.get("execution_time")
    )


@router.get("/logs", response_model=List[AgentLogEntry])
async def get_agent_logs(
    limit: int = Query(50, le=200),
    agent_name: Optional[str] = Query(None, description="æŒ‰æ™ºèƒ½ä½“åç§°ç­›é€‰"),
    status: Optional[str] = Query(None, description="æŒ‰çŠ¶æ€ç­›é€‰: started, completed, failed")
):
    """
    è·å–æ™ºèƒ½ä½“æ‰§è¡Œæ—¥å¿—
    
    - **limit**: è¿”å›æ•°é‡é™åˆ¶
    - **agent_name**: æŒ‰æ™ºèƒ½ä½“åç§°ç­›é€‰
    - **status**: æŒ‰çŠ¶æ€ç­›é€‰
    """
    logs = execution_logs.copy()
    
    # ç­›é€‰
    if agent_name:
        logs = [log for log in logs if log.get("agent_name") == agent_name]
    if status:
        logs = [log for log in logs if log.get("status") == status]
    
    # æŒ‰æ—¶é—´å€’åº
    logs.sort(key=lambda x: x.get("timestamp", ""), reverse=True)
    
    # é™åˆ¶æ•°é‡
    logs = logs[:limit]
    
    return [AgentLogEntry(**log) for log in logs]


@router.get("/metrics", response_model=AgentMetrics)
async def get_agent_metrics():
    """
    è·å–æ™ºèƒ½ä½“æ€§èƒ½æŒ‡æ ‡
    """
    total = len(execution_logs)
    successful = len([log for log in execution_logs if log.get("status") == "completed"])
    failed = len([log for log in execution_logs if log.get("status") == "failed"])
    
    # è®¡ç®—å¹³å‡æ‰§è¡Œæ—¶é—´
    execution_times = [
        log.get("execution_time", 0) 
        for log in execution_logs 
        if log.get("execution_time") is not None
    ]
    avg_time = sum(execution_times) / len(execution_times) if execution_times else 0
    
    # æŒ‰æ™ºèƒ½ä½“ç»Ÿè®¡
    agent_stats = {}
    for log in execution_logs:
        agent_name = log.get("agent_name", "Unknown")
        if agent_name not in agent_stats:
            agent_stats[agent_name] = {
                "total": 0,
                "successful": 0,
                "failed": 0,
                "avg_time": 0,
                "times": []
            }
        agent_stats[agent_name]["total"] += 1
        if log.get("status") == "completed":
            agent_stats[agent_name]["successful"] += 1
        elif log.get("status") == "failed":
            agent_stats[agent_name]["failed"] += 1
        if log.get("execution_time"):
            agent_stats[agent_name]["times"].append(log["execution_time"])
    
    # è®¡ç®—æ¯ä¸ªæ™ºèƒ½ä½“çš„å¹³å‡æ—¶é—´
    for agent_name, stats in agent_stats.items():
        if stats["times"]:
            stats["avg_time"] = sum(stats["times"]) / len(stats["times"])
        del stats["times"]  # ä¸è¿”å›åŸå§‹æ—¶é—´åˆ—è¡¨
    
    # æœ€è¿‘æ´»åŠ¨
    recent_logs = sorted(
        execution_logs, 
        key=lambda x: x.get("timestamp", ""), 
        reverse=True
    )[:10]
    
    recent_activity = [
        {
            "timestamp": log.get("timestamp"),
            "agent_name": log.get("agent_name"),
            "action": log.get("action"),
            "status": log.get("status")
        }
        for log in recent_logs
    ]
    
    return AgentMetrics(
        total_executions=total,
        successful_executions=successful,
        failed_executions=failed,
        avg_execution_time=round(avg_time, 2),
        agent_stats=agent_stats,
        recent_activity=recent_activity
    )


@router.get("/trajectory/{debate_id}", response_model=List[TrajectoryStep])
async def get_debate_trajectory(debate_id: str):
    """
    è·å–è¾©è®ºæ‰§è¡Œè½¨è¿¹
    
    - **debate_id**: è¾©è®ºID
    """
    if debate_id not in debate_results:
        raise HTTPException(status_code=404, detail="Debate not found")
    
    result = debate_results[debate_id]
    trajectory = result.get("trajectory", [])
    
    steps = []
    for i, step in enumerate(trajectory):
        steps.append(TrajectoryStep(
            step_id=f"{debate_id}_step_{i}",
            step_name=step.get("step", "unknown"),
            timestamp=step.get("timestamp", ""),
            agent_name=step.get("data", {}).get("agent"),
            input_data=None,  # å¯ä»¥æ‰©å±•
            output_data=step.get("data"),
            duration=None,
            status="completed"
        ))
    
    return steps


@router.delete("/logs")
async def clear_logs():
    """
    æ¸…ç©ºæ‰§è¡Œæ—¥å¿—ï¼ˆä»…ç”¨äºå¼€å‘æµ‹è¯•ï¼‰
    """
    global execution_logs
    count = len(execution_logs)
    execution_logs = []
    return {"message": f"Cleared {count} logs"}


@router.get("/available")
async def get_available_agents():
    """
    è·å–å¯ç”¨çš„æ™ºèƒ½ä½“åˆ—è¡¨
    """
    return {
        "agents": [
            {
                "name": "NewsAnalyst",
                "role": "é‡‘èæ–°é—»åˆ†æå¸ˆ",
                "description": "åˆ†æé‡‘èæ–°é—»çš„æƒ…æ„Ÿã€å½±å“å’Œå…³é”®ä¿¡æ¯",
                "status": "active"
            },
            {
                "name": "BullResearcher",
                "role": "çœ‹å¤šç ”ç©¶å‘˜",
                "description": "ä»ç§¯æè§’åº¦åˆ†æè‚¡ç¥¨ï¼Œå‘ç°æŠ•èµ„æœºä¼š",
                "status": "active"
            },
            {
                "name": "BearResearcher",
                "role": "çœ‹ç©ºç ”ç©¶å‘˜",
                "description": "ä»é£é™©è§’åº¦åˆ†æè‚¡ç¥¨ï¼Œè¯†åˆ«æ½œåœ¨é—®é¢˜",
                "status": "active"
            },
            {
                "name": "InvestmentManager",
                "role": "æŠ•èµ„ç»ç†",
                "description": "ç»¼åˆå¤šæ–¹è§‚ç‚¹ï¼Œåšå‡ºæŠ•èµ„å†³ç­–",
                "status": "active"
            },
            {
                "name": "SearchAnalyst",
                "role": "æœç´¢åˆ†æå¸ˆ",
                "description": "åŠ¨æ€è·å–æ•°æ®ï¼Œæ”¯æŒ AkShareã€BochaAIã€ç½‘é¡µæœç´¢ç­‰",
                "status": "active"
            }
        ],
        "workflows": [
            {
                "name": "NewsAnalysisWorkflow",
                "description": "æ–°é—»åˆ†æå·¥ä½œæµï¼šçˆ¬å– -> æ¸…æ´— -> æƒ…æ„Ÿåˆ†æ",
                "agents": ["NewsAnalyst"],
                "status": "active"
            },
            {
                "name": "InvestmentDebateWorkflow",
                "description": "æŠ•èµ„è¾©è®ºå·¥ä½œæµï¼šBull vs Bear å¤šæ™ºèƒ½ä½“è¾©è®º",
                "agents": ["BullResearcher", "BearResearcher", "InvestmentManager"],
                "status": "active"
            }
        ]
    }


# ============ è¾©è®ºå†å² API ============

class DebateHistoryRequest(BaseModel):
    """ä¿å­˜è¾©è®ºå†å²è¯·æ±‚"""
    stock_code: str = Field(..., description="è‚¡ç¥¨ä»£ç ")
    sessions: List[Dict[str, Any]] = Field(..., description="ä¼šè¯åˆ—è¡¨")


class DebateHistoryResponse(BaseModel):
    """è¾©è®ºå†å²å“åº”"""
    success: bool
    stock_code: str
    sessions: List[Dict[str, Any]] = []
    message: Optional[str] = None


@router.get("/debate/history/{stock_code}", response_model=DebateHistoryResponse)
async def get_debate_history(
    stock_code: str,
    limit: int = Query(10, le=50, description="è¿”å›ä¼šè¯æ•°é‡é™åˆ¶"),
    db: AsyncSession = Depends(get_db)
):
    """
    è·å–è‚¡ç¥¨çš„è¾©è®ºå†å²
    
    - **stock_code**: è‚¡ç¥¨ä»£ç 
    - **limit**: è¿”å›æ•°é‡é™åˆ¶ï¼ˆé»˜è®¤10ï¼Œæœ€å¤§50ï¼‰
    """
    from ...models.debate_history import DebateHistory
    
    try:
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        code = stock_code.upper()
        if not (code.startswith("SH") or code.startswith("SZ")):
            code = f"SH{code}" if code.startswith("6") else f"SZ{code}"
        
        # æŸ¥è¯¢å†å²è®°å½•
        query = select(DebateHistory).where(
            DebateHistory.stock_code == code
        ).order_by(desc(DebateHistory.updated_at)).limit(limit)
        
        result = await db.execute(query)
        histories = result.scalars().all()
        
        sessions = []
        for h in histories:
            sessions.append({
                "id": h.session_id,
                "stockCode": h.stock_code,
                "stockName": h.stock_name,
                "mode": h.mode,
                "messages": h.messages,
                "createdAt": h.created_at.isoformat() if h.created_at else None,
                "updatedAt": h.updated_at.isoformat() if h.updated_at else None
            })
        
        return DebateHistoryResponse(
            success=True,
            stock_code=code,
            sessions=sessions
        )
        
    except Exception as e:
        logger.error(f"è·å–è¾©è®ºå†å²å¤±è´¥: {e}", exc_info=True)
        return DebateHistoryResponse(
            success=False,
            stock_code=stock_code,
            message=str(e)
        )


@router.post("/debate/history", response_model=DebateHistoryResponse)
async def save_debate_history(
    request: DebateHistoryRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    ä¿å­˜è¾©è®ºå†å²
    
    - **stock_code**: è‚¡ç¥¨ä»£ç 
    - **sessions**: ä¼šè¯åˆ—è¡¨
    """
    from ...models.debate_history import DebateHistory
    
    try:
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        code = request.stock_code.upper()
        if not (code.startswith("SH") or code.startswith("SZ")):
            code = f"SH{code}" if code.startswith("6") else f"SZ{code}"
        
        saved_count = 0
        
        for session_data in request.sessions:
            session_id = session_data.get("id")
            if not session_id:
                continue
            
            messages = session_data.get("messages", [])
            logger.info(f"ğŸ“¥ Processing session {session_id}: {len(messages)} messages")
            logger.info(f"ğŸ“¥ Message roles: {[m.get('role') for m in messages]}")
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            existing_query = select(DebateHistory).where(
                DebateHistory.session_id == session_id
            )
            existing_result = await db.execute(existing_query)
            existing = existing_result.scalar_one_or_none()
            
            if existing:
                # æ›´æ–°ç°æœ‰è®°å½•
                logger.info(f"ğŸ“¥ Updating existing session, old messages: {len(existing.messages)}, new: {len(messages)}")
                existing.messages = messages
                existing.mode = session_data.get("mode")
                existing.updated_at = datetime.utcnow()
            else:
                # è§£æ created_atï¼Œç¡®ä¿æ˜¯ naive datetimeï¼ˆå»æ‰æ—¶åŒºä¿¡æ¯ï¼‰
                created_at_str = session_data.get("createdAt")
                if created_at_str:
                    # å¤„ç† ISO æ ¼å¼å­—ç¬¦ä¸²ï¼Œç§»é™¤æœ«å°¾çš„ 'Z' å¹¶è½¬æ¢
                    if created_at_str.endswith('Z'):
                        created_at_str = created_at_str[:-1] + '+00:00'
                    parsed_dt = datetime.fromisoformat(created_at_str)
                    # è½¬æ¢ä¸º naive datetime (å»æ‰æ—¶åŒºä¿¡æ¯)
                    if parsed_dt.tzinfo is not None:
                        created_at = parsed_dt.replace(tzinfo=None)
                    else:
                        created_at = parsed_dt
                else:
                    created_at = datetime.utcnow()
                
                # åˆ›å»ºæ–°è®°å½•
                new_history = DebateHistory(
                    session_id=session_id,
                    stock_code=code,
                    stock_name=session_data.get("stockName"),
                    mode=session_data.get("mode"),
                    messages=session_data.get("messages", []),
                    created_at=created_at,
                    updated_at=datetime.utcnow()
                )
                db.add(new_history)
            
            saved_count += 1
        
        await db.commit()
        
        logger.info(f"ä¿å­˜äº† {saved_count} ä¸ªè¾©è®ºä¼šè¯åˆ°æ•°æ®åº“")
        
        return DebateHistoryResponse(
            success=True,
            stock_code=code,
            message=f"æˆåŠŸä¿å­˜ {saved_count} ä¸ªä¼šè¯"
        )
        
    except Exception as e:
        logger.error(f"ä¿å­˜è¾©è®ºå†å²å¤±è´¥: {e}", exc_info=True)
        await db.rollback()
        return DebateHistoryResponse(
            success=False,
            stock_code=request.stock_code,
            message=str(e)
        )


@router.delete("/debate/history/{stock_code}")
async def delete_debate_history(
    stock_code: str,
    session_id: Optional[str] = Query(None, description="åˆ é™¤æŒ‡å®šä¼šè¯ï¼Œä¸ä¼ åˆ™åˆ é™¤æ‰€æœ‰"),
    db: AsyncSession = Depends(get_db)
):
    """
    åˆ é™¤è¾©è®ºå†å²
    
    - **stock_code**: è‚¡ç¥¨ä»£ç 
    - **session_id**: ä¼šè¯IDï¼ˆå¯é€‰ï¼Œä¸ä¼ åˆ™åˆ é™¤è¯¥è‚¡ç¥¨çš„æ‰€æœ‰å†å²ï¼‰
    """
    from ...models.debate_history import DebateHistory
    from sqlalchemy import delete
    
    try:
        # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç 
        code = stock_code.upper()
        if not (code.startswith("SH") or code.startswith("SZ")):
            code = f"SH{code}" if code.startswith("6") else f"SZ{code}"
        
        if session_id:
            # åˆ é™¤æŒ‡å®šä¼šè¯
            stmt = delete(DebateHistory).where(
                DebateHistory.session_id == session_id
            )
        else:
            # åˆ é™¤è¯¥è‚¡ç¥¨çš„æ‰€æœ‰ä¼šè¯
            stmt = delete(DebateHistory).where(
                DebateHistory.stock_code == code
            )
        
        result = await db.execute(stmt)
        await db.commit()
        
        deleted_count = result.rowcount
        
        return {
            "success": True,
            "stock_code": code,
            "deleted_count": deleted_count,
            "message": f"åˆ é™¤äº† {deleted_count} æ¡è®°å½•"
        }
        
    except Exception as e:
        logger.error(f"åˆ é™¤è¾©è®ºå†å²å¤±è´¥: {e}", exc_info=True)
        await db.rollback()
        return {
            "success": False,
            "stock_code": stock_code,
            "message": str(e)
    }

