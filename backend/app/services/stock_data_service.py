"""
è‚¡ç¥¨æ•°æ®æœåŠ¡ - ä½¿ç”¨ akshare è·å–çœŸå®è‚¡ç¥¨æ•°æ®
"""
import logging
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any
from functools import lru_cache
import asyncio

logger = logging.getLogger(__name__)

# å°è¯•å¯¼å…¥ akshare
try:
    import akshare as ak
    import pandas as pd
    AKSHARE_AVAILABLE = True
except ImportError:
    AKSHARE_AVAILABLE = False
    logger.warning("akshare not installed, using mock data")


class StockDataService:
    """è‚¡ç¥¨æ•°æ®æœåŠ¡ - å°è£… akshare æ¥å£"""
    
    # ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
    CACHE_TTL = 300  # 5åˆ†é’Ÿ
    CACHE_TTL_MINUTE = 60  # åˆ†é’Ÿçº§æ•°æ®ç¼“å­˜1åˆ†é’Ÿ
    
    # è‚¡ç¥¨ä»£ç å‰ç¼€æ˜ å°„
    MARKET_PREFIX = {
        "sh": "6",     # ä¸Šæµ· 60xxxx
        "sz": "0",     # æ·±åœ³ 00xxxx, 30xxxx
        "sz3": "3",    # åˆ›ä¸šæ¿ 30xxxx
    }
    
    # å‘¨æœŸæ˜ å°„
    PERIOD_MAP = {
        "1m": "1",      # 1åˆ†é’Ÿ
        "5m": "5",      # 5åˆ†é’Ÿ
        "15m": "15",    # 15åˆ†é’Ÿ
        "30m": "30",    # 30åˆ†é’Ÿ
        "60m": "60",    # 60åˆ†é’Ÿ/1å°æ—¶
        "1h": "60",     # 1å°æ—¶ï¼ˆåˆ«åï¼‰
        "daily": "daily",  # æ—¥çº¿
        "1d": "daily",     # æ—¥çº¿ï¼ˆåˆ«åï¼‰
    }
    
    def __init__(self):
        self._cache: Dict[str, tuple] = {}  # {key: (data, timestamp)}
    
    def _normalize_code(self, stock_code: str) -> str:
        """
        æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ï¼Œè¿”å›çº¯æ•°å­—ä»£ç 
        æ”¯æŒæ ¼å¼: SH600519, sh600519, 600519
        """
        code = stock_code.upper().strip()
        if code.startswith("SH") or code.startswith("SZ"):
            return code[2:]
        return code
    
    def _get_symbol(self, stock_code: str) -> str:
        """
        è·å– akshare ä½¿ç”¨çš„è‚¡ç¥¨ä»£ç æ ¼å¼
        akshare stock_zh_a_hist éœ€è¦çº¯æ•°å­—ä»£ç 
        """
        return self._normalize_code(stock_code)
    
    def _is_cache_valid(self, key: str, ttl: int = None) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if key not in self._cache:
            return False
        _, timestamp = self._cache[key]
        cache_ttl = ttl if ttl is not None else self.CACHE_TTL
        # ä¿®å¤bug: ä½¿ç”¨ total_seconds() è€Œä¸æ˜¯ seconds
        # seconds åªè¿”å›ç§’æ•°éƒ¨åˆ†(0-86399)ï¼Œä¸åŒ…æ‹¬å¤©æ•°
        return (datetime.now() - timestamp).total_seconds() < cache_ttl
    
    def _get_cached(self, key: str, ttl: int = None) -> Optional[Any]:
        """è·å–ç¼“å­˜æ•°æ®"""
        if self._is_cache_valid(key, ttl):
            return self._cache[key][0]
        # æ¸…ç†è¿‡æœŸç¼“å­˜
        if key in self._cache:
            del self._cache[key]
        return None
    
    def _set_cache(self, key: str, data: Any):
        """è®¾ç½®ç¼“å­˜"""
        self._cache[key] = (data, datetime.now())
    
    def clear_cache(self, pattern: str = None):
        """
        æ¸…é™¤ç¼“å­˜
        Args:
            pattern: å¯é€‰çš„ç¼“å­˜é”®æ¨¡å¼ï¼Œå¦‚æœæä¾›åˆ™åªæ¸…é™¤åŒ¹é…çš„ç¼“å­˜
        """
        if pattern:
            keys_to_delete = [k for k in self._cache.keys() if pattern in k]
            for key in keys_to_delete:
                del self._cache[key]
            logger.info(f"ğŸ§¹ Cleared {len(keys_to_delete)} cache entries matching pattern: {pattern}")
        else:
            count = len(self._cache)
            self._cache.clear()
            logger.info(f"ğŸ§¹ Cleared all {count} cache entries")
    
    async def get_kline_data(
        self,
        stock_code: str,
        period: str = "daily",  # daily, 1m, 5m, 15m, 30m, 60m
        limit: int = 90,  # æ•°æ®æ¡æ•°
        adjust: str = "qfq"  # qfq=å‰å¤æƒ, hfq=åå¤æƒ, ""=ä¸å¤æƒ
    ) -> List[Dict[str, Any]]:
        """
        è·å–Kçº¿æ•°æ®ï¼ˆæ”¯æŒæ—¥çº¿å’Œåˆ†é’Ÿçº§æ•°æ®ï¼‰
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            period: å‘¨æœŸ (daily, 1m, 5m, 15m, 30m, 60m)
            limit: è¿”å›æ•°æ®æ¡æ•°
            adjust: å¤æƒç±»å‹ï¼ˆä»…æ—¥çº¿æœ‰æ•ˆï¼‰
            
        Returns:
            Kçº¿æ•°æ®åˆ—è¡¨ï¼Œæ¯æ¡åŒ…å«: timestamp, open, high, low, close, volume, turnover
        """
        # æ ‡å‡†åŒ–å‘¨æœŸ
        period_key = self.PERIOD_MAP.get(period, period)
        cache_key = f"kline:{stock_code}:{period}:{limit}:{adjust}"
        
        # æ ¹æ®å‘¨æœŸä½¿ç”¨ä¸åŒçš„ç¼“å­˜TTLï¼šæ—¥çº¿5åˆ†é’Ÿï¼Œåˆ†é’Ÿçº§1åˆ†é’Ÿ
        cache_ttl = self.CACHE_TTL if period_key == "daily" else self.CACHE_TTL_MINUTE
        cached = self._get_cached(cache_key, ttl=cache_ttl)
        if cached:
            latest_date = cached[-1].get('date', 'unknown') if cached else 'empty'
            logger.info(f"ğŸ”µ Cache hit for {cache_key}, latest date: {latest_date}, count: {len(cached)}")
            return cached
        
        logger.info(f"ğŸ”´ Cache miss for {cache_key}, fetching fresh data...")
        
        if not AKSHARE_AVAILABLE:
            logger.warning("akshare not available, returning mock data")
            return self._generate_mock_kline(stock_code, limit)
        
        try:
            symbol = self._get_symbol(stock_code)
            loop = asyncio.get_event_loop()
            
            if period_key == "daily":
                # æ—¥çº¿æ•°æ®
                kline_data = await self._fetch_daily_kline(symbol, limit, adjust, loop)
            else:
                # åˆ†é’Ÿçº§æ•°æ®
                kline_data = await self._fetch_minute_kline(symbol, period_key, limit, loop)
            
            if not kline_data:
                logger.warning(f"âš ï¸ No valid data after parsing for {stock_code} period={period}, using mock data")
                return self._generate_mock_kline(stock_code, limit)
            
            # è®°å½•æœ€æ–°æ•°æ®çš„æ—¥æœŸå’Œä»·æ ¼ï¼Œä¾¿äºè°ƒè¯•
            latest = kline_data[-1]
            logger.info(f"âœ… Successfully fetched {len(kline_data)} kline records for {stock_code} period={period}, latest: {latest['date']}, close: {latest['close']}")
            
            self._set_cache(cache_key, kline_data)
            return kline_data
            
        except Exception as e:
            logger.error(f"âŒ Failed to fetch kline data for {stock_code}: {type(e).__name__}: {e}", exc_info=True)
            # åªåœ¨æŸäº›ç‰¹å®šé”™è¯¯æ—¶è¿”å›mockæ•°æ®ï¼Œå…¶ä»–é”™è¯¯åº”è¯¥æŠ›å‡º
            if "NaTType" in str(e) or "timestamp" in str(e).lower():
                logger.warning(f"Data parsing error, this should not happen after fix. Returning empty list.")
                return []
            # ç½‘ç»œé”™è¯¯æˆ–APIé”™è¯¯æ‰è¿”å›mockæ•°æ®
            return self._generate_mock_kline(stock_code, limit)
    
    async def _fetch_daily_kline(
        self, 
        symbol: str, 
        limit: int, 
        adjust: str,
        loop
    ) -> List[Dict[str, Any]]:
        """è·å–æ—¥çº¿æ•°æ®"""
        end_date = datetime.now()
        # å¤šè·å–ä¸€äº›å¤©æ•°ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®ï¼ˆè€ƒè™‘å‘¨æœ«å’ŒèŠ‚å‡æ—¥ï¼Œçº¦1ä¸ªäº¤æ˜“æ—¥=1.5ä¸ªè‡ªç„¶æ—¥ï¼‰
        # limit * 1.6 èƒ½ç¡®ä¿è·å–åˆ°è¶³å¤Ÿçš„äº¤æ˜“æ—¥æ•°æ®
        start_date = end_date - timedelta(days=int(limit * 1.6))
        
        logger.info(f"ğŸ“Š Calling akshare API: symbol={symbol}, start={start_date.strftime('%Y%m%d')}, end={end_date.strftime('%Y%m%d')}, adjust={adjust}")
        
        df = await loop.run_in_executor(
            None,
            lambda: ak.stock_zh_a_hist(
                symbol=symbol,
                start_date=start_date.strftime("%Y%m%d"),
                end_date=end_date.strftime("%Y%m%d"),
                adjust=adjust
            )
        )
        
        logger.info(f"âœ… Akshare returned {len(df) if df is not None and not df.empty else 0} rows")
        
        if df is None or df.empty:
            return []
        
        # æ¸…ç†æ•°æ®ï¼šç§»é™¤æ—¥æœŸä¸ºNaTçš„è¡Œ
        df = df.dropna(subset=['æ—¥æœŸ'])
        
        # åªå–æœ€è¿‘ limit æ¡æ•°æ®
        df = df.tail(limit)
        
        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        kline_data = []
        for _, row in df.iterrows():
            try:
                # å¤„ç†æ—¥æœŸ
                date_val = row['æ—¥æœŸ']
                if pd.isna(date_val):
                    logger.warning(f"Skipping row with NaT date")
                    continue
                    
                if isinstance(date_val, str):
                    dt = datetime.strptime(date_val, "%Y-%m-%d")
                    date_str = date_val
                else:
                    dt = pd.to_datetime(date_val)
                    if pd.isna(dt):
                        logger.warning(f"Skipping row with invalid date")
                        continue
                    date_str = dt.strftime("%Y-%m-%d")
                
                timestamp = int(dt.timestamp() * 1000)
                
                kline_data.append({
                    "timestamp": timestamp,
                    "date": date_str,
                    "open": float(row['å¼€ç›˜']),
                    "high": float(row['æœ€é«˜']),
                    "low": float(row['æœ€ä½']),
                    "close": float(row['æ”¶ç›˜']),
                    "volume": int(row['æˆäº¤é‡']),
                    "turnover": float(row.get('æˆäº¤é¢', 0)),
                    "change_percent": float(row.get('æ¶¨è·Œå¹…', 0)),
                    "change_amount": float(row.get('æ¶¨è·Œé¢', 0)),
                    "amplitude": float(row.get('æŒ¯å¹…', 0)),
                    "turnover_rate": float(row.get('æ¢æ‰‹ç‡', 0)),
                })
            except Exception as e:
                logger.warning(f"Failed to parse row, skipping: {e}")
                continue
        
        # è®°å½•æ•°æ®èŒƒå›´
        if kline_data:
            logger.info(f"âœ… Parsed {len(kline_data)} valid records, date range: {kline_data[0]['date']} to {kline_data[-1]['date']}")
        
        return kline_data
    
    async def _fetch_minute_kline(
        self, 
        symbol: str, 
        period: str,  # "1", "5", "15", "30", "60"
        limit: int,
        loop
    ) -> List[Dict[str, Any]]:
        """è·å–åˆ†é’Ÿçº§æ•°æ®"""
        df = await loop.run_in_executor(
            None,
            lambda: ak.stock_zh_a_hist_min_em(
                symbol=symbol,
                period=period,
                adjust=""
            )
        )
        
        if df is None or df.empty:
            return []
        
        # æ¸…ç†æ•°æ®ï¼šç§»é™¤æ—¶é—´ä¸ºNaTçš„è¡Œ
        df = df.dropna(subset=['æ—¶é—´'])
        
        # åªå–æœ€è¿‘ limit æ¡æ•°æ®
        df = df.tail(limit)
        
        # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        kline_data = []
        for _, row in df.iterrows():
            try:
                # å¤„ç†æ—¶é—´
                time_val = row['æ—¶é—´']
                if pd.isna(time_val):
                    logger.warning(f"Skipping row with NaT time")
                    continue
                
                time_str = str(time_val)
                try:
                    dt = datetime.strptime(time_str, "%Y-%m-%d %H:%M:%S")
                except:
                    dt = pd.to_datetime(time_val)
                    if pd.isna(dt):
                        logger.warning(f"Skipping row with invalid time")
                        continue
                    time_str = dt.strftime("%Y-%m-%d %H:%M:%S")
                
                timestamp = int(dt.timestamp() * 1000)
                
                kline_data.append({
                    "timestamp": timestamp,
                    "date": time_str,
                    "open": float(row['å¼€ç›˜']),
                    "high": float(row['æœ€é«˜']),
                    "low": float(row['æœ€ä½']),
                    "close": float(row['æ”¶ç›˜']),
                    "volume": int(row['æˆäº¤é‡']),
                    "turnover": float(row.get('æˆäº¤é¢', 0)),
                    "change_percent": 0,  # åˆ†é’Ÿæ•°æ®å¯èƒ½æ²¡æœ‰æ¶¨è·Œå¹…
                    "change_amount": 0,
                    "amplitude": 0,
                    "turnover_rate": 0,
                })
            except Exception as e:
                logger.warning(f"Failed to parse minute row, skipping: {e}")
                continue
        
        # è®°å½•æ•°æ®èŒƒå›´
        if kline_data:
            logger.info(f"âœ… Parsed {len(kline_data)} valid minute records, time range: {kline_data[0]['date']} to {kline_data[-1]['date']}")
        
        return kline_data
    
    async def get_realtime_quote(self, stock_code: str) -> Optional[Dict[str, Any]]:
        """
        è·å–å®æ—¶è¡Œæƒ…
        
        Returns:
            å®æ—¶è¡Œæƒ…æ•°æ®
        """
        cache_key = f"realtime:{stock_code}"
        cached = self._get_cached(cache_key)
        if cached:
            return cached
        
        if not AKSHARE_AVAILABLE:
            return None
        
        try:
            symbol = self._get_symbol(stock_code)
            
            loop = asyncio.get_event_loop()
            df = await loop.run_in_executor(
                None,
                lambda: ak.stock_zh_a_spot_em()
            )
            
            if df is None or df.empty:
                return None
            
            # æ ¹æ®è‚¡ç¥¨ä»£ç ç­›é€‰
            row = df[df['ä»£ç '] == symbol]
            if row.empty:
                return None
            
            row = row.iloc[0]
            quote = {
                "code": symbol,
                "name": row.get('åç§°', ''),
                "price": float(row.get('æœ€æ–°ä»·', 0)),
                "change_percent": float(row.get('æ¶¨è·Œå¹…', 0)),
                "change_amount": float(row.get('æ¶¨è·Œé¢', 0)),
                "volume": int(row.get('æˆäº¤é‡', 0)),
                "turnover": float(row.get('æˆäº¤é¢', 0)),
                "high": float(row.get('æœ€é«˜', 0)),
                "low": float(row.get('æœ€ä½', 0)),
                "open": float(row.get('ä»Šå¼€', 0)),
                "prev_close": float(row.get('æ˜¨æ”¶', 0)),
            }
            
            self._set_cache(cache_key, quote)
            return quote
            
        except Exception as e:
            logger.error(f"Failed to fetch realtime quote for {stock_code}: {e}")
            return None
    
    async def search_stocks(
        self,
        keyword: str,
        limit: int = 20
    ) -> List[Dict[str, Any]]:
        """
        æœç´¢è‚¡ç¥¨ï¼ˆé€šè¿‡ä»£ç æˆ–åç§°æ¨¡ç³ŠåŒ¹é…ï¼‰
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            limit: è¿”å›æ•°é‡é™åˆ¶
            
        Returns:
            è‚¡ç¥¨åˆ—è¡¨
        """
        cache_key = f"search:{keyword}:{limit}"
        cached = self._get_cached(cache_key)
        if cached:
            return cached
        
        if not AKSHARE_AVAILABLE:
            return self._get_mock_stock_list(keyword, limit)
        
        try:
            loop = asyncio.get_event_loop()
            
            # è·å–å…¨éƒ¨ A è‚¡å®æ—¶è¡Œæƒ…ï¼ˆåŒ…å«ä»£ç å’Œåç§°ï¼‰
            df = await loop.run_in_executor(
                None,
                lambda: ak.stock_zh_a_spot_em()
            )
            
            if df is None or df.empty:
                return self._get_mock_stock_list(keyword, limit)
            
            # æ¨¡ç³ŠåŒ¹é…ä»£ç æˆ–åç§°
            keyword_upper = keyword.upper()
            mask = (
                df['ä»£ç '].str.contains(keyword_upper, na=False) |
                df['åç§°'].str.contains(keyword, na=False)
            )
            matched = df[mask].head(limit)
            
            results = []
            for _, row in matched.iterrows():
                code = str(row['ä»£ç '])
                # ç¡®å®šå¸‚åœºå‰ç¼€
                if code.startswith('6'):
                    full_code = f"SH{code}"
                elif code.startswith('0') or code.startswith('3'):
                    full_code = f"SZ{code}"
                else:
                    full_code = code
                
                results.append({
                    "code": code,
                    "name": str(row['åç§°']),
                    "full_code": full_code,
                    "price": float(row.get('æœ€æ–°ä»·', 0)) if pd.notna(row.get('æœ€æ–°ä»·')) else 0,
                    "change_percent": float(row.get('æ¶¨è·Œå¹…', 0)) if pd.notna(row.get('æ¶¨è·Œå¹…')) else 0,
                })
            
            self._set_cache(cache_key, results)
            return results
            
        except Exception as e:
            logger.error(f"Failed to search stocks: {e}")
            return self._get_mock_stock_list(keyword, limit)
    
    def _get_mock_stock_list(self, keyword: str, limit: int) -> List[Dict[str, Any]]:
        """è¿”å›æ¨¡æ‹Ÿè‚¡ç¥¨åˆ—è¡¨"""
        mock_stocks = [
            {"code": "600519", "name": "è´µå·èŒ…å°", "full_code": "SH600519", "price": 1420.0, "change_percent": 0.5},
            {"code": "000001", "name": "å¹³å®‰é“¶è¡Œ", "full_code": "SZ000001", "price": 12.0, "change_percent": -0.3},
            {"code": "601318", "name": "ä¸­å›½å¹³å®‰", "full_code": "SH601318", "price": 45.0, "change_percent": 0.2},
            {"code": "000858", "name": "äº”ç²®æ¶²", "full_code": "SZ000858", "price": 150.0, "change_percent": 1.1},
            {"code": "002594", "name": "æ¯”äºšè¿ª", "full_code": "SZ002594", "price": 250.0, "change_percent": -0.8},
            {"code": "600036", "name": "æ‹›å•†é“¶è¡Œ", "full_code": "SH600036", "price": 35.0, "change_percent": 0.1},
            {"code": "601166", "name": "å…´ä¸šé“¶è¡Œ", "full_code": "SH601166", "price": 18.0, "change_percent": 0.3},
            {"code": "000333", "name": "ç¾çš„é›†å›¢", "full_code": "SZ000333", "price": 65.0, "change_percent": 0.6},
            {"code": "002415", "name": "æµ·åº·å¨è§†", "full_code": "SZ002415", "price": 32.0, "change_percent": -0.5},
            {"code": "600276", "name": "æ’ç‘åŒ»è¯", "full_code": "SH600276", "price": 42.0, "change_percent": 0.4},
        ]
        
        keyword_lower = keyword.lower()
        filtered = [
            s for s in mock_stocks
            if keyword_lower in s["code"].lower() or keyword_lower in s["name"].lower()
        ]
        return filtered[:limit]
    
    async def get_stock_info(self, stock_code: str) -> Optional[Dict[str, Any]]:
        """
        è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        """
        if not AKSHARE_AVAILABLE:
            return None
        
        try:
            symbol = self._get_symbol(stock_code)
            
            loop = asyncio.get_event_loop()
            df = await loop.run_in_executor(
                None,
                lambda: ak.stock_individual_info_em(symbol=symbol)
            )
            
            if df is None or df.empty:
                return None
            
            # è½¬æ¢ä¸ºå­—å…¸
            info = {}
            for _, row in df.iterrows():
                info[row['item']] = row['value']
            
            return info
            
        except Exception as e:
            logger.error(f"Failed to fetch stock info for {stock_code}: {e}")
            return None
    
    def _generate_mock_kline(self, stock_code: str, days: int) -> List[Dict[str, Any]]:
        """
        ç”Ÿæˆæ¨¡æ‹ŸKçº¿æ•°æ®ï¼ˆå½“ akshare ä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰
        """
        import random
        
        # æ ¹æ®è‚¡ç¥¨ä»£ç è®¾å®šåŸºå‡†ä»·æ ¼
        base_prices = {
            "600519": 1500.0,  # è´µå·èŒ…å°
            "000001": 12.0,    # å¹³å®‰é“¶è¡Œ
            "601318": 45.0,    # ä¸­å›½å¹³å®‰
            "000858": 150.0,   # äº”ç²®æ¶²
            "002594": 250.0,   # æ¯”äºšè¿ª
        }
        
        code = self._normalize_code(stock_code)
        base_price = base_prices.get(code, 50.0)
        current_price = base_price
        
        kline_data = []
        for i in range(days):
            dt = datetime.now() - timedelta(days=days - i - 1)
            # è·³è¿‡å‘¨æœ«
            if dt.weekday() >= 5:
                continue
                
            timestamp = int(dt.timestamp() * 1000)
            date_str = dt.strftime("%Y-%m-%d")
            
            # éšæœºæ³¢åŠ¨
            change_percent = random.uniform(-3, 3)
            open_price = current_price
            close_price = current_price * (1 + change_percent / 100)
            high_price = max(open_price, close_price) * (1 + random.uniform(0, 1.5) / 100)
            low_price = min(open_price, close_price) * (1 - random.uniform(0, 1.5) / 100)
            volume = random.randint(50000, 500000)
            turnover = volume * close_price
            
            kline_data.append({
                "timestamp": timestamp,
                "date": date_str,
                "open": round(open_price, 2),
                "high": round(high_price, 2),
                "low": round(low_price, 2),
                "close": round(close_price, 2),
                "volume": volume,
                "turnover": round(turnover, 2),
                "change_percent": round(change_percent, 2),
                "change_amount": round(close_price - open_price, 2),
                "amplitude": round((high_price - low_price) / open_price * 100, 2),
                "turnover_rate": round(random.uniform(0.5, 5), 2),
            })
            
            current_price = close_price
        
        return kline_data[-days:] if len(kline_data) > days else kline_data


# å•ä¾‹å®ä¾‹
stock_data_service = StockDataService()

