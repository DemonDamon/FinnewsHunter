"""
çŸ¥è¯†æå–å™¨
ä»å¤šç§æ•°æ®æºæå–å…¬å¸çŸ¥è¯†å¹¶æ„å»ºå›¾è°±
"""
import logging
import json
from typing import List, Dict, Any, Optional
from datetime import datetime

from agenticx import Agent
from ..services.llm_service import get_llm_provider
from .graph_models import (
    CompanyNode,
    NameVariantNode,
    BusinessNode,
    IndustryNode,
    ProductNode,
    KeywordNode,
    ConceptNode,
    CompanyKnowledgeGraph
)

logger = logging.getLogger(__name__)


class KnowledgeExtractorAgent(Agent):
    """
    çŸ¥è¯†æå–æ™ºèƒ½ä½“
    ä»å¤šç§æ•°æ®æºæå–å…¬å¸ä¿¡æ¯å¹¶æ„å»ºçŸ¥è¯†å›¾è°±
    """
    
    def __init__(self, llm_provider=None, organization_id: str = "finnews"):
        super().__init__(
            name="KnowledgeExtractor",
            role="çŸ¥è¯†æå–ä¸“å®¶",
            goal="ä»å¤šç§æ•°æ®æºæå–å…¬å¸ä¿¡æ¯ï¼Œæ„å»ºå…¨é¢çš„çŸ¥è¯†å›¾è°±",
            backstory="""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ä¼ä¸šåˆ†æå¸ˆå’ŒçŸ¥è¯†å·¥ç¨‹å¸ˆã€‚
ä½ æ“…é•¿ä»å„ç±»æ•°æ®æºï¼ˆè´¢åŠ¡æ•°æ®ã€æ–°é—»ã€å…¬å‘Šã€ç ”æŠ¥ï¼‰ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œ
è¯†åˆ«å…¬å¸çš„ä¸šåŠ¡çº¿ã€äº§å“ã€è¡Œä¸šå½’å±ã€å…³è”æ¦‚å¿µç­‰ï¼Œ
å¹¶å°†è¿™äº›ä¿¡æ¯ç»“æ„åŒ–ä¸ºçŸ¥è¯†å›¾è°±ï¼Œç”¨äºåç»­çš„æ™ºèƒ½æ£€ç´¢å’Œåˆ†æã€‚""",
            organization_id=organization_id
        )
        
        if llm_provider is None:
            llm_provider = get_llm_provider()
        object.__setattr__(self, '_llm_provider', llm_provider)
        
        logger.info(f"Initialized {self.name} agent")
    
    async def extract_from_akshare(
        self,
        stock_code: str,
        stock_name: str,
        stock_info: Dict[str, Any]
    ) -> CompanyKnowledgeGraph:
        """
        ä» akshare æ•°æ®æå–åŸºç¡€ä¿¡æ¯
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            stock_info: akshare è¿”å›çš„è‚¡ç¥¨ä¿¡æ¯
            
        Returns:
            å…¬å¸çŸ¥è¯†å›¾è°±
        """
        # è·å–å½“å‰æ—¶é—´
        current_time = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")
        
        # æå–çº¯æ•°å­—ä»£ç 
        short_code = stock_code
        if stock_code.startswith("SH") or stock_code.startswith("SZ"):
            short_code = stock_code[2:]
        
        # åˆ›å»ºå…¬å¸èŠ‚ç‚¹
        company = CompanyNode(
            stock_code=stock_code,
            stock_name=stock_name,
            short_code=short_code,
            industry=stock_info.get("industry"),
            sector=stock_info.get("sector"),
            market_cap=stock_info.get("market_cap"),
            listed_date=stock_info.get("listed_date")
        )
        
        # ç”Ÿæˆåç§°å˜ä½“ï¼ˆé€šè¿‡ LLM æ¨ç†ï¼‰
        name_variants_prompt = f"""è¯·ä¸ºä»¥ä¸‹å…¬å¸ç”Ÿæˆå¯èƒ½çš„åç§°å˜ä½“ï¼ˆç®€ç§°ã€åˆ«åç­‰ï¼‰ï¼š

ã€å½“å‰æ—¶é—´ã€‘
{current_time}

ã€å…¬å¸ä¿¡æ¯ã€‘
è‚¡ç¥¨ä»£ç : {stock_code}
å…¬å¸å…¨ç§°: {stock_name}
æ‰€å±è¡Œä¸š: {stock_info.get('industry', 'æœªçŸ¥')}

è¯·ä»¥JSONæ ¼å¼è¿”å›åç§°å˜ä½“åˆ—è¡¨ï¼Œæ¯ä¸ªå˜ä½“åŒ…å«ï¼š
- variant: å˜ä½“åç§°
- variant_type: ç±»å‹ï¼ˆabbreviation=ç®€ç§°, alias=åˆ«å, full_name=å…¨ç§°ï¼‰

ç¤ºä¾‹ï¼š
```json
[
    {{"variant": "å½©è®¯", "variant_type": "abbreviation"}},
    {{"variant": "å½©è®¯ç§‘æŠ€", "variant_type": "alias"}},
    {{"variant": "{stock_name}", "variant_type": "full_name"}}
]
```

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"""
        
        try:
            response = self._llm_provider.invoke([
                {"role": "system", "content": f"ä½ æ˜¯{self.role}ï¼Œ{self.backstory}"},
                {"role": "user", "content": name_variants_prompt}
            ])
            
            content = response.content if hasattr(response, 'content') else str(response)
            
            # æå–JSON
            import re
            json_match = re.search(r'\[.*\]', content, re.DOTALL)
            if json_match:
                variants_data = json.loads(json_match.group())
                name_variants = [NameVariantNode(**v) for v in variants_data]
            else:
                # é»˜è®¤å˜ä½“
                name_variants = [
                    NameVariantNode(variant=stock_name, variant_type="full_name"),
                    NameVariantNode(variant=stock_name[:2], variant_type="abbreviation")
                ]
                logger.warning("LLM æœªè¿”å›æœ‰æ•ˆJSONï¼Œä½¿ç”¨é»˜è®¤å˜ä½“")
        except Exception as e:
            logger.error(f"åç§°å˜ä½“æå–å¤±è´¥: {e}")
            name_variants = [
                NameVariantNode(variant=stock_name, variant_type="full_name")
            ]
        
        # ç”Ÿæˆä¸šåŠ¡çº¿ï¼ˆé€šè¿‡ LLM æ¨ç† + akshare æ•°æ®ï¼‰
        business_prompt = f"""è¯·åˆ†æä»¥ä¸‹å…¬å¸çš„ä¸»è¥ä¸šåŠ¡çº¿ï¼š

ã€å½“å‰æ—¶é—´ã€‘
{current_time}

ã€å…¬å¸ä¿¡æ¯ã€‘
è‚¡ç¥¨ä»£ç : {stock_code}
å…¬å¸åç§°: {stock_name}
æ‰€å±è¡Œä¸š: {stock_info.get('industry', 'æœªçŸ¥')}
ä¸»è¥ä¸šåŠ¡: {stock_info.get('main_business', 'æœªçŸ¥')}

è¯·ä»¥JSONæ ¼å¼è¿”å›ä¸šåŠ¡çº¿åˆ—è¡¨ï¼Œæ¯ä¸ªä¸šåŠ¡åŒ…å«ï¼š
- business_name: ä¸šåŠ¡åç§°ï¼ˆç®€æ´ï¼‰
- business_type: ç±»å‹ï¼ˆmain=ä¸»è¥, new=æ–°å¢, stopped=å·²åœæ­¢ï¼‰
- description: ä¸šåŠ¡æè¿°
- status: çŠ¶æ€ï¼ˆactive=æ´»è·ƒ, stopped=å·²åœæ­¢ï¼‰

ç¤ºä¾‹ï¼š
```json
[
    {{"business_name": "è¿è¥å•†å¢å€¼æœåŠ¡", "business_type": "main", "description": "ä¸ºè¿è¥å•†æä¾›å¢å€¼ä¸šåŠ¡", "status": "active"}},
    {{"business_name": "AIå¤§æ¨¡å‹åº”ç”¨", "business_type": "new", "description": "AIåº”ç”¨å¼€å‘ä¸è½åœ°", "status": "active"}}
]
```

åªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"""
        
        try:
            response = self._llm_provider.invoke([
                {"role": "system", "content": f"ä½ æ˜¯{self.role}ï¼Œ{self.backstory}"},
                {"role": "user", "content": business_prompt}
            ])
            
            content = response.content if hasattr(response, 'content') else str(response)
            
            # æå–JSON
            json_match = re.search(r'\[.*\]', content, re.DOTALL)
            if json_match:
                businesses_data = json.loads(json_match.group())
                businesses = [BusinessNode(**b) for b in businesses_data]
            else:
                businesses = []
                logger.warning("LLM æœªè¿”å›æœ‰æ•ˆä¸šåŠ¡çº¿JSON")
        except Exception as e:
            logger.error(f"ä¸šåŠ¡çº¿æå–å¤±è´¥: {e}")
            businesses = []
        
        # è¡Œä¸šèŠ‚ç‚¹
        industries = []
        if stock_info.get('industry'):
            industries.append(IndustryNode(
                industry_name=stock_info['industry'],
                level=1
            ))
        
        # è¿”å›åŸºç¡€å›¾è°±
        return CompanyKnowledgeGraph(
            company=company,
            name_variants=name_variants,
            businesses=businesses,
            industries=industries,
            products=[],
            keywords=[],
            concepts=[]
        )
    
    async def extract_from_news(
        self,
        stock_code: str,
        stock_name: str,
        news_list: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        ä»æ–°é—»ä¸­æå–ä¸šåŠ¡å˜åŒ–å’Œæ¦‚å¿µ
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            news_list: æ–°é—»åˆ—è¡¨
            
        Returns:
            æå–çš„ä¿¡æ¯
        """
        if not news_list:
            return {
                "new_businesses": [],
                "stopped_businesses": [],
                "new_products": [],
                "new_concepts": []
            }
        
        # è·å–å½“å‰æ—¶é—´
        current_time = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")
        
        # æ±‡æ€»æ–°é—»
        news_summary = "\n\n".join([
            f"ã€{i+1}ã€‘{news.get('title', '')}\n{news.get('content', '')[:300]}..."
            for i, news in enumerate(news_list[:10])
        ])
        
        prompt = f"""è¯·åˆ†æä»¥ä¸‹æ–°é—»ï¼Œæå–{stock_name}å…¬å¸çš„ä¸šåŠ¡å˜åŒ–å’Œç›¸å…³æ¦‚å¿µï¼š

ã€å½“å‰æ—¶é—´ã€‘
{current_time}

ã€å…¬å¸ã€‘{stock_name}({stock_code})

ã€è¿‘æœŸæ–°é—»ã€‘
{news_summary}

è¯·ä»æ–°é—»ä¸­æå–ï¼š
1. **æ–°å¢ä¸šåŠ¡çº¿**ï¼šå…¬å¸æ–°å¼€æ‹“çš„ä¸šåŠ¡æ–¹å‘
2. **åœæ­¢ä¸šåŠ¡çº¿**ï¼šå…¬å¸æ˜ç¡®è¡¨ç¤ºåœæ­¢æˆ–é€€å‡ºçš„ä¸šåŠ¡
3. **æ–°äº§å“/æœåŠ¡**ï¼šå…¬å¸æ¨å‡ºçš„æ–°äº§å“æˆ–æœåŠ¡
4. **å…³è”æ¦‚å¿µ**ï¼šæ–°é—»ä¸­æåˆ°çš„çƒ­é—¨æ¦‚å¿µï¼ˆå¦‚ AIå¤§æ¨¡å‹ã€äº‘è®¡ç®—ã€å…ƒå®‡å®™ç­‰ï¼‰

ä»¥JSONæ ¼å¼è¿”å›ï¼š
```json
{{
    "new_businesses": ["ä¸šåŠ¡1", "ä¸šåŠ¡2"],
    "stopped_businesses": ["ä¸šåŠ¡3"],
    "new_products": ["äº§å“1", "äº§å“2"],
    "new_concepts": ["æ¦‚å¿µ1", "æ¦‚å¿µ2"]
}}
```

æ³¨æ„ï¼š
- åªæå–æ˜ç¡®çš„ä¿¡æ¯ï¼Œä¸è¦è‡†æµ‹
- å¦‚æœæ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¿”å›ç©ºæ•°ç»„
- åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—

JSON:"""
        
        try:
            response = self._llm_provider.invoke([
                {"role": "system", "content": f"ä½ æ˜¯{self.role}ï¼Œ{self.backstory}"},
                {"role": "user", "content": prompt}
            ])
            
            content = response.content if hasattr(response, 'content') else str(response)
            
            # æå–JSON
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                extracted = json.loads(json_match.group())
                logger.info(f"âœ… ä»æ–°é—»æå–ä¿¡æ¯: {extracted}")
                return extracted
            else:
                logger.warning("LLM æœªè¿”å›æœ‰æ•ˆJSON")
                return {
                    "new_businesses": [],
                    "stopped_businesses": [],
                    "new_products": [],
                    "new_concepts": []
                }
        except Exception as e:
            logger.error(f"æ–°é—»ä¿¡æ¯æå–å¤±è´¥: {e}")
            return {
                "new_businesses": [],
                "stopped_businesses": [],
                "new_products": [],
                "new_concepts": []
            }
    
    async def extract_from_document(
        self,
        stock_code: str,
        stock_name: str,
        document_content: str,
        document_type: str = "annual_report"
    ) -> Dict[str, Any]:
        """
        ä»PDF/Wordæ–‡æ¡£æå–æ·±åº¦ä¿¡æ¯
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            document_content: æ–‡æ¡£å†…å®¹ï¼ˆå·²é€šè¿‡MinerUè§£æï¼‰
            document_type: æ–‡æ¡£ç±»å‹ï¼ˆannual_report=å¹´æŠ¥, announcement=å…¬å‘Šï¼‰
            
        Returns:
            æå–çš„ä¿¡æ¯
        """
        # è·å–å½“å‰æ—¶é—´
        current_time = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")
        
        prompt = f"""è¯·ä»ä»¥ä¸‹{stock_name}çš„{document_type}ä¸­æå–è¯¦ç»†çš„ä¸šåŠ¡ä¿¡æ¯ï¼š

ã€å½“å‰æ—¶é—´ã€‘
{current_time}

ã€å…¬å¸ã€‘{stock_name}({stock_code})

ã€æ–‡æ¡£å†…å®¹ã€‘ï¼ˆå‰3000å­—ï¼‰
{document_content[:3000]}

è¯·æå–ï¼š
1. **ä¸»è¥ä¸šåŠ¡**ï¼šå…¬å¸å½“å‰çš„æ ¸å¿ƒä¸šåŠ¡ï¼ˆè¯¦ç»†ï¼‰
2. **æ–°å¢ä¸šåŠ¡**ï¼šæ–‡æ¡£ä¸­æåˆ°çš„æ–°ä¸šåŠ¡æ‹“å±•
3. **ä¸»è¦äº§å“**ï¼šå…¬å¸çš„ä¸»è¦äº§å“æˆ–æœåŠ¡
4. **è¡Œä¸šå®šä½**ï¼šæ‰€å±è¡Œä¸šå’Œç»†åˆ†é¢†åŸŸ
5. **æˆ˜ç•¥æ–¹å‘**ï¼šæœªæ¥æˆ˜ç•¥å’Œå…³æ³¨çš„çƒ­ç‚¹é¢†åŸŸ

ä»¥JSONæ ¼å¼è¿”å›ï¼š
```json
{{
    "main_businesses": [
        {{"name": "ä¸šåŠ¡1", "description": "è¯¦ç»†æè¿°"}}
    ],
    "new_businesses": [
        {{"name": "ä¸šåŠ¡2", "description": "è¯¦ç»†æè¿°"}}
    ],
    "products": [
        {{"name": "äº§å“1", "type": "software/hardware/service", "description": "æè¿°"}}
    ],
    "industries": ["ä¸€çº§è¡Œä¸š", "äºŒçº§è¡Œä¸š"],
    "concepts": ["æ¦‚å¿µ1", "æ¦‚å¿µ2"],
    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"]
}}
```

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚"""
        
        try:
            response = self._llm_provider.invoke([
                {"role": "system", "content": f"ä½ æ˜¯{self.role}ï¼Œ{self.backstory}"},
                {"role": "user", "content": prompt}
            ])
            
            content = response.content if hasattr(response, 'content') else str(response)
            
            # æå–JSON
            import re
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                extracted = json.loads(json_match.group())
                logger.info(f"âœ… ä»æ–‡æ¡£æå–ä¿¡æ¯: {len(extracted.get('products', []))}ä¸ªäº§å“, {len(extracted.get('concepts', []))}ä¸ªæ¦‚å¿µ")
                return extracted
            else:
                logger.warning("LLM æœªè¿”å›æœ‰æ•ˆJSON")
                return {}
        except Exception as e:
            logger.error(f"æ–‡æ¡£ä¿¡æ¯æå–å¤±è´¥: {e}")
            return {}


class AkshareKnowledgeExtractor:
    """
    ä» akshare æå–åŸºç¡€ä¿¡æ¯ï¼Œæ„å»ºç®€å•å›¾è°±å¹¶ç”Ÿæˆæœç´¢å…³é”®è¯
    """
    
    @staticmethod
    def extract_company_info(stock_code: str) -> Optional[Dict[str, Any]]:
        """
        ä» akshare è·å–å…¬å¸åŸºç¡€ä¿¡æ¯
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            å…¬å¸ä¿¡æ¯å­—å…¸
        """
        try:
            import akshare as ak
            
            # æå–çº¯æ•°å­—ä»£ç 
            pure_code = stock_code
            if stock_code.startswith("SH") or stock_code.startswith("SZ"):
                pure_code = stock_code[2:]
            
            logger.info(f"ğŸ” ä» akshare è·å–å…¬å¸ä¿¡æ¯: {pure_code}")
            
            # è·å–ä¸ªè‚¡ä¿¡æ¯
            try:
                # å°è¯•è·å–å®æ—¶è¡Œæƒ…ï¼ˆåŒ…å«åŸºæœ¬ä¿¡æ¯ï¼‰
                stock_df = ak.stock_individual_info_em(symbol=pure_code)
                
                if stock_df is not None and not stock_df.empty:
                    # æ‰“å° DataFrame ç»“æ„ç”¨äºè°ƒè¯•
                    logger.info(f"ğŸ“‹ akshare è¿”å› DataFrame: columns={list(stock_df.columns)}, rows={len(stock_df)}")
                    
                    # è½¬æ¢ä¸ºå­—å…¸ - å…¼å®¹ä¸åŒçš„åˆ—åæ ¼å¼
                    info_dict = {}
                    
                    # ç¡®å®šåˆ—å
                    columns = list(stock_df.columns)
                    key_col = None
                    value_col = None
                    
                    # å°è¯•æ‰¾åˆ° key åˆ—
                    for col in ['item', 'å±æ€§', 'name', 'é¡¹ç›®']:
                        if col in columns:
                            key_col = col
                            break
                    
                    # å°è¯•æ‰¾åˆ° value åˆ—
                    for col in ['value', 'å€¼', 'data', 'æ•°å€¼']:
                        if col in columns:
                            value_col = col
                            break
                    
                    # å¦‚æœåªæœ‰ä¸¤åˆ—ï¼Œç›´æ¥ä½¿ç”¨
                    if len(columns) == 2 and (key_col is None or value_col is None):
                        key_col, value_col = columns[0], columns[1]
                    
                    if key_col and value_col:
                        for _, row in stock_df.iterrows():
                            try:
                                key = str(row[key_col]) if row[key_col] is not None else ''
                                value = str(row[value_col]) if row[value_col] is not None else ''
                                if key and value and key != 'nan' and value != 'nan':
                                    info_dict[key] = value
                            except Exception as row_err:
                                logger.debug(f"è·³è¿‡è¡Œ: {row_err}")
                                continue
                    else:
                        logger.warning(f"âš ï¸ æ— æ³•è¯†åˆ« DataFrame åˆ—ç»“æ„: {columns}")
                    
                    logger.info(f"ğŸ“Š è§£æåˆ° {len(info_dict)} ä¸ªå­—æ®µ: {list(info_dict.keys())[:10]}...")
                    
                    # æå–å…³é”®å­—æ®µ
                    result = {
                        "industry": info_dict.get("è¡Œä¸š") or info_dict.get("æ‰€å±è¡Œä¸š"),
                        "sector": info_dict.get("æ¿å—") or info_dict.get("æ‰€å±æ¿å—"),
                        "main_business": info_dict.get("ä¸»è¥ä¸šåŠ¡") or info_dict.get("ç»è¥èŒƒå›´"),
                        "total_market_cap": info_dict.get("æ€»å¸‚å€¼"),
                        "listed_date": info_dict.get("ä¸Šå¸‚æ—¶é—´"),
                        "raw_data": info_dict
                    }
                    
                    main_business_preview = (result.get('main_business') or '')[:30]
                    logger.info(f"âœ… è·å–åˆ°å…¬å¸ä¿¡æ¯: è¡Œä¸š={result.get('industry')}, ä¸»è¥={main_business_preview}...")
                    return result
                else:
                    logger.warning(f"âš ï¸ akshare æœªè¿”å›æ•°æ®: {pure_code}")
                    return None
                    
            except Exception as e:
                logger.error(f"âŒ akshare æŸ¥è¯¢å¤±è´¥: {e}", exc_info=True)
                return None
                
        except ImportError:
            logger.error("akshare æœªå®‰è£…")
            return None
        except Exception as e:
            logger.error(f"æå–å…¬å¸ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    @staticmethod
    def generate_search_keywords(
        stock_code: str,
        stock_name: str,
        akshare_info: Optional[Dict[str, Any]] = None
    ) -> Dict[str, List[str]]:
        """
        åŸºäºè‚¡ç¥¨ä¿¡æ¯ç”Ÿæˆåˆ†å±‚å…³é”®è¯
        
        è¿”å›ä¸¤ç±»å…³é”®è¯ï¼š
        - core_keywords: æ ¸å¿ƒå…³é”®è¯ï¼ˆå…¬å¸åã€ä»£ç ç­‰ï¼Œå¿…é¡»åŒ…å«ï¼‰
        - extension_keywords: æ‰©å±•å…³é”®è¯ï¼ˆè¡Œä¸šã€ä¸šåŠ¡ã€äººåç­‰ï¼Œç”¨äºç»„åˆï¼‰
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ SZ000004ï¼‰
            stock_name: è‚¡ç¥¨åç§°ï¼ˆå¦‚ *STå›½åï¼‰
            akshare_info: akshare è¿”å›çš„å…¬å¸ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            {"core_keywords": [...], "extension_keywords": [...]}
        """
        core_keywords = []
        extension_keywords = []
        
        # æå–çº¯æ•°å­—ä»£ç 
        pure_code = stock_code
        if stock_code.startswith("SH") or stock_code.startswith("SZ"):
            pure_code = stock_code[2:]
        
        # === 1. æ ¸å¿ƒå…³é”®è¯ï¼ˆå¿…é¡»åŒ…å«ï¼Œç”¨äºç¡®ä¿ç›¸å…³æ€§ï¼‰===
        # åŸå§‹åç§°ï¼ˆå¦‚ *STå›½åï¼‰
        core_keywords.append(stock_name)
        
        # å»é™¤ ST æ ‡è®°çš„åç§°ï¼ˆå¦‚ å›½åï¼‰
        clean_name = stock_name
        for prefix in ["*ST", "ST", "S*ST", "S"]:
            if clean_name.startswith(prefix):
                clean_name = clean_name[len(prefix):]
                break
        if clean_name != stock_name and len(clean_name) >= 2:
            core_keywords.append(clean_name)
        
        # è‚¡ç¥¨ä»£ç 
        core_keywords.append(pure_code)  # 000004
        core_keywords.append(stock_code)  # SZ000004
        
        # å°å†™å˜ä½“ï¼ˆå¦‚ stå›½åï¼‰
        core_keywords.append(stock_name.lower())
        if clean_name != stock_name:
            core_keywords.append(clean_name.lower())
        
        # === 2. æ‰©å±•å…³é”®è¯ï¼ˆç”¨äºç»„åˆæœç´¢ï¼Œæ‰©å¤§èŒƒå›´ï¼‰===
        if akshare_info:
            raw_data = akshare_info.get("raw_data", {})
            
            # å…¬å¸å…¨ç§°ï¼ˆä» raw_data ä¸­æå–ï¼‰
            company_full_name = raw_data.get("å…¬å¸åç§°", raw_data.get("å…¬å¸å…¨ç§°"))
            if company_full_name and len(company_full_name) > 4:
                extension_keywords.append(company_full_name)
            
            # è¡Œä¸šï¼ˆä½†ä¸å•ç‹¬æœç´¢ï¼‰
            industry = akshare_info.get("industry")
            if industry:
                extension_keywords.append(industry)
            
            # ä¸»è¥ä¸šåŠ¡ï¼ˆæå–å…³é”®è¯ï¼‰
            main_business = akshare_info.get("main_business", "")
            if main_business:
                import re
                business_parts = re.split(r'[ï¼Œ,ã€ï¼›;ã€‚\s]+', main_business)
                for part in business_parts[:3]:  # åªå–å‰3ä¸ª
                    if 3 <= len(part) <= 10:  # é•¿åº¦é€‚ä¸­çš„è¯
                        extension_keywords.append(part)
            
            # è‘£äº‹é•¿ã€æ€»ç»ç†ç­‰å…³é”®äººç‰©
            ceo = raw_data.get("è‘£äº‹é•¿", raw_data.get("æ€»ç»ç†"))
            if ceo and 2 <= len(str(ceo)) <= 4:
                extension_keywords.append(str(ceo))
        
        # å»é‡
        core_keywords = list(dict.fromkeys(core_keywords))
        extension_keywords = list(dict.fromkeys(extension_keywords))
        
        logger.info(
            f"ğŸ“‹ ç”Ÿæˆåˆ†å±‚å…³é”®è¯: æ ¸å¿ƒ={len(core_keywords)}ä¸ª{core_keywords[:5]}, "
            f"æ‰©å±•={len(extension_keywords)}ä¸ª{extension_keywords[:5]}"
        )
        
        return {
            "core_keywords": core_keywords,
            "extension_keywords": extension_keywords
        }
    
    @staticmethod
    def build_simple_graph_from_info(
        stock_code: str,
        stock_name: str,
        akshare_info: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        åŸºäº akshare ä¿¡æ¯æ„å»ºç®€å•çš„çŸ¥è¯†å›¾è°±ç»“æ„
        
        å³ä½¿ akshare è°ƒç”¨å¤±è´¥ï¼Œä¹Ÿèƒ½åŸºäºè‚¡ç¥¨åç§°æ„å»ºåŸºç¡€å›¾è°±
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            akshare_info: akshare è¿”å›çš„å…¬å¸ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ç®€å•å›¾è°±ç»“æ„
        """
        # æå–çº¯æ•°å­—ä»£ç 
        pure_code = stock_code
        if stock_code.startswith("SH") or stock_code.startswith("SZ"):
            pure_code = stock_code[2:]
        
        # æ„å»ºåŸºç¡€å›¾è°±
        graph = {
            "company": {
                "stock_code": stock_code,
                "stock_name": stock_name,
                "pure_code": pure_code
            },
            "name_variants": [],
            "industries": [],
            "businesses": [],
            "keywords": []
        }
        
        # === 1. åç§°å˜ä½“ ===
        graph["name_variants"].append(stock_name)
        
        # å»é™¤ ST æ ‡è®°
        clean_name = stock_name
        for prefix in ["*ST", "ST", "S*ST", "S"]:
            if clean_name.startswith(prefix):
                clean_name = clean_name[len(prefix):]
                break
        if clean_name != stock_name:
            graph["name_variants"].append(clean_name)
        
        # ç®€ç§°ï¼ˆå–å‰ä¸¤ä¸ªå­—ï¼‰
        if len(clean_name) >= 2:
            graph["name_variants"].append(clean_name[:2])
        
        # === 2. åŸºäº akshare ä¿¡æ¯å¡«å…… ===
        if akshare_info:
            # è¡Œä¸š
            industry = akshare_info.get("industry")
            if industry:
                graph["industries"].append(industry)
            
            # æ¿å—
            sector = akshare_info.get("sector")
            if sector:
                graph["industries"].append(sector)
            
            # ä¸»è¥ä¸šåŠ¡
            main_business = akshare_info.get("main_business", "")
            if main_business:
                graph["businesses"].append(main_business[:100])  # æˆªå–å‰100å­—
                
                # æå–ä¸šåŠ¡å…³é”®è¯
                import re
                business_parts = re.split(r'[ï¼Œ,ã€ï¼›;ã€‚\s]+', main_business)
                for part in business_parts[:5]:
                    if 2 <= len(part) <= 10:
                        graph["keywords"].append(part)
        
        # === 3. ç”Ÿæˆæœç´¢å…³é”®è¯ï¼ˆåˆ†å±‚ï¼šæ ¸å¿ƒ + æ‰©å±•ï¼‰ ===
        keyword_groups = AkshareKnowledgeExtractor.generate_search_keywords(
            stock_code, stock_name, akshare_info
        )
        graph["core_keywords"] = keyword_groups["core_keywords"]
        graph["extension_keywords"] = keyword_groups["extension_keywords"]
        
        logger.info(f"ğŸ“Š æ„å»ºç®€å•å›¾è°±: å…¬å¸={stock_name}, åç§°å˜ä½“={len(graph['name_variants'])}ä¸ª, "
                   f"è¡Œä¸š={len(graph['industries'])}ä¸ª, "
                   f"æ ¸å¿ƒè¯={len(graph['core_keywords'])}ä¸ª, æ‰©å±•è¯={len(graph['extension_keywords'])}ä¸ª")
        
        return graph


class NewsKnowledgeExtractor:
    """
    ä»æ–°é—»ä¸­æå–ä¸šåŠ¡å˜åŒ–
    """
    
    def __init__(self, extractor_agent: KnowledgeExtractorAgent):
        self.agent = extractor_agent
    
    async def extract_business_changes(
        self,
        stock_code: str,
        stock_name: str,
        news_list: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        ä»æ–°é—»åˆ—è¡¨ä¸­æå–ä¸šåŠ¡å˜åŒ–
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            news_list: æ–°é—»åˆ—è¡¨
            
        Returns:
            ä¸šåŠ¡å˜åŒ–ä¿¡æ¯
        """
        return await self.agent.extract_from_news(stock_code, stock_name, news_list)


# å·¥å‚å‡½æ•°
def create_knowledge_extractor(llm_provider=None) -> KnowledgeExtractorAgent:
    """åˆ›å»ºçŸ¥è¯†æå–æ™ºèƒ½ä½“"""
    return KnowledgeExtractorAgent(llm_provider)

